{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ad207ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\kaggle_smbcd\\lib\\site-packages\\timm\\layers\\padding.py:19: TracerWarning: Converting a tensor to a Python float might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "C:\\Users\\User\\anaconda3\\envs\\kaggle_smbcd\\lib\\site-packages\\timm\\layers\\padding.py:19: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
      "C:\\Users\\User\\anaconda3\\envs\\kaggle_smbcd\\lib\\site-packages\\timm\\layers\\padding.py:31: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if pad_h > 0 or pad_w > 0:\n",
      "C:\\Users\\User\\anaconda3\\envs\\kaggle_smbcd\\lib\\site-packages\\torch\\onnx\\utils.py:689: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\jit\\passes\\onnx\\constant_fold.cpp:181.)\n",
      "  _C._jit_pass_onnx_graph_shape_type_inference(\n",
      "C:\\Users\\User\\anaconda3\\envs\\kaggle_smbcd\\lib\\site-packages\\torch\\onnx\\utils.py:1186: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\jit\\passes\\onnx\\constant_fold.cpp:181.)\n",
      "  _C._jit_pass_onnx_graph_shape_type_inference(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= Diagnostic Run torch.onnx.export version 2.0.0+cu117 =============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.onnx as torch_onnx\n",
    "\n",
    "class Customize_Model(nn.Module):\n",
    "    def __init__(self, model_name, cls):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, image):\n",
    "        x = self.model(image)\n",
    "        return x\n",
    "\n",
    "input_shape = (3, 128, 313)\n",
    "# input_shape = (3, 192, 470)\n",
    "\n",
    "# torch_model_path= './train_model/cv0_best.pth'\n",
    "torch_model_path= './test_model/effb0_imgsz128_PL2/model_soup.pth'\n",
    "\n",
    "model= torch.load(torch_model_path, map_location='cpu').eval()\n",
    "\n",
    "# dynamic input: can accept different input size image\n",
    "model_onnx_path = torch_model_path.replace('pth', 'onnx')\n",
    "\n",
    "# Export the model to an ONNX file\n",
    "dummy_input = Variable(torch.randn(1, *input_shape))\n",
    "output = torch_onnx.export(model, \n",
    "                           dummy_input, \n",
    "                           model_onnx_path, \n",
    "#                            opset_version=12,\n",
    "                           input_names= ['input'],\n",
    "                           verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63d885ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime\n",
    "\n",
    "session = onnxruntime.InferenceSession(torch_model_path.replace('pth', 'onnx'),\n",
    "                                       providers=[\n",
    "#                                             'TensorrtExecutionProvider',\n",
    "#                                             'CUDAExecutionProvider',\n",
    "                                            'CPUExecutionProvider'\n",
    "                                       ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "272f5d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import time\n",
    "\n",
    "def model_predict(session, img):\n",
    "    \n",
    "    session.get_modelmeta()\n",
    "    first_input_name = session.get_inputs()[0]\n",
    "    first_output_name = session.get_outputs()[0]\n",
    "\n",
    "    inname = [input.name for input in session.get_inputs()]\n",
    "    outname = [output.name for output in session.get_outputs()]\n",
    "\n",
    "    data_output = session.run(outname, {inname[0]: img})\n",
    "\n",
    "    pred= {}\n",
    "    pred['label']= data_output[0]\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1468cdd1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.4291, 5.7834, 5.3119, 5.6427, 5.8332, 4.8138, 4.5394, 4.4131, 6.1539,\n",
      "        4.7093])\n",
      "[5.4290733 5.783387  5.311868  5.6426854 5.8332057 4.813763  4.5394173\n",
      " 4.413128  6.153949  4.7093315]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "img= torch.rand(1,3,128,313)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    pred= model(img)\n",
    "print(pred[0][:10])\n",
    "\n",
    "pred= model_predict(session, img.numpy())['label']\n",
    "print(pred[0][:10])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
