{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c42fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import cv2\n",
    "import time\n",
    "import random\n",
    "import glob\n",
    "from PIL import Image\n",
    "import  matplotlib.pyplot as plt\n",
    "\n",
    "# For data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Pytorch Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda import amp\n",
    "from pytorch_toolbelt import losses as L\n",
    "\n",
    "# Utils\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# For Image Models\n",
    "import timm\n",
    "\n",
    "# Albumentations for augmentations\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "## using gpu:1\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "def seed_everything(seed=123):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "seed_everything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dad1498",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Customize_Model(nn.Module):\n",
    "    def __init__(self, model_name, cls):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(model_name, pretrained=True)\n",
    "        \n",
    "    def forward(self, image):\n",
    "        x = self.model(image)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "def get_test_transform(img_size):\n",
    "    return A.Compose([\n",
    "        A.SmallestMaxSize(max_size=img_size, interpolation=3, p=1),\n",
    "#         A.Resize(img_size, img_size),\n",
    "        ToTensorV2(p=1.0),\n",
    "    ])\n",
    "\n",
    "class Customize_Dataset(Dataset):\n",
    "    def __init__(self, df, transforms=None):\n",
    "        self.df = df\n",
    "        self.transforms = transforms\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        data = self.df.loc[index]\n",
    "        img = cv2.imread(data['image_path'])\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        if self.transforms:\n",
    "            img = self.transforms(image=img)[\"image\"]\n",
    "            \n",
    "        return {\n",
    "            'image': torch.tensor(img/255, dtype=torch.float32),\n",
    "        }\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add9004c",
   "metadata": {},
   "source": [
    "# CFG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200ee22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG= {\n",
    "    'fold': 4,\n",
    "    'img_size': 128,\n",
    "    'TTA': False,\n",
    "#     'model': ['./train_model/cv0_best.pth'],\n",
    "    'model': [\n",
    "        './test_model/convnextv2_tiny_imgsz128_PL3/cv4_best.pth',\n",
    "        './test_model/effv2s_imgsz128_PL3/cv4_best.pth',\n",
    "    ]\n",
    "}\n",
    "CFG['model']= [ torch.load(m, map_location= 'cuda:0') for m in CFG['model']]\n",
    "print(f\"length of model: {len(CFG['model'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0061056",
   "metadata": {},
   "source": [
    "# Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ecfbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('Data/train.csv')\n",
    "train_df= df[df['fold']!=CFG['fold']].reset_index(drop=True)\n",
    "valid_df= df[df['fold']==CFG['fold']].reset_index(drop=True)\n",
    "print(f'train dataset: {len(train_df)}')\n",
    "print(f'valid dataset: {len(valid_df)}')\n",
    "\n",
    "valid_dataset= Customize_Dataset(valid_df.iloc[:], get_test_transform(CFG['img_size']))\n",
    "valid_loader= DataLoader(valid_dataset, batch_size=32, shuffle=False, num_workers=0)\n",
    "valid_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cca9943",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, img):\n",
    "    \n",
    "    img= torch.unsqueeze(img, 0).cuda()\n",
    "    for i, m in enumerate(model):\n",
    "        with torch.no_grad():\n",
    "            m.eval()\n",
    "            if CFG['TTA']:\n",
    "                imgs= torch.cat([\n",
    "                            img, \n",
    "                            img.flip(-1), \n",
    "                            img.flip(-2), \n",
    "                            img.flip(-1).flip(-2)\n",
    "                        ], dim=0)\n",
    "                \n",
    "                ## tensor_trt can't use bs!=1\n",
    "                for j in range(CFG['TTA']):\n",
    "                    p= m(imgs[j:j+1])\n",
    "                    if j==0: ps= p\n",
    "                    else: ps+= p\n",
    "                pred= ps/CFG['TTA']\n",
    "            else:\n",
    "                pred= m(img)[0]\n",
    "                \n",
    "        if i==0: preds= pred.softmax(dim=-1)\n",
    "        else: preds+= pred.softmax(dim=-1)\n",
    "            \n",
    "    pred= preds/len(model)\n",
    "    pred= pred.cpu().numpy()\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79354f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df['pred_cls']= None\n",
    "valid_df['pred_prob']= None\n",
    "count= 0\n",
    "for i, data in enumerate(tqdm(valid_loader)):\n",
    "    for j in range(len(data['image'])):\n",
    "        img= data['image'][j]\n",
    "#         print(img.shape)\n",
    "        pred= inference(CFG['model'], img)\n",
    "        valid_df.loc[count, 'pred_cls']= pred.argmax(0)\n",
    "        valid_df.at[count, 'pred_prob']= pred.tolist()\n",
    "        count+= 1\n",
    "valid_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10dfac32",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df['pred_cls'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc9716e",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df['pred_cls'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8082c1b",
   "metadata": {},
   "source": [
    "# Make Pseudo Label"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6c809ae8",
   "metadata": {},
   "source": [
    "valid_df.to_csv(f\"Data/effb0_cv{CFG['fold']}_PL4.csv\", index=False)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7c646db5",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "\n",
    "df1= pd.read_csv('Data/effb0_cv0_PL4.csv')\n",
    "df2= pd.read_csv('Data/effb0_cv1_PL4.csv')\n",
    "df3= pd.read_csv('Data/effb0_cv2_PL4.csv')\n",
    "df4= pd.read_csv('Data/effb0_cv3_PL4.csv')\n",
    "df5= pd.read_csv('Data/effb0_cv4_PL4.csv')\n",
    "\n",
    "df= pd.concat([df1,df2,df3,df4,df5], axis=0).reset_index(drop=True)\n",
    "df.to_csv('Data/train_effb0_PL4.csv',index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a2434b1d",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "pl= pd.read_csv('Data/train_effb0_PL4.csv')\n",
    "df= pd.read_csv('Data/train_2nd_label.csv')\n",
    "\n",
    "for i in tqdm(range(len(pl))):\n",
    "    name= pl.loc[i,'image_path']\n",
    "    prob= pl.loc[i,'pred_prob']\n",
    "    indx= df[df['image_path']==name].index[0]\n",
    "    df.loc[indx, 'pred_prob']= prob\n",
    "df.to_csv('Data/train_effb0_PL4.csv',index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0831d24",
   "metadata": {},
   "source": [
    "# Confusion_Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f92202",
   "metadata": {},
   "outputs": [],
   "source": [
    "from metrics import *\n",
    "\n",
    "label= valid_df['label'].values\n",
    "pred= valid_df['pred_prob'].values\n",
    "pred= np.array([np.array(p) for p in pred])\n",
    "\n",
    "recall= Mean_Recall(pred, label)\n",
    "print(f'mean_recall: {recall}')\n",
    "\n",
    "cmap= padded_cmap(pred, label)\n",
    "print(f'cmap: {cmap}')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e4f5384d",
   "metadata": {},
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm_df= pd.DataFrame( confusion_matrix(valid_df['label'].values, \n",
    "                                      valid_df['pred_cls'].astype(np.int64).values) )\n",
    "\n",
    "for i in range(len(cm_df)):\n",
    "    recall= cm_df.loc[i,i] / cm_df.loc[i].sum()\n",
    "    cm_df.loc[i,'recall']= recall\n",
    "print(f\"avg_recall {cm_df['recall'].mean()}\")\n",
    "    \n",
    "print(f'row: label, column: pred')\n",
    "cm_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42eeb1a",
   "metadata": {},
   "source": [
    "# show error img"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f4d65f78",
   "metadata": {},
   "source": [
    "df= valid_df[valid_df['label']==1]\n",
    "df= df[df['pred_cls']!=1].reset_index(drop=True)\n",
    "for i in range(len(df)):\n",
    "    print(f\"pred: {df.loc[i, 'pred_cls']}\")\n",
    "    img= np.array(Image.open(df.loc[i, 'image_path']))\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fd6c39",
   "metadata": {},
   "source": [
    "# Grad_Cam"
   ]
  },
  {
   "cell_type": "raw",
   "id": "887f4306",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "from pytorch_grad_cam import GradCAM, HiResCAM, ScoreCAM, GradCAMPlusPlus, AblationCAM, XGradCAM, EigenCAM, FullGrad\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def reshape_transform(tensor, height=7, width=7):\n",
    "    result = tensor.reshape(tensor.size(0),\n",
    "                            height, width, tensor.size(2))\n",
    "\n",
    "    # Bring the channels to the first dimension,\n",
    "    # like in CNNs.\n",
    "    result = result.transpose(2, 3).transpose(1, 2)\n",
    "    return result\n",
    "\n",
    "model= CFG['model'][0]\n",
    "data= valid_dataset[1]\n",
    "img= data['image']\n",
    "rgb_img= img.permute(1,2,0).numpy()\n",
    "\n",
    "target_layers = [model.model.conv_head]\n",
    "cam= GradCAM(model=model, \n",
    "             target_layers=target_layers, \n",
    "#              reshape_transform=reshape_transform, ## if swin_tranformer\n",
    "             use_cuda=True)\n",
    "\n",
    "input_tensor = img.unsqueeze(0)\n",
    "targets = [ClassifierOutputTarget(0)]\n",
    "grayscale_cam = cam(\n",
    "                    input_tensor=input_tensor, \n",
    "                    eigen_smooth=True,\n",
    "                    aug_smooth=True,\n",
    "                    targets=targets,\n",
    "#                     targets=None,  ## if swin_tranformer\n",
    "                )\n",
    "\n",
    "grayscale_cam = grayscale_cam[0, :]\n",
    "visualization = show_cam_on_image(rgb_img, grayscale_cam, use_rgb=True)\n",
    "plt.imshow(visualization)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
