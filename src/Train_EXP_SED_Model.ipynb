{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ab1420b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import cv2\n",
    "import time\n",
    "import random\n",
    "\n",
    "# For data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Pytorch Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda import amp\n",
    "from pytorch_toolbelt import losses as L\n",
    "\n",
    "# Utils\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# For Image Models\n",
    "import timm\n",
    "\n",
    "# Albumentations for augmentations\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "## using gpu:1\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "def seed_everything(seed=123):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "seed_everything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85ceec4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Customize_Model(nn.Module):\n",
    "    def __init__(self, model_name, classes_num):\n",
    "        super().__init__()\n",
    "        self.encoder= torch.load('pretrained/effb0_ex_1_20_21_22.pth').model\n",
    "        self.encoder.global_pool= nn.Identity()\n",
    "        self.encoder.classifier= nn.Identity()\n",
    "        in_feat= 1280\n",
    "        self.cla= nn.Conv1d(\n",
    "                        in_channels=in_feat,\n",
    "                        out_channels=classes_num,\n",
    "                        kernel_size=1,\n",
    "                        stride=1,\n",
    "                        padding=0,\n",
    "                        bias=True\n",
    "                    )\n",
    "        self.att= nn.Conv1d(\n",
    "                        in_channels=in_feat,\n",
    "                        out_channels=classes_num,\n",
    "                        kernel_size=1,\n",
    "                        stride=1,\n",
    "                        padding=0,\n",
    "                        bias=True\n",
    "                    )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x= self.encoder(x)\n",
    "        x= torch.mean(x, dim=2)\n",
    "        \n",
    "        att_map= self.att(x).sigmoid()\n",
    "        x= self.cla(x).softmax(dim=-1)\n",
    "#         print(att_map)\n",
    "        out= x*att_map\n",
    "        out= torch.sum(out, dim=2)\n",
    "        out= torch.clamp(out, 0, 1)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "# model= Customize_Model('', 264).cuda()\n",
    "# x= torch.rand(1,3,128,313).cuda()\n",
    "# model(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8881b53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_transform(img_size):\n",
    "    return A.Compose([\n",
    "        A.SmallestMaxSize(max_size=img_size, interpolation=3, p=1),\n",
    "#         A.Resize(img_size, img_size),\n",
    "        \n",
    "        A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),\n",
    "#         A.HorizontalFlip(p=0.5),\n",
    "#         A.VerticalFlip(p=0.5),\n",
    "#         A.Blur(blur_limit= 3, p=0.3), \n",
    "        A.GaussNoise(p=0.3),\n",
    "        A.OneOf([\n",
    "                A.Cutout(max_h_size=10, max_w_size=16),\n",
    "                A.CoarseDropout(max_holes=4),\n",
    "            ], p=0.5),\n",
    "        A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.15, rotate_limit= 0,\n",
    "                                        interpolation=cv2.INTER_LINEAR, border_mode=0, p=0.7),\n",
    "        ToTensorV2(p=1.0),\n",
    "    ])\n",
    "\n",
    "\n",
    "def get_test_transform(img_size):\n",
    "    return A.Compose([\n",
    "        A.SmallestMaxSize(max_size=img_size, interpolation=3, p=1),\n",
    "#         A.Resize(img_size, img_size),\n",
    "        ToTensorV2(p=1.0),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a153977",
   "metadata": {},
   "outputs": [],
   "source": [
    "from toolbox.audio_aug import *\n",
    "\n",
    "class Customize_Dataset(Dataset):\n",
    "    def __init__(self, df, transforms=None, mixup=0):\n",
    "        self.df = df\n",
    "        self.transforms = transforms\n",
    "        self.mixup= mixup\n",
    "        \n",
    "    def mixup_aug(self, img_1, mask_1, \n",
    "                        img_2, mask_2):\n",
    "        \"\"\"\n",
    "        img: numpy array of shape (height, width,channel)\n",
    "        mask: numpy array of shape (height, width,channel)\n",
    "        \"\"\"\n",
    "        ## mixup\n",
    "        weight= np.random.beta(a=0.5, b=0.5)\n",
    "        img= img_1*weight + img_2*(1-weight)\n",
    "        mask= mask_1*weight + mask_2*(1-weight)\n",
    "        return img.astype(np.uint8), mask\n",
    "    \n",
    "    def read_data(self, data):\n",
    "        img = cv2.imread(data['image_path'])\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        label= [0]*CFG['num_classes']\n",
    "        cls = data['label']\n",
    "        label[cls]= 1\n",
    "        label= np.array(label)\n",
    "        return img, label\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        data = self.df.loc[index]\n",
    "        img, label= self.read_data(data)\n",
    "        \n",
    "        # use mixup\n",
    "        if self.mixup and np.random.rand() >= (1-self.mixup):\n",
    "            img_1= img\n",
    "            label_1= np.array(label)\n",
    "            while True:\n",
    "                indx= np.random.randint(len(self.df))\n",
    "                data= self.df.loc[indx]\n",
    "                img_2, label_2= self.read_data(data)\n",
    "                if label_1.argmax(0)!=label_2.argmax(0): break\n",
    "            img, label= self.mixup_aug(img_1, label_1, \n",
    "                                       img_2, label_2)\n",
    "        \n",
    "        if self.transforms:\n",
    "            img = self.transforms(image=img)[\"image\"]\n",
    "            \n",
    "        return {\n",
    "            'image': torch.tensor(img/255, dtype=torch.float32),\n",
    "            'label': torch.tensor(label, dtype=torch.float32),\n",
    "        }\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "25e62a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Customize_loss(nn.Module):\n",
    "    def  __init__(self):\n",
    "        super().__init__()\n",
    "        self.CrossEntropy= nn.CrossEntropyLoss(weight= None, label_smoothing=0.25)\n",
    "        self.FocalCosineLoss= L.FocalCosineLoss()\n",
    "        self.soft_ce= L.SoftCrossEntropyLoss(smooth_factor=0.25)\n",
    "        self.bi_temp= L.BiTemperedLogisticLoss(t1=0.8, t2=1.2)\n",
    "        self.bce= nn.BCELoss()\n",
    "        self.nll= nn.NLLLoss()\n",
    "    \n",
    "    def forward(self, y_pred, y_true):\n",
    "        loss= 1.0 * self.bce(y_pred, y_true)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f8f51ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(dataloader, model, criterion, optimizer):\n",
    "    scaler= amp.GradScaler()\n",
    "    model.train()\n",
    "\n",
    "    ep_loss= []\n",
    "    for i, data in enumerate(tqdm(dataloader)):\n",
    "\n",
    "        imgs= data['image'].to('cuda')\n",
    "        labels= data['label'].to('cuda')\n",
    "        \n",
    "        preds= model(imgs)\n",
    "        loss= criterion(preds, labels)\n",
    "        ep_loss.append(loss.item())\n",
    "        loss/= CFG['gradient_accumulation']\n",
    "        loss.backward()\n",
    "            \n",
    "        if (i+1) % CFG['gradient_accumulation']== 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "                \n",
    "    return np.mean(ep_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4efbece7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from metrics import *\n",
    "\n",
    "def valid_epoch(dataloader, model, criterion):\n",
    "    model.eval()\n",
    "    \n",
    "    ep_loss= []\n",
    "    all_pred= []\n",
    "    all_label= []\n",
    "    for i, data in enumerate(tqdm(dataloader)):\n",
    "\n",
    "        imgs= data['image'].to('cuda')\n",
    "        labels= data['label'].to('cuda')\n",
    "        all_label.extend(labels.cpu().numpy())\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            preds= model(imgs)\n",
    "            loss= criterion(preds, labels)\n",
    "            ep_loss.append(loss.item())\n",
    "        all_pred.extend(preds.cpu().numpy())\n",
    "        \n",
    "    \n",
    "    ## caculate metrics\n",
    "    all_label= np.array(all_label).argmax(1)\n",
    "    all_pred= np.array(all_pred)\n",
    "    \n",
    "    acc= Accuracy(all_pred, all_label)\n",
    "    print(f'accuracy: {acc}')\n",
    "    recall= Mean_Recall(all_pred, all_label)\n",
    "    print(f'mean_recall: {recall}')\n",
    "    \n",
    "    cmap= padded_cmap(all_pred, all_label)\n",
    "    print(f'cmap: {cmap}')\n",
    "    \n",
    "    score= cmap\n",
    "    return np.mean(ep_loss), score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1bde5f",
   "metadata": {},
   "source": [
    "# CFG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e809850e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adv_inception_v3',\n",
       " 'bat_resnext26ts.ch_in1k',\n",
       " 'beit_base_patch16_224.in22k_ft_in22k',\n",
       " 'beit_base_patch16_224.in22k_ft_in22k_in1k',\n",
       " 'beit_base_patch16_384.in22k_ft_in22k_in1k',\n",
       " 'beit_large_patch16_224.in22k_ft_in22k',\n",
       " 'beit_large_patch16_224.in22k_ft_in22k_in1k',\n",
       " 'beit_large_patch16_384.in22k_ft_in22k_in1k',\n",
       " 'beit_large_patch16_512.in22k_ft_in22k_in1k',\n",
       " 'beitv2_base_patch16_224.in1k_ft_in22k',\n",
       " 'beitv2_base_patch16_224.in1k_ft_in22k_in1k',\n",
       " 'beitv2_large_patch16_224.in1k_ft_in22k',\n",
       " 'beitv2_large_patch16_224.in1k_ft_in22k_in1k',\n",
       " 'botnet26t_256',\n",
       " 'cait_m36_384',\n",
       " 'cait_m48_448',\n",
       " 'cait_s24_224',\n",
       " 'cait_s24_384',\n",
       " 'cait_s36_384',\n",
       " 'cait_xs24_384',\n",
       " 'cait_xxs24_224',\n",
       " 'cait_xxs24_384',\n",
       " 'cait_xxs36_224',\n",
       " 'cait_xxs36_384',\n",
       " 'coat_lite_mini',\n",
       " 'coat_lite_small',\n",
       " 'coat_lite_tiny',\n",
       " 'coat_mini',\n",
       " 'coat_tiny',\n",
       " 'coatnet_0_rw_224.sw_in1k',\n",
       " 'coatnet_1_rw_224.sw_in1k',\n",
       " 'coatnet_2_rw_224.sw_in12k',\n",
       " 'coatnet_2_rw_224.sw_in12k_ft_in1k',\n",
       " 'coatnet_3_rw_224.sw_in12k',\n",
       " 'coatnet_bn_0_rw_224.sw_in1k',\n",
       " 'coatnet_nano_rw_224.sw_in1k',\n",
       " 'coatnet_rmlp_1_rw2_224.sw_in12k',\n",
       " 'coatnet_rmlp_1_rw2_224.sw_in12k_ft_in1k',\n",
       " 'coatnet_rmlp_1_rw_224.sw_in1k',\n",
       " 'coatnet_rmlp_2_rw_224.sw_in1k',\n",
       " 'coatnet_rmlp_2_rw_224.sw_in12k',\n",
       " 'coatnet_rmlp_2_rw_224.sw_in12k_ft_in1k',\n",
       " 'coatnet_rmlp_2_rw_384.sw_in12k_ft_in1k',\n",
       " 'coatnet_rmlp_nano_rw_224.sw_in1k',\n",
       " 'coatnext_nano_rw_224.sw_in1k',\n",
       " 'convit_base',\n",
       " 'convit_small',\n",
       " 'convit_tiny',\n",
       " 'convmixer_768_32',\n",
       " 'convmixer_1024_20_ks9_p14',\n",
       " 'convmixer_1536_20',\n",
       " 'convnext_atto.d2_in1k',\n",
       " 'convnext_atto_ols.a2_in1k',\n",
       " 'convnext_base.clip_laion2b',\n",
       " 'convnext_base.clip_laion2b_augreg',\n",
       " 'convnext_base.clip_laion2b_augreg_ft_in1k',\n",
       " 'convnext_base.clip_laiona',\n",
       " 'convnext_base.clip_laiona_320',\n",
       " 'convnext_base.clip_laiona_augreg_320',\n",
       " 'convnext_base.clip_laiona_augreg_ft_in1k_384',\n",
       " 'convnext_base.fb_in1k',\n",
       " 'convnext_base.fb_in22k',\n",
       " 'convnext_base.fb_in22k_ft_in1k',\n",
       " 'convnext_base.fb_in22k_ft_in1k_384',\n",
       " 'convnext_femto.d1_in1k',\n",
       " 'convnext_femto_ols.d1_in1k',\n",
       " 'convnext_large.fb_in1k',\n",
       " 'convnext_large.fb_in22k',\n",
       " 'convnext_large.fb_in22k_ft_in1k',\n",
       " 'convnext_large.fb_in22k_ft_in1k_384',\n",
       " 'convnext_large_mlp.clip_laion2b_augreg',\n",
       " 'convnext_large_mlp.clip_laion2b_augreg_ft_in1k',\n",
       " 'convnext_large_mlp.clip_laion2b_augreg_ft_in1k_384',\n",
       " 'convnext_large_mlp.clip_laion2b_ft_320',\n",
       " 'convnext_large_mlp.clip_laion2b_ft_soup_320',\n",
       " 'convnext_nano.d1h_in1k',\n",
       " 'convnext_nano.in12k',\n",
       " 'convnext_nano.in12k_ft_in1k',\n",
       " 'convnext_nano_ols.d1h_in1k',\n",
       " 'convnext_pico.d1_in1k',\n",
       " 'convnext_pico_ols.d1_in1k',\n",
       " 'convnext_small.fb_in1k',\n",
       " 'convnext_small.fb_in22k',\n",
       " 'convnext_small.fb_in22k_ft_in1k',\n",
       " 'convnext_small.fb_in22k_ft_in1k_384',\n",
       " 'convnext_small.in12k',\n",
       " 'convnext_small.in12k_ft_in1k',\n",
       " 'convnext_small.in12k_ft_in1k_384',\n",
       " 'convnext_tiny.fb_in1k',\n",
       " 'convnext_tiny.fb_in22k',\n",
       " 'convnext_tiny.fb_in22k_ft_in1k',\n",
       " 'convnext_tiny.fb_in22k_ft_in1k_384',\n",
       " 'convnext_tiny.in12k',\n",
       " 'convnext_tiny.in12k_ft_in1k',\n",
       " 'convnext_tiny.in12k_ft_in1k_384',\n",
       " 'convnext_tiny_hnf.a2h_in1k',\n",
       " 'convnext_xlarge.fb_in22k',\n",
       " 'convnext_xlarge.fb_in22k_ft_in1k',\n",
       " 'convnext_xlarge.fb_in22k_ft_in1k_384',\n",
       " 'convnext_xxlarge.clip_laion2b_rewind',\n",
       " 'convnext_xxlarge.clip_laion2b_soup',\n",
       " 'convnextv2_atto.fcmae',\n",
       " 'convnextv2_atto.fcmae_ft_in1k',\n",
       " 'convnextv2_base.fcmae',\n",
       " 'convnextv2_base.fcmae_ft_in1k',\n",
       " 'convnextv2_base.fcmae_ft_in22k_in1k',\n",
       " 'convnextv2_base.fcmae_ft_in22k_in1k_384',\n",
       " 'convnextv2_femto.fcmae',\n",
       " 'convnextv2_femto.fcmae_ft_in1k',\n",
       " 'convnextv2_huge.fcmae',\n",
       " 'convnextv2_huge.fcmae_ft_in1k',\n",
       " 'convnextv2_huge.fcmae_ft_in22k_in1k_384',\n",
       " 'convnextv2_huge.fcmae_ft_in22k_in1k_512',\n",
       " 'convnextv2_large.fcmae',\n",
       " 'convnextv2_large.fcmae_ft_in1k',\n",
       " 'convnextv2_large.fcmae_ft_in22k_in1k',\n",
       " 'convnextv2_large.fcmae_ft_in22k_in1k_384',\n",
       " 'convnextv2_nano.fcmae',\n",
       " 'convnextv2_nano.fcmae_ft_in1k',\n",
       " 'convnextv2_nano.fcmae_ft_in22k_in1k',\n",
       " 'convnextv2_nano.fcmae_ft_in22k_in1k_384',\n",
       " 'convnextv2_pico.fcmae',\n",
       " 'convnextv2_pico.fcmae_ft_in1k',\n",
       " 'convnextv2_tiny.fcmae',\n",
       " 'convnextv2_tiny.fcmae_ft_in1k',\n",
       " 'convnextv2_tiny.fcmae_ft_in22k_in1k',\n",
       " 'convnextv2_tiny.fcmae_ft_in22k_in1k_384',\n",
       " 'crossvit_9_240',\n",
       " 'crossvit_9_dagger_240',\n",
       " 'crossvit_15_240',\n",
       " 'crossvit_15_dagger_240',\n",
       " 'crossvit_15_dagger_408',\n",
       " 'crossvit_18_240',\n",
       " 'crossvit_18_dagger_240',\n",
       " 'crossvit_18_dagger_408',\n",
       " 'crossvit_base_240',\n",
       " 'crossvit_small_240',\n",
       " 'crossvit_tiny_240',\n",
       " 'cs3darknet_focus_l',\n",
       " 'cs3darknet_focus_m',\n",
       " 'cs3darknet_l',\n",
       " 'cs3darknet_m',\n",
       " 'cs3darknet_x',\n",
       " 'cs3edgenet_x',\n",
       " 'cs3se_edgenet_x',\n",
       " 'cs3sedarknet_l',\n",
       " 'cs3sedarknet_x',\n",
       " 'cspdarknet53',\n",
       " 'cspresnet50',\n",
       " 'cspresnext50',\n",
       " 'darknet53',\n",
       " 'darknetaa53',\n",
       " 'davit_base.msft_in1k',\n",
       " 'davit_small.msft_in1k',\n",
       " 'davit_tiny.msft_in1k',\n",
       " 'deit3_base_patch16_224.fb_in1k',\n",
       " 'deit3_base_patch16_224.fb_in22k_ft_in1k',\n",
       " 'deit3_base_patch16_384.fb_in1k',\n",
       " 'deit3_base_patch16_384.fb_in22k_ft_in1k',\n",
       " 'deit3_huge_patch14_224.fb_in1k',\n",
       " 'deit3_huge_patch14_224.fb_in22k_ft_in1k',\n",
       " 'deit3_large_patch16_224.fb_in1k',\n",
       " 'deit3_large_patch16_224.fb_in22k_ft_in1k',\n",
       " 'deit3_large_patch16_384.fb_in1k',\n",
       " 'deit3_large_patch16_384.fb_in22k_ft_in1k',\n",
       " 'deit3_medium_patch16_224.fb_in1k',\n",
       " 'deit3_medium_patch16_224.fb_in22k_ft_in1k',\n",
       " 'deit3_small_patch16_224.fb_in1k',\n",
       " 'deit3_small_patch16_224.fb_in22k_ft_in1k',\n",
       " 'deit3_small_patch16_384.fb_in1k',\n",
       " 'deit3_small_patch16_384.fb_in22k_ft_in1k',\n",
       " 'deit_base_distilled_patch16_224.fb_in1k',\n",
       " 'deit_base_distilled_patch16_384.fb_in1k',\n",
       " 'deit_base_patch16_224.fb_in1k',\n",
       " 'deit_base_patch16_384.fb_in1k',\n",
       " 'deit_small_distilled_patch16_224.fb_in1k',\n",
       " 'deit_small_patch16_224.fb_in1k',\n",
       " 'deit_tiny_distilled_patch16_224.fb_in1k',\n",
       " 'deit_tiny_patch16_224.fb_in1k',\n",
       " 'densenet121',\n",
       " 'densenet161',\n",
       " 'densenet169',\n",
       " 'densenet201',\n",
       " 'densenetblur121d',\n",
       " 'dla34',\n",
       " 'dla46_c',\n",
       " 'dla46x_c',\n",
       " 'dla60',\n",
       " 'dla60_res2net',\n",
       " 'dla60_res2next',\n",
       " 'dla60x',\n",
       " 'dla60x_c',\n",
       " 'dla102',\n",
       " 'dla102x',\n",
       " 'dla102x2',\n",
       " 'dla169',\n",
       " 'dm_nfnet_f0.dm_in1k',\n",
       " 'dm_nfnet_f1.dm_in1k',\n",
       " 'dm_nfnet_f2.dm_in1k',\n",
       " 'dm_nfnet_f3.dm_in1k',\n",
       " 'dm_nfnet_f4.dm_in1k',\n",
       " 'dm_nfnet_f5.dm_in1k',\n",
       " 'dm_nfnet_f6.dm_in1k',\n",
       " 'dpn68',\n",
       " 'dpn68b',\n",
       " 'dpn92',\n",
       " 'dpn98',\n",
       " 'dpn107',\n",
       " 'dpn131',\n",
       " 'eca_botnext26ts_256',\n",
       " 'eca_halonext26ts',\n",
       " 'eca_nfnet_l0.ra2_in1k',\n",
       " 'eca_nfnet_l1.ra2_in1k',\n",
       " 'eca_nfnet_l2.ra3_in1k',\n",
       " 'eca_resnet33ts.ra2_in1k',\n",
       " 'eca_resnext26ts.ch_in1k',\n",
       " 'ecaresnet26t',\n",
       " 'ecaresnet50d',\n",
       " 'ecaresnet50d_pruned',\n",
       " 'ecaresnet50t',\n",
       " 'ecaresnet101d',\n",
       " 'ecaresnet101d_pruned',\n",
       " 'ecaresnet269d',\n",
       " 'ecaresnetlight',\n",
       " 'edgenext_base',\n",
       " 'edgenext_small',\n",
       " 'edgenext_small_rw',\n",
       " 'edgenext_x_small',\n",
       " 'edgenext_xx_small',\n",
       " 'efficientformer_l1.snap_dist_in1k',\n",
       " 'efficientformer_l3.snap_dist_in1k',\n",
       " 'efficientformer_l7.snap_dist_in1k',\n",
       " 'efficientformerv2_l.snap_dist_in1k',\n",
       " 'efficientformerv2_s0.snap_dist_in1k',\n",
       " 'efficientformerv2_s1.snap_dist_in1k',\n",
       " 'efficientformerv2_s2.snap_dist_in1k',\n",
       " 'efficientnet_b0.ra_in1k',\n",
       " 'efficientnet_b1.ft_in1k',\n",
       " 'efficientnet_b1_pruned.in1k',\n",
       " 'efficientnet_b2.ra_in1k',\n",
       " 'efficientnet_b2_pruned.in1k',\n",
       " 'efficientnet_b3.ra2_in1k',\n",
       " 'efficientnet_b3_pruned.in1k',\n",
       " 'efficientnet_b4.ra2_in1k',\n",
       " 'efficientnet_b5.in12k',\n",
       " 'efficientnet_b5.in12k_ft_in1k',\n",
       " 'efficientnet_el.ra_in1k',\n",
       " 'efficientnet_el_pruned.in1k',\n",
       " 'efficientnet_em.ra2_in1k',\n",
       " 'efficientnet_es.ra_in1k',\n",
       " 'efficientnet_es_pruned.in1k',\n",
       " 'efficientnet_lite0.ra_in1k',\n",
       " 'efficientnetv2_rw_m.agc_in1k',\n",
       " 'efficientnetv2_rw_s.ra2_in1k',\n",
       " 'efficientnetv2_rw_t.ra2_in1k',\n",
       " 'ens_adv_inception_resnet_v2',\n",
       " 'ese_vovnet19b_dw',\n",
       " 'ese_vovnet39b',\n",
       " 'eva_giant_patch14_224.clip_ft_in1k',\n",
       " 'eva_giant_patch14_336.clip_ft_in1k',\n",
       " 'eva_giant_patch14_336.m30m_ft_in22k_in1k',\n",
       " 'eva_giant_patch14_560.m30m_ft_in22k_in1k',\n",
       " 'eva_large_patch14_196.in22k_ft_in1k',\n",
       " 'eva_large_patch14_196.in22k_ft_in22k_in1k',\n",
       " 'eva_large_patch14_336.in22k_ft_in1k',\n",
       " 'eva_large_patch14_336.in22k_ft_in22k_in1k',\n",
       " 'fbnetc_100.rmsp_in1k',\n",
       " 'fbnetv3_b.ra2_in1k',\n",
       " 'fbnetv3_d.ra2_in1k',\n",
       " 'fbnetv3_g.ra2_in1k',\n",
       " 'flexivit_base.300ep_in1k',\n",
       " 'flexivit_base.300ep_in21k',\n",
       " 'flexivit_base.600ep_in1k',\n",
       " 'flexivit_base.1000ep_in21k',\n",
       " 'flexivit_base.1200ep_in1k',\n",
       " 'flexivit_base.patch16_in21k',\n",
       " 'flexivit_base.patch30_in21k',\n",
       " 'flexivit_large.300ep_in1k',\n",
       " 'flexivit_large.600ep_in1k',\n",
       " 'flexivit_large.1200ep_in1k',\n",
       " 'flexivit_small.300ep_in1k',\n",
       " 'flexivit_small.600ep_in1k',\n",
       " 'flexivit_small.1200ep_in1k',\n",
       " 'focalnet_base_lrf.ms_in1k',\n",
       " 'focalnet_base_srf.ms_in1k',\n",
       " 'focalnet_huge_fl3.ms_in22k',\n",
       " 'focalnet_huge_fl4.ms_in22k',\n",
       " 'focalnet_large_fl3.ms_in22k',\n",
       " 'focalnet_large_fl4.ms_in22k',\n",
       " 'focalnet_small_lrf.ms_in1k',\n",
       " 'focalnet_small_srf.ms_in1k',\n",
       " 'focalnet_tiny_lrf.ms_in1k',\n",
       " 'focalnet_tiny_srf.ms_in1k',\n",
       " 'focalnet_xlarge_fl3.ms_in22k',\n",
       " 'focalnet_xlarge_fl4.ms_in22k',\n",
       " 'gc_efficientnetv2_rw_t.agc_in1k',\n",
       " 'gcresnet33ts.ra2_in1k',\n",
       " 'gcresnet50t.ra2_in1k',\n",
       " 'gcresnext26ts.ch_in1k',\n",
       " 'gcresnext50ts.ch_in1k',\n",
       " 'gcvit_base',\n",
       " 'gcvit_small',\n",
       " 'gcvit_tiny',\n",
       " 'gcvit_xtiny',\n",
       " 'gcvit_xxtiny',\n",
       " 'gernet_l.idstcv_in1k',\n",
       " 'gernet_m.idstcv_in1k',\n",
       " 'gernet_s.idstcv_in1k',\n",
       " 'ghostnet_100',\n",
       " 'gluon_inception_v3',\n",
       " 'gluon_resnet18_v1b',\n",
       " 'gluon_resnet34_v1b',\n",
       " 'gluon_resnet50_v1b',\n",
       " 'gluon_resnet50_v1c',\n",
       " 'gluon_resnet50_v1d',\n",
       " 'gluon_resnet50_v1s',\n",
       " 'gluon_resnet101_v1b',\n",
       " 'gluon_resnet101_v1c',\n",
       " 'gluon_resnet101_v1d',\n",
       " 'gluon_resnet101_v1s',\n",
       " 'gluon_resnet152_v1b',\n",
       " 'gluon_resnet152_v1c',\n",
       " 'gluon_resnet152_v1d',\n",
       " 'gluon_resnet152_v1s',\n",
       " 'gluon_resnext50_32x4d',\n",
       " 'gluon_resnext101_32x4d',\n",
       " 'gluon_resnext101_64x4d',\n",
       " 'gluon_senet154',\n",
       " 'gluon_seresnext50_32x4d',\n",
       " 'gluon_seresnext101_32x4d',\n",
       " 'gluon_seresnext101_64x4d',\n",
       " 'gluon_xception65',\n",
       " 'gmixer_24_224.ra3_in1k',\n",
       " 'gmlp_s16_224.ra3_in1k',\n",
       " 'halo2botnet50ts_256',\n",
       " 'halonet26t',\n",
       " 'halonet50ts',\n",
       " 'haloregnetz_b',\n",
       " 'hardcorenas_a',\n",
       " 'hardcorenas_b',\n",
       " 'hardcorenas_c',\n",
       " 'hardcorenas_d',\n",
       " 'hardcorenas_e',\n",
       " 'hardcorenas_f',\n",
       " 'hrnet_w18',\n",
       " 'hrnet_w18_small',\n",
       " 'hrnet_w18_small_v2',\n",
       " 'hrnet_w30',\n",
       " 'hrnet_w32',\n",
       " 'hrnet_w40',\n",
       " 'hrnet_w44',\n",
       " 'hrnet_w48',\n",
       " 'hrnet_w64',\n",
       " 'ig_resnext101_32x8d',\n",
       " 'ig_resnext101_32x16d',\n",
       " 'ig_resnext101_32x32d',\n",
       " 'ig_resnext101_32x48d',\n",
       " 'inception_resnet_v2',\n",
       " 'inception_v3',\n",
       " 'inception_v4',\n",
       " 'jx_nest_base',\n",
       " 'jx_nest_small',\n",
       " 'jx_nest_tiny',\n",
       " 'lambda_resnet26rpt_256',\n",
       " 'lambda_resnet26t',\n",
       " 'lambda_resnet50ts',\n",
       " 'lamhalobotnet50ts_256',\n",
       " 'lcnet_050.ra2_in1k',\n",
       " 'lcnet_075.ra2_in1k',\n",
       " 'lcnet_100.ra2_in1k',\n",
       " 'legacy_senet154',\n",
       " 'legacy_seresnet18',\n",
       " 'legacy_seresnet34',\n",
       " 'legacy_seresnet50',\n",
       " 'legacy_seresnet101',\n",
       " 'legacy_seresnet152',\n",
       " 'legacy_seresnext26_32x4d',\n",
       " 'legacy_seresnext50_32x4d',\n",
       " 'legacy_seresnext101_32x4d',\n",
       " 'levit_128.fb_dist_in1k',\n",
       " 'levit_128s.fb_dist_in1k',\n",
       " 'levit_192.fb_dist_in1k',\n",
       " 'levit_256.fb_dist_in1k',\n",
       " 'levit_384.fb_dist_in1k',\n",
       " 'levit_conv_128.fb_dist_in1k',\n",
       " 'levit_conv_128s.fb_dist_in1k',\n",
       " 'levit_conv_192.fb_dist_in1k',\n",
       " 'levit_conv_256.fb_dist_in1k',\n",
       " 'levit_conv_384.fb_dist_in1k',\n",
       " 'maxvit_base_tf_224.in1k',\n",
       " 'maxvit_base_tf_384.in1k',\n",
       " 'maxvit_base_tf_384.in21k_ft_in1k',\n",
       " 'maxvit_base_tf_512.in1k',\n",
       " 'maxvit_base_tf_512.in21k_ft_in1k',\n",
       " 'maxvit_large_tf_224.in1k',\n",
       " 'maxvit_large_tf_384.in1k',\n",
       " 'maxvit_large_tf_384.in21k_ft_in1k',\n",
       " 'maxvit_large_tf_512.in1k',\n",
       " 'maxvit_large_tf_512.in21k_ft_in1k',\n",
       " 'maxvit_nano_rw_256.sw_in1k',\n",
       " 'maxvit_rmlp_base_rw_224.sw_in12k',\n",
       " 'maxvit_rmlp_base_rw_224.sw_in12k_ft_in1k',\n",
       " 'maxvit_rmlp_base_rw_384.sw_in12k_ft_in1k',\n",
       " 'maxvit_rmlp_nano_rw_256.sw_in1k',\n",
       " 'maxvit_rmlp_pico_rw_256.sw_in1k',\n",
       " 'maxvit_rmlp_small_rw_224.sw_in1k',\n",
       " 'maxvit_rmlp_tiny_rw_256.sw_in1k',\n",
       " 'maxvit_small_tf_224.in1k',\n",
       " 'maxvit_small_tf_384.in1k',\n",
       " 'maxvit_small_tf_512.in1k',\n",
       " 'maxvit_tiny_rw_224.sw_in1k',\n",
       " 'maxvit_tiny_tf_224.in1k',\n",
       " 'maxvit_tiny_tf_384.in1k',\n",
       " 'maxvit_tiny_tf_512.in1k',\n",
       " 'maxvit_xlarge_tf_384.in21k_ft_in1k',\n",
       " 'maxvit_xlarge_tf_512.in21k_ft_in1k',\n",
       " 'maxxvit_rmlp_nano_rw_256.sw_in1k',\n",
       " 'maxxvit_rmlp_small_rw_256.sw_in1k',\n",
       " 'maxxvitv2_nano_rw_256.sw_in1k',\n",
       " 'maxxvitv2_rmlp_base_rw_224.sw_in12k',\n",
       " 'maxxvitv2_rmlp_base_rw_224.sw_in12k_ft_in1k',\n",
       " 'maxxvitv2_rmlp_base_rw_384.sw_in12k_ft_in1k',\n",
       " 'mixer_b16_224.goog_in21k',\n",
       " 'mixer_b16_224.goog_in21k_ft_in1k',\n",
       " 'mixer_b16_224.miil_in21k',\n",
       " 'mixer_b16_224.miil_in21k_ft_in1k',\n",
       " 'mixer_l16_224.goog_in21k',\n",
       " 'mixer_l16_224.goog_in21k_ft_in1k',\n",
       " 'mixnet_l.ft_in1k',\n",
       " 'mixnet_m.ft_in1k',\n",
       " 'mixnet_s.ft_in1k',\n",
       " 'mixnet_xl.ra_in1k',\n",
       " 'mnasnet_100.rmsp_in1k',\n",
       " 'mnasnet_small.lamb_in1k',\n",
       " 'mobilenetv2_050.lamb_in1k',\n",
       " 'mobilenetv2_100.ra_in1k',\n",
       " 'mobilenetv2_110d.ra_in1k',\n",
       " 'mobilenetv2_120d.ra_in1k',\n",
       " 'mobilenetv2_140.ra_in1k',\n",
       " 'mobilenetv3_large_100.miil_in21k',\n",
       " 'mobilenetv3_large_100.miil_in21k_ft_in1k',\n",
       " 'mobilenetv3_large_100.ra_in1k',\n",
       " 'mobilenetv3_rw.rmsp_in1k',\n",
       " 'mobilenetv3_small_050.lamb_in1k',\n",
       " 'mobilenetv3_small_075.lamb_in1k',\n",
       " 'mobilenetv3_small_100.lamb_in1k',\n",
       " 'mobilevit_s',\n",
       " 'mobilevit_xs',\n",
       " 'mobilevit_xxs',\n",
       " 'mobilevitv2_050',\n",
       " 'mobilevitv2_075',\n",
       " 'mobilevitv2_100',\n",
       " 'mobilevitv2_125',\n",
       " 'mobilevitv2_150',\n",
       " 'mobilevitv2_150_384_in22ft1k',\n",
       " 'mobilevitv2_150_in22ft1k',\n",
       " 'mobilevitv2_175',\n",
       " 'mobilevitv2_175_384_in22ft1k',\n",
       " 'mobilevitv2_175_in22ft1k',\n",
       " 'mobilevitv2_200',\n",
       " 'mobilevitv2_200_384_in22ft1k',\n",
       " 'mobilevitv2_200_in22ft1k',\n",
       " 'mvitv2_base',\n",
       " 'mvitv2_large',\n",
       " 'mvitv2_small',\n",
       " 'mvitv2_tiny',\n",
       " 'nasnetalarge',\n",
       " 'nf_regnet_b1.ra2_in1k',\n",
       " 'nf_resnet50.ra2_in1k',\n",
       " 'nfnet_l0.ra2_in1k',\n",
       " 'pit_b_224',\n",
       " 'pit_b_distilled_224',\n",
       " 'pit_s_224',\n",
       " 'pit_s_distilled_224',\n",
       " 'pit_ti_224',\n",
       " 'pit_ti_distilled_224',\n",
       " 'pit_xs_224',\n",
       " 'pit_xs_distilled_224',\n",
       " 'pnasnet5large',\n",
       " 'poolformer_m36',\n",
       " 'poolformer_m48',\n",
       " 'poolformer_s12',\n",
       " 'poolformer_s24',\n",
       " 'poolformer_s36',\n",
       " 'pvt_v2_b0',\n",
       " 'pvt_v2_b1',\n",
       " 'pvt_v2_b2',\n",
       " 'pvt_v2_b2_li',\n",
       " 'pvt_v2_b3',\n",
       " 'pvt_v2_b4',\n",
       " 'pvt_v2_b5',\n",
       " 'regnetv_040.ra3_in1k',\n",
       " 'regnetv_064.ra3_in1k',\n",
       " 'regnetx_002.pycls_in1k',\n",
       " 'regnetx_004.pycls_in1k',\n",
       " 'regnetx_004_tv.tv2_in1k',\n",
       " 'regnetx_006.pycls_in1k',\n",
       " 'regnetx_008.pycls_in1k',\n",
       " 'regnetx_008.tv2_in1k',\n",
       " 'regnetx_016.pycls_in1k',\n",
       " 'regnetx_016.tv2_in1k',\n",
       " 'regnetx_032.pycls_in1k',\n",
       " 'regnetx_032.tv2_in1k',\n",
       " 'regnetx_040.pycls_in1k',\n",
       " 'regnetx_064.pycls_in1k',\n",
       " 'regnetx_080.pycls_in1k',\n",
       " 'regnetx_080.tv2_in1k',\n",
       " 'regnetx_120.pycls_in1k',\n",
       " 'regnetx_160.pycls_in1k',\n",
       " 'regnetx_160.tv2_in1k',\n",
       " 'regnetx_320.pycls_in1k',\n",
       " 'regnetx_320.tv2_in1k',\n",
       " 'regnety_002.pycls_in1k',\n",
       " 'regnety_004.pycls_in1k',\n",
       " 'regnety_004.tv2_in1k',\n",
       " 'regnety_006.pycls_in1k',\n",
       " 'regnety_008.pycls_in1k',\n",
       " 'regnety_008_tv.tv2_in1k',\n",
       " 'regnety_016.pycls_in1k',\n",
       " 'regnety_016.tv2_in1k',\n",
       " 'regnety_032.pycls_in1k',\n",
       " 'regnety_032.ra_in1k',\n",
       " 'regnety_032.tv2_in1k',\n",
       " 'regnety_040.pycls_in1k',\n",
       " 'regnety_040.ra3_in1k',\n",
       " 'regnety_064.pycls_in1k',\n",
       " 'regnety_064.ra3_in1k',\n",
       " 'regnety_080.pycls_in1k',\n",
       " 'regnety_080.ra3_in1k',\n",
       " 'regnety_080_tv.tv2_in1k',\n",
       " 'regnety_120.pycls_in1k',\n",
       " 'regnety_120.sw_in12k',\n",
       " 'regnety_120.sw_in12k_ft_in1k',\n",
       " 'regnety_160.deit_in1k',\n",
       " 'regnety_160.lion_in12k_ft_in1k',\n",
       " 'regnety_160.pycls_in1k',\n",
       " 'regnety_160.sw_in12k',\n",
       " 'regnety_160.sw_in12k_ft_in1k',\n",
       " 'regnety_160.swag_ft_in1k',\n",
       " 'regnety_160.swag_lc_in1k',\n",
       " 'regnety_160.tv2_in1k',\n",
       " 'regnety_320.pycls_in1k',\n",
       " 'regnety_320.seer',\n",
       " 'regnety_320.seer_ft_in1k',\n",
       " 'regnety_320.swag_ft_in1k',\n",
       " 'regnety_320.swag_lc_in1k',\n",
       " 'regnety_320.tv2_in1k',\n",
       " 'regnety_640.seer',\n",
       " 'regnety_640.seer_ft_in1k',\n",
       " 'regnety_1280.seer',\n",
       " 'regnety_1280.seer_ft_in1k',\n",
       " 'regnety_1280.swag_ft_in1k',\n",
       " 'regnety_1280.swag_lc_in1k',\n",
       " 'regnety_2560.seer_ft_in1k',\n",
       " 'regnetz_040.ra3_in1k',\n",
       " 'regnetz_040_h.ra3_in1k',\n",
       " 'regnetz_b16.ra3_in1k',\n",
       " 'regnetz_c16.ra3_in1k',\n",
       " 'regnetz_c16_evos.ch_in1k',\n",
       " 'regnetz_d8.ra3_in1k',\n",
       " 'regnetz_d8_evos.ch_in1k',\n",
       " 'regnetz_d32.ra3_in1k',\n",
       " 'regnetz_e8.ra3_in1k',\n",
       " 'repvgg_a2.rvgg_in1k',\n",
       " 'repvgg_b0.rvgg_in1k',\n",
       " 'repvgg_b1.rvgg_in1k',\n",
       " 'repvgg_b1g4.rvgg_in1k',\n",
       " 'repvgg_b2.rvgg_in1k',\n",
       " 'repvgg_b2g4.rvgg_in1k',\n",
       " 'repvgg_b3.rvgg_in1k',\n",
       " 'repvgg_b3g4.rvgg_in1k',\n",
       " 'res2net50_14w_8s',\n",
       " 'res2net50_26w_4s',\n",
       " 'res2net50_26w_6s',\n",
       " 'res2net50_26w_8s',\n",
       " 'res2net50_48w_2s',\n",
       " 'res2net101_26w_4s',\n",
       " 'res2next50',\n",
       " 'resmlp_12_224.fb_dino',\n",
       " 'resmlp_12_224.fb_distilled_in1k',\n",
       " 'resmlp_12_224.fb_in1k',\n",
       " 'resmlp_24_224.fb_dino',\n",
       " 'resmlp_24_224.fb_distilled_in1k',\n",
       " 'resmlp_24_224.fb_in1k',\n",
       " 'resmlp_36_224.fb_distilled_in1k',\n",
       " 'resmlp_36_224.fb_in1k',\n",
       " 'resmlp_big_24_224.fb_distilled_in1k',\n",
       " 'resmlp_big_24_224.fb_in1k',\n",
       " 'resmlp_big_24_224.fb_in22k_ft_in1k',\n",
       " 'resnest14d',\n",
       " 'resnest26d',\n",
       " 'resnest50d',\n",
       " 'resnest50d_1s4x24d',\n",
       " 'resnest50d_4s2x40d',\n",
       " 'resnest101e',\n",
       " 'resnest200e',\n",
       " 'resnest269e',\n",
       " 'resnet10t',\n",
       " 'resnet14t',\n",
       " 'resnet18',\n",
       " 'resnet18d',\n",
       " 'resnet26',\n",
       " 'resnet26d',\n",
       " 'resnet26t',\n",
       " 'resnet32ts.ra2_in1k',\n",
       " 'resnet33ts.ra2_in1k',\n",
       " 'resnet34',\n",
       " 'resnet34d',\n",
       " 'resnet50',\n",
       " 'resnet50_gn',\n",
       " 'resnet50d',\n",
       " 'resnet51q.ra2_in1k',\n",
       " 'resnet61q.ra2_in1k',\n",
       " 'resnet101',\n",
       " 'resnet101d',\n",
       " 'resnet152',\n",
       " 'resnet152d',\n",
       " 'resnet200d',\n",
       " 'resnetaa50',\n",
       " 'resnetblur50',\n",
       " 'resnetrs50',\n",
       " 'resnetrs101',\n",
       " 'resnetrs152',\n",
       " 'resnetrs200',\n",
       " 'resnetrs270',\n",
       " 'resnetrs350',\n",
       " 'resnetrs420',\n",
       " 'resnetv2_50.a1h_in1k',\n",
       " 'resnetv2_50d_evos.ah_in1k',\n",
       " 'resnetv2_50d_gn.ah_in1k',\n",
       " 'resnetv2_50x1_bit.goog_distilled_in1k',\n",
       " 'resnetv2_50x1_bit.goog_in21k',\n",
       " 'resnetv2_50x1_bit.goog_in21k_ft_in1k',\n",
       " 'resnetv2_50x3_bit.goog_in21k',\n",
       " 'resnetv2_50x3_bit.goog_in21k_ft_in1k',\n",
       " 'resnetv2_101.a1h_in1k',\n",
       " 'resnetv2_101x1_bit.goog_in21k',\n",
       " 'resnetv2_101x1_bit.goog_in21k_ft_in1k',\n",
       " 'resnetv2_101x3_bit.goog_in21k',\n",
       " 'resnetv2_101x3_bit.goog_in21k_ft_in1k',\n",
       " 'resnetv2_152x2_bit.goog_in21k',\n",
       " 'resnetv2_152x2_bit.goog_in21k_ft_in1k',\n",
       " 'resnetv2_152x2_bit.goog_teacher_in21k_ft_in1k',\n",
       " 'resnetv2_152x2_bit.goog_teacher_in21k_ft_in1k_384',\n",
       " 'resnetv2_152x4_bit.goog_in21k',\n",
       " 'resnetv2_152x4_bit.goog_in21k_ft_in1k',\n",
       " 'resnext26ts.ra2_in1k',\n",
       " 'resnext50_32x4d',\n",
       " 'resnext50d_32x4d',\n",
       " 'resnext101_32x8d',\n",
       " 'resnext101_64x4d',\n",
       " 'rexnet_100.nav_in1k',\n",
       " 'rexnet_130.nav_in1k',\n",
       " 'rexnet_150.nav_in1k',\n",
       " 'rexnet_200.nav_in1k',\n",
       " 'rexnet_300.nav_in1k',\n",
       " 'rexnetr_200.sw_in12k',\n",
       " 'rexnetr_200.sw_in12k_ft_in1k',\n",
       " 'rexnetr_300.sw_in12k',\n",
       " 'rexnetr_300.sw_in12k_ft_in1k',\n",
       " 'sebotnet33ts_256',\n",
       " 'sehalonet33ts',\n",
       " 'selecsls42b',\n",
       " 'selecsls60',\n",
       " 'selecsls60b',\n",
       " 'semnasnet_075.rmsp_in1k',\n",
       " 'semnasnet_100.rmsp_in1k',\n",
       " 'sequencer2d_l',\n",
       " 'sequencer2d_m',\n",
       " 'sequencer2d_s',\n",
       " 'seresnet33ts.ra2_in1k',\n",
       " 'seresnet50',\n",
       " 'seresnet152d',\n",
       " 'seresnext26d_32x4d',\n",
       " 'seresnext26t_32x4d',\n",
       " 'seresnext26ts.ch_in1k',\n",
       " 'seresnext50_32x4d',\n",
       " 'seresnext101_32x8d',\n",
       " 'seresnext101d_32x8d',\n",
       " 'seresnextaa101d_32x8d',\n",
       " 'skresnet18',\n",
       " 'skresnet34',\n",
       " 'skresnext50_32x4d',\n",
       " 'spnasnet_100.rmsp_in1k',\n",
       " 'ssl_resnet18',\n",
       " 'ssl_resnet50',\n",
       " 'ssl_resnext50_32x4d',\n",
       " 'ssl_resnext101_32x4d',\n",
       " 'ssl_resnext101_32x8d',\n",
       " 'ssl_resnext101_32x16d',\n",
       " 'swin_base_patch4_window7_224.ms_in1k',\n",
       " 'swin_base_patch4_window7_224.ms_in22k',\n",
       " 'swin_base_patch4_window7_224.ms_in22k_ft_in1k',\n",
       " 'swin_base_patch4_window12_384.ms_in1k',\n",
       " 'swin_base_patch4_window12_384.ms_in22k',\n",
       " 'swin_base_patch4_window12_384.ms_in22k_ft_in1k',\n",
       " 'swin_large_patch4_window7_224.ms_in22k',\n",
       " 'swin_large_patch4_window7_224.ms_in22k_ft_in1k',\n",
       " 'swin_large_patch4_window12_384.ms_in22k',\n",
       " 'swin_large_patch4_window12_384.ms_in22k_ft_in1k',\n",
       " 'swin_s3_base_224.ms_in1k',\n",
       " 'swin_s3_small_224.ms_in1k',\n",
       " 'swin_s3_tiny_224.ms_in1k',\n",
       " 'swin_small_patch4_window7_224.ms_in1k',\n",
       " 'swin_small_patch4_window7_224.ms_in22k',\n",
       " 'swin_small_patch4_window7_224.ms_in22k_ft_in1k',\n",
       " 'swin_tiny_patch4_window7_224.ms_in1k',\n",
       " 'swin_tiny_patch4_window7_224.ms_in22k',\n",
       " 'swin_tiny_patch4_window7_224.ms_in22k_ft_in1k',\n",
       " 'swinv2_base_window8_256.ms_in1k',\n",
       " 'swinv2_base_window12_192.ms_in22k',\n",
       " 'swinv2_base_window12to16_192to256.ms_in22k_ft_in1k',\n",
       " 'swinv2_base_window12to24_192to384.ms_in22k_ft_in1k',\n",
       " 'swinv2_base_window16_256.ms_in1k',\n",
       " 'swinv2_cr_small_224.sw_in1k',\n",
       " 'swinv2_cr_small_ns_224.sw_in1k',\n",
       " 'swinv2_cr_tiny_ns_224.sw_in1k',\n",
       " 'swinv2_large_window12_192.ms_in22k',\n",
       " 'swinv2_large_window12to16_192to256.ms_in22k_ft_in1k',\n",
       " 'swinv2_large_window12to24_192to384.ms_in22k_ft_in1k',\n",
       " 'swinv2_small_window8_256.ms_in1k',\n",
       " 'swinv2_small_window16_256.ms_in1k',\n",
       " 'swinv2_tiny_window8_256.ms_in1k',\n",
       " 'swinv2_tiny_window16_256.ms_in1k',\n",
       " 'swsl_resnet18',\n",
       " 'swsl_resnet50',\n",
       " 'swsl_resnext50_32x4d',\n",
       " 'swsl_resnext101_32x4d',\n",
       " 'swsl_resnext101_32x8d',\n",
       " 'swsl_resnext101_32x16d',\n",
       " 'tf_efficientnet_b0.aa_in1k',\n",
       " 'tf_efficientnet_b0.ap_in1k',\n",
       " 'tf_efficientnet_b0.ns_jft_in1k',\n",
       " 'tf_efficientnet_b1.aa_in1k',\n",
       " 'tf_efficientnet_b1.ap_in1k',\n",
       " 'tf_efficientnet_b1.ns_jft_in1k',\n",
       " 'tf_efficientnet_b2.aa_in1k',\n",
       " 'tf_efficientnet_b2.ap_in1k',\n",
       " 'tf_efficientnet_b2.ns_jft_in1k',\n",
       " 'tf_efficientnet_b3.aa_in1k',\n",
       " 'tf_efficientnet_b3.ap_in1k',\n",
       " 'tf_efficientnet_b3.ns_jft_in1k',\n",
       " 'tf_efficientnet_b4.aa_in1k',\n",
       " 'tf_efficientnet_b4.ap_in1k',\n",
       " 'tf_efficientnet_b4.ns_jft_in1k',\n",
       " 'tf_efficientnet_b5.ap_in1k',\n",
       " 'tf_efficientnet_b5.ns_jft_in1k',\n",
       " 'tf_efficientnet_b5.ra_in1k',\n",
       " 'tf_efficientnet_b6.aa_in1k',\n",
       " 'tf_efficientnet_b6.ap_in1k',\n",
       " 'tf_efficientnet_b6.ns_jft_in1k',\n",
       " 'tf_efficientnet_b7.ap_in1k',\n",
       " 'tf_efficientnet_b7.ns_jft_in1k',\n",
       " 'tf_efficientnet_b7.ra_in1k',\n",
       " 'tf_efficientnet_b8.ap_in1k',\n",
       " 'tf_efficientnet_b8.ra_in1k',\n",
       " 'tf_efficientnet_cc_b0_4e.in1k',\n",
       " 'tf_efficientnet_cc_b0_8e.in1k',\n",
       " 'tf_efficientnet_cc_b1_8e.in1k',\n",
       " 'tf_efficientnet_el.in1k',\n",
       " 'tf_efficientnet_em.in1k',\n",
       " 'tf_efficientnet_es.in1k',\n",
       " 'tf_efficientnet_l2.ns_jft_in1k',\n",
       " 'tf_efficientnet_l2.ns_jft_in1k_475',\n",
       " 'tf_efficientnet_lite0.in1k',\n",
       " 'tf_efficientnet_lite1.in1k',\n",
       " 'tf_efficientnet_lite2.in1k',\n",
       " 'tf_efficientnet_lite3.in1k',\n",
       " 'tf_efficientnet_lite4.in1k',\n",
       " 'tf_efficientnetv2_b0.in1k',\n",
       " 'tf_efficientnetv2_b1.in1k',\n",
       " 'tf_efficientnetv2_b2.in1k',\n",
       " 'tf_efficientnetv2_b3.in1k',\n",
       " 'tf_efficientnetv2_b3.in21k',\n",
       " 'tf_efficientnetv2_b3.in21k_ft_in1k',\n",
       " 'tf_efficientnetv2_l.in1k',\n",
       " 'tf_efficientnetv2_l.in21k',\n",
       " 'tf_efficientnetv2_l.in21k_ft_in1k',\n",
       " 'tf_efficientnetv2_m.in1k',\n",
       " 'tf_efficientnetv2_m.in21k',\n",
       " 'tf_efficientnetv2_m.in21k_ft_in1k',\n",
       " 'tf_efficientnetv2_s.in1k',\n",
       " 'tf_efficientnetv2_s.in21k',\n",
       " 'tf_efficientnetv2_s.in21k_ft_in1k',\n",
       " 'tf_efficientnetv2_xl.in21k',\n",
       " 'tf_efficientnetv2_xl.in21k_ft_in1k',\n",
       " 'tf_inception_v3',\n",
       " 'tf_mixnet_l.in1k',\n",
       " 'tf_mixnet_m.in1k',\n",
       " 'tf_mixnet_s.in1k',\n",
       " 'tf_mobilenetv3_large_075.in1k',\n",
       " 'tf_mobilenetv3_large_100.in1k',\n",
       " 'tf_mobilenetv3_large_minimal_100.in1k',\n",
       " 'tf_mobilenetv3_small_075.in1k',\n",
       " 'tf_mobilenetv3_small_100.in1k',\n",
       " 'tf_mobilenetv3_small_minimal_100.in1k',\n",
       " 'tinynet_a.in1k',\n",
       " 'tinynet_b.in1k',\n",
       " 'tinynet_c.in1k',\n",
       " 'tinynet_d.in1k',\n",
       " 'tinynet_e.in1k',\n",
       " 'tnt_s_patch16_224',\n",
       " 'tresnet_l',\n",
       " 'tresnet_l_448',\n",
       " 'tresnet_m',\n",
       " 'tresnet_m_448',\n",
       " 'tresnet_m_miil_in21k',\n",
       " 'tresnet_v2_l',\n",
       " 'tresnet_xl',\n",
       " 'tresnet_xl_448',\n",
       " 'tv_densenet121',\n",
       " 'tv_resnet34',\n",
       " 'tv_resnet50',\n",
       " 'tv_resnet101',\n",
       " 'tv_resnet152',\n",
       " 'tv_resnext50_32x4d',\n",
       " 'twins_pcpvt_base',\n",
       " 'twins_pcpvt_large',\n",
       " 'twins_pcpvt_small',\n",
       " 'twins_svt_base',\n",
       " 'twins_svt_large',\n",
       " 'twins_svt_small',\n",
       " 'vgg11',\n",
       " 'vgg11_bn',\n",
       " 'vgg13',\n",
       " 'vgg13_bn',\n",
       " 'vgg16',\n",
       " 'vgg16_bn',\n",
       " 'vgg19',\n",
       " 'vgg19_bn',\n",
       " 'visformer_small',\n",
       " 'vit_base_patch8_224.augreg2_in21k_ft_in1k',\n",
       " 'vit_base_patch8_224.augreg_in21k',\n",
       " 'vit_base_patch8_224.augreg_in21k_ft_in1k',\n",
       " 'vit_base_patch8_224.dino',\n",
       " 'vit_base_patch16_224.augreg2_in21k_ft_in1k',\n",
       " 'vit_base_patch16_224.augreg_in1k',\n",
       " 'vit_base_patch16_224.augreg_in21k',\n",
       " 'vit_base_patch16_224.augreg_in21k_ft_in1k',\n",
       " 'vit_base_patch16_224.dino',\n",
       " 'vit_base_patch16_224.orig_in21k_ft_in1k',\n",
       " 'vit_base_patch16_224.sam',\n",
       " 'vit_base_patch16_224_miil.in21k',\n",
       " 'vit_base_patch16_224_miil.in21k_ft_in1k',\n",
       " 'vit_base_patch16_384.augreg_in1k',\n",
       " 'vit_base_patch16_384.augreg_in21k_ft_in1k',\n",
       " 'vit_base_patch16_384.orig_in21k_ft_in1k',\n",
       " 'vit_base_patch16_clip_224.laion2b_ft_in1k',\n",
       " 'vit_base_patch16_clip_224.laion2b_ft_in12k',\n",
       " 'vit_base_patch16_clip_224.laion2b_ft_in12k_in1k',\n",
       " 'vit_base_patch16_clip_224.openai',\n",
       " 'vit_base_patch16_clip_224.openai_ft_in1k',\n",
       " 'vit_base_patch16_clip_224.openai_ft_in12k',\n",
       " 'vit_base_patch16_clip_224.openai_ft_in12k_in1k',\n",
       " 'vit_base_patch16_clip_384.laion2b_ft_in1k',\n",
       " 'vit_base_patch16_clip_384.laion2b_ft_in12k_in1k',\n",
       " 'vit_base_patch16_clip_384.openai_ft_in1k',\n",
       " 'vit_base_patch16_clip_384.openai_ft_in12k_in1k',\n",
       " 'vit_base_patch16_rpn_224.in1k',\n",
       " 'vit_base_patch32_224.augreg_in1k',\n",
       " 'vit_base_patch32_224.augreg_in21k',\n",
       " 'vit_base_patch32_224.augreg_in21k_ft_in1k',\n",
       " 'vit_base_patch32_224.sam',\n",
       " 'vit_base_patch32_384.augreg_in1k',\n",
       " 'vit_base_patch32_384.augreg_in21k_ft_in1k',\n",
       " 'vit_base_patch32_clip_224.laion2b',\n",
       " 'vit_base_patch32_clip_224.laion2b_ft_in1k',\n",
       " 'vit_base_patch32_clip_224.laion2b_ft_in12k_in1k',\n",
       " 'vit_base_patch32_clip_224.openai',\n",
       " 'vit_base_patch32_clip_224.openai_ft_in1k',\n",
       " 'vit_base_patch32_clip_384.laion2b_ft_in12k_in1k',\n",
       " 'vit_base_patch32_clip_384.openai_ft_in12k_in1k',\n",
       " 'vit_base_patch32_clip_448.laion2b_ft_in12k_in1k',\n",
       " 'vit_base_r50_s16_224.orig_in21k',\n",
       " 'vit_base_r50_s16_384.orig_in21k_ft_in1k',\n",
       " 'vit_giant_patch14_clip_224.laion2b',\n",
       " 'vit_gigantic_patch14_clip_224.laion2b',\n",
       " 'vit_huge_patch14_224.orig_in21k',\n",
       " 'vit_huge_patch14_clip_224.laion2b',\n",
       " 'vit_huge_patch14_clip_224.laion2b_ft_in1k',\n",
       " 'vit_huge_patch14_clip_224.laion2b_ft_in12k',\n",
       " 'vit_huge_patch14_clip_224.laion2b_ft_in12k_in1k',\n",
       " 'vit_huge_patch14_clip_336.laion2b_ft_in12k_in1k',\n",
       " 'vit_large_patch14_clip_224.laion2b',\n",
       " 'vit_large_patch14_clip_224.laion2b_ft_in1k',\n",
       " 'vit_large_patch14_clip_224.laion2b_ft_in12k',\n",
       " 'vit_large_patch14_clip_224.laion2b_ft_in12k_in1k',\n",
       " 'vit_large_patch14_clip_224.openai',\n",
       " 'vit_large_patch14_clip_224.openai_ft_in1k',\n",
       " 'vit_large_patch14_clip_224.openai_ft_in12k',\n",
       " 'vit_large_patch14_clip_224.openai_ft_in12k_in1k',\n",
       " 'vit_large_patch14_clip_336.laion2b_ft_in1k',\n",
       " 'vit_large_patch14_clip_336.laion2b_ft_in12k_in1k',\n",
       " 'vit_large_patch14_clip_336.openai_ft_in12k_in1k',\n",
       " 'vit_large_patch16_224.augreg_in21k',\n",
       " 'vit_large_patch16_224.augreg_in21k_ft_in1k',\n",
       " 'vit_large_patch16_384.augreg_in21k_ft_in1k',\n",
       " 'vit_large_patch32_224.orig_in21k',\n",
       " 'vit_large_patch32_384.orig_in21k_ft_in1k',\n",
       " 'vit_large_r50_s32_224.augreg_in21k',\n",
       " 'vit_large_r50_s32_224.augreg_in21k_ft_in1k',\n",
       " 'vit_large_r50_s32_384.augreg_in21k_ft_in1k',\n",
       " 'vit_medium_patch16_gap_240.in12k',\n",
       " 'vit_medium_patch16_gap_256.in12k_ft_in1k',\n",
       " 'vit_medium_patch16_gap_384.in12k_ft_in1k',\n",
       " 'vit_relpos_base_patch16_224.sw_in1k',\n",
       " 'vit_relpos_base_patch16_clsgap_224.sw_in1k',\n",
       " 'vit_relpos_base_patch32_plus_rpn_256.sw_in1k',\n",
       " 'vit_relpos_medium_patch16_224.sw_in1k',\n",
       " 'vit_relpos_medium_patch16_cls_224.sw_in1k',\n",
       " 'vit_relpos_medium_patch16_rpn_224.sw_in1k',\n",
       " 'vit_relpos_small_patch16_224.sw_in1k',\n",
       " 'vit_small_patch8_224.dino',\n",
       " 'vit_small_patch16_224.augreg_in1k',\n",
       " 'vit_small_patch16_224.augreg_in21k',\n",
       " 'vit_small_patch16_224.augreg_in21k_ft_in1k',\n",
       " 'vit_small_patch16_224.dino',\n",
       " 'vit_small_patch16_384.augreg_in1k',\n",
       " 'vit_small_patch16_384.augreg_in21k_ft_in1k',\n",
       " 'vit_small_patch32_224.augreg_in21k',\n",
       " 'vit_small_patch32_224.augreg_in21k_ft_in1k',\n",
       " 'vit_small_patch32_384.augreg_in21k_ft_in1k',\n",
       " 'vit_small_r26_s32_224.augreg_in21k',\n",
       " 'vit_small_r26_s32_224.augreg_in21k_ft_in1k',\n",
       " 'vit_small_r26_s32_384.augreg_in21k_ft_in1k',\n",
       " 'vit_srelpos_medium_patch16_224.sw_in1k',\n",
       " 'vit_srelpos_small_patch16_224.sw_in1k',\n",
       " 'vit_tiny_patch16_224.augreg_in21k',\n",
       " 'vit_tiny_patch16_224.augreg_in21k_ft_in1k',\n",
       " 'vit_tiny_patch16_384.augreg_in21k_ft_in1k',\n",
       " 'vit_tiny_r_s16_p8_224.augreg_in21k',\n",
       " 'vit_tiny_r_s16_p8_224.augreg_in21k_ft_in1k',\n",
       " 'vit_tiny_r_s16_p8_384.augreg_in21k_ft_in1k',\n",
       " 'volo_d1_224',\n",
       " 'volo_d1_384',\n",
       " 'volo_d2_224',\n",
       " 'volo_d2_384',\n",
       " 'volo_d3_224',\n",
       " 'volo_d3_448',\n",
       " 'volo_d4_224',\n",
       " 'volo_d4_448',\n",
       " 'volo_d5_224',\n",
       " 'volo_d5_448',\n",
       " 'volo_d5_512',\n",
       " 'wide_resnet50_2',\n",
       " 'wide_resnet101_2',\n",
       " 'xception',\n",
       " 'xception41',\n",
       " 'xception41p',\n",
       " 'xception65',\n",
       " 'xception65p',\n",
       " 'xception71',\n",
       " 'xcit_large_24_p8_224',\n",
       " 'xcit_large_24_p8_224_dist',\n",
       " 'xcit_large_24_p8_384_dist',\n",
       " 'xcit_large_24_p16_224',\n",
       " 'xcit_large_24_p16_224_dist',\n",
       " 'xcit_large_24_p16_384_dist',\n",
       " 'xcit_medium_24_p8_224',\n",
       " 'xcit_medium_24_p8_224_dist',\n",
       " 'xcit_medium_24_p8_384_dist',\n",
       " 'xcit_medium_24_p16_224',\n",
       " 'xcit_medium_24_p16_224_dist',\n",
       " 'xcit_medium_24_p16_384_dist',\n",
       " 'xcit_nano_12_p8_224',\n",
       " 'xcit_nano_12_p8_224_dist',\n",
       " 'xcit_nano_12_p8_384_dist',\n",
       " 'xcit_nano_12_p16_224',\n",
       " 'xcit_nano_12_p16_224_dist',\n",
       " 'xcit_nano_12_p16_384_dist',\n",
       " 'xcit_small_12_p8_224',\n",
       " 'xcit_small_12_p8_224_dist',\n",
       " 'xcit_small_12_p8_384_dist',\n",
       " 'xcit_small_12_p16_224',\n",
       " 'xcit_small_12_p16_224_dist',\n",
       " 'xcit_small_12_p16_384_dist',\n",
       " 'xcit_small_24_p8_224',\n",
       " 'xcit_small_24_p8_224_dist',\n",
       " 'xcit_small_24_p8_384_dist',\n",
       " 'xcit_small_24_p16_224',\n",
       " 'xcit_small_24_p16_224_dist',\n",
       " 'xcit_small_24_p16_384_dist',\n",
       " 'xcit_tiny_12_p8_224',\n",
       " 'xcit_tiny_12_p8_224_dist',\n",
       " 'xcit_tiny_12_p8_384_dist',\n",
       " 'xcit_tiny_12_p16_224',\n",
       " 'xcit_tiny_12_p16_224_dist',\n",
       " 'xcit_tiny_12_p16_384_dist',\n",
       " 'xcit_tiny_24_p8_224',\n",
       " 'xcit_tiny_24_p8_224_dist',\n",
       " 'xcit_tiny_24_p8_384_dist',\n",
       " 'xcit_tiny_24_p16_224',\n",
       " 'xcit_tiny_24_p16_224_dist',\n",
       " 'xcit_tiny_24_p16_384_dist']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timm.list_models(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4d8029a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fold': 0,\n",
       " 'epoch': 30,\n",
       " 'model_name': 'tf_efficientnet_b0_ns',\n",
       " 'finetune': False,\n",
       " 'img_size': 128,\n",
       " 'batch_size': 64,\n",
       " 'gradient_accumulation': 1,\n",
       " 'gradient_checkpoint': False,\n",
       " 'drop_out': 0.3,\n",
       " 'drop_path': 0.2,\n",
       " 'lr': 0.0003,\n",
       " 'weight_decay': 0.0005,\n",
       " 'num_classes': 264,\n",
       " 'load_model': './train_model_copy/cv0_best.pth',\n",
       " 'save_model': './train_model_copy'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CFG= {\n",
    "    'fold': 0,\n",
    "    'epoch': 30,\n",
    "    'model_name': 'tf_efficientnet_b0_ns',\n",
    "    'finetune': False,\n",
    "    \n",
    "    'img_size': 128,\n",
    "    'batch_size': 64,\n",
    "    'gradient_accumulation': 1,\n",
    "    'gradient_checkpoint': False,\n",
    "    'drop_out': 0.3,\n",
    "    'drop_path': 0.2,\n",
    "    \n",
    "    'lr': 3e-4,\n",
    "    'weight_decay': 5e-4,\n",
    "    \n",
    "    'num_classes': 264,\n",
    "    'load_model': f\"./train_model_copy/cv0_best.pth\", #False,\n",
    "    'save_model': './train_model_copy'\n",
    "}\n",
    "\n",
    "if CFG['finetune']:\n",
    "    CFG['lr']= 3e-5\n",
    "    CFG['load_model']= f\"./train_model_copy/cv{CFG['fold']}_best.pth\"\n",
    "CFG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3aa7835",
   "metadata": {},
   "source": [
    "# Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "44ab6b58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>label</th>\n",
       "      <th>label_name</th>\n",
       "      <th>group</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data/train_img_ex2020\\barswa\\XC134349._15804.png</td>\n",
       "      <td>20</td>\n",
       "      <td>barswa</td>\n",
       "      <td>XC134349.</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data/train_img_ex2020\\barswa\\XC134349._15805.png</td>\n",
       "      <td>20</td>\n",
       "      <td>barswa</td>\n",
       "      <td>XC134349.</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data/train_img_ex2020\\barswa\\XC134349._15806.png</td>\n",
       "      <td>20</td>\n",
       "      <td>barswa</td>\n",
       "      <td>XC134349.</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data/train_img_ex2020\\barswa\\XC134349._15807.png</td>\n",
       "      <td>20</td>\n",
       "      <td>barswa</td>\n",
       "      <td>XC134349.</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data/train_img_ex2020\\barswa\\XC134349._15808.png</td>\n",
       "      <td>20</td>\n",
       "      <td>barswa</td>\n",
       "      <td>XC134349.</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17325</th>\n",
       "      <td>Data/train_img_ex1\\greegr\\XC58490._95648.png</td>\n",
       "      <td>106</td>\n",
       "      <td>greegr</td>\n",
       "      <td>XC58490.</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17326</th>\n",
       "      <td>Data/train_img_ex1\\greegr\\XC586205._95649.png</td>\n",
       "      <td>106</td>\n",
       "      <td>greegr</td>\n",
       "      <td>XC586205.</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17327</th>\n",
       "      <td>Data/train_img_ex1\\greegr\\XC84914._95650.png</td>\n",
       "      <td>106</td>\n",
       "      <td>greegr</td>\n",
       "      <td>XC84914.</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17328</th>\n",
       "      <td>Data/train_img_ex1\\greegr\\XC84914._95651.png</td>\n",
       "      <td>106</td>\n",
       "      <td>greegr</td>\n",
       "      <td>XC84914.</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17329</th>\n",
       "      <td>Data/train_img_ex1\\greegr\\XC84914._95652.png</td>\n",
       "      <td>106</td>\n",
       "      <td>greegr</td>\n",
       "      <td>XC84914.</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17330 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             image_path  label label_name   \n",
       "0      Data/train_img_ex2020\\barswa\\XC134349._15804.png     20     barswa  \\\n",
       "1      Data/train_img_ex2020\\barswa\\XC134349._15805.png     20     barswa   \n",
       "2      Data/train_img_ex2020\\barswa\\XC134349._15806.png     20     barswa   \n",
       "3      Data/train_img_ex2020\\barswa\\XC134349._15807.png     20     barswa   \n",
       "4      Data/train_img_ex2020\\barswa\\XC134349._15808.png     20     barswa   \n",
       "...                                                 ...    ...        ...   \n",
       "17325      Data/train_img_ex1\\greegr\\XC58490._95648.png    106     greegr   \n",
       "17326     Data/train_img_ex1\\greegr\\XC586205._95649.png    106     greegr   \n",
       "17327      Data/train_img_ex1\\greegr\\XC84914._95650.png    106     greegr   \n",
       "17328      Data/train_img_ex1\\greegr\\XC84914._95651.png    106     greegr   \n",
       "17329      Data/train_img_ex1\\greegr\\XC84914._95652.png    106     greegr   \n",
       "\n",
       "           group  fold  \n",
       "0      XC134349.   1.0  \n",
       "1      XC134349.   1.0  \n",
       "2      XC134349.   1.0  \n",
       "3      XC134349.   1.0  \n",
       "4      XC134349.   1.0  \n",
       "...          ...   ...  \n",
       "17325   XC58490.   2.0  \n",
       "17326  XC586205.   4.0  \n",
       "17327   XC84914.   2.0  \n",
       "17328   XC84914.   2.0  \n",
       "17329   XC84914.   2.0  \n",
       "\n",
       "[17330 rows x 5 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.read_csv('Data/train.csv')\n",
    "label_name= list(df['label_name'].unique())\n",
    "\n",
    "df_1= pd.read_csv('Data/train_ex2020.csv')\n",
    "df_2= pd.read_csv('Data/train_ex2021.csv')\n",
    "df_3= pd.read_csv('Data/train_ex2022.csv')\n",
    "df_4= pd.read_csv('Data/train_ex1.csv')\n",
    "ex_df= pd.concat([df_1, df_2, df_3, df_4], axis=0)\n",
    "ex_df= ex_df[ex_df['label_name'].isin(label_name)].reset_index(drop=True)\n",
    "\n",
    "la= list(ex_df['label_name'].unique())\n",
    "for l in la:\n",
    "    ex_df.loc[ ex_df['label_name']==l, 'label' ]= label_name.index(l)\n",
    "ex_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0010c7a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da05bc249a8e4654b4bdbf9c191f12a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/264 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataset: 56523\n",
      "valid dataset: 26194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\kaggle_smbcd\\lib\\site-packages\\albumentations\\augmentations\\dropout\\cutout.py:49: FutureWarning: Cutout has been deprecated. Please use CoarseDropout\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>label</th>\n",
       "      <th>label_name</th>\n",
       "      <th>group</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data/train_img\\abethr1\\XC128013._0.png</td>\n",
       "      <td>0</td>\n",
       "      <td>abethr1</td>\n",
       "      <td>XC128013.</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data/train_img\\abethr1\\XC128013._1.png</td>\n",
       "      <td>0</td>\n",
       "      <td>abethr1</td>\n",
       "      <td>XC128013.</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data/train_img\\abethr1\\XC128013._2.png</td>\n",
       "      <td>0</td>\n",
       "      <td>abethr1</td>\n",
       "      <td>XC128013.</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data/train_img\\abethr1\\XC128013._3.png</td>\n",
       "      <td>0</td>\n",
       "      <td>abethr1</td>\n",
       "      <td>XC128013.</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data/train_img\\abethr1\\XC128013._4.png</td>\n",
       "      <td>0</td>\n",
       "      <td>abethr1</td>\n",
       "      <td>XC128013.</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               image_path  label label_name      group  fold\n",
       "0  Data/train_img\\abethr1\\XC128013._0.png      0    abethr1  XC128013.   1.0\n",
       "1  Data/train_img\\abethr1\\XC128013._1.png      0    abethr1  XC128013.   1.0\n",
       "2  Data/train_img\\abethr1\\XC128013._2.png      0    abethr1  XC128013.   1.0\n",
       "3  Data/train_img\\abethr1\\XC128013._3.png      0    abethr1  XC128013.   1.0\n",
       "4  Data/train_img\\abethr1\\XC128013._4.png      0    abethr1  XC128013.   1.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.read_csv('Data/train.csv')\n",
    "\n",
    "train_dataset= df[df['fold']!=CFG['fold']].reset_index(drop=True)\n",
    "train_dataset= pd.concat([train_dataset, ex_df],axis=0).reset_index(drop=True)\n",
    "train_dataset= df[df['fold']!=CFG['fold']].reset_index(drop=True)\n",
    "label= train_dataset['label'].unique().tolist()\n",
    "n= 500\n",
    "for i,g in enumerate(tqdm(label)):\n",
    "    sample_df= train_dataset[train_dataset['label']==g]\n",
    "    if len(sample_df)>=500: sample_df= sample_df.sample(n=n, replace=False, random_state=1).reset_index(drop=True)\n",
    "    elif len(sample_df)<50: sample_df= sample_df.sample(n=50, replace=True, random_state=1).reset_index(drop=True)\n",
    "    if i==0: new_df= sample_df\n",
    "    else: new_df= pd.concat([new_df, sample_df], axis=0).reset_index(drop=True)\n",
    "train_dataset= new_df\n",
    "\n",
    "valid_dataset= df[df['fold']==CFG['fold']].reset_index(drop=True)\n",
    "print(f'train dataset: {len(train_dataset)}')\n",
    "print(f'valid dataset: {len(valid_dataset)}')\n",
    "\n",
    "train_dataset= Customize_Dataset(train_dataset, get_train_transform(CFG['img_size']), mixup=0.65)\n",
    "valid_dataset= Customize_Dataset(valid_dataset, get_test_transform(CFG['img_size']), mixup=False)\n",
    "\n",
    "train_loader= DataLoader(train_dataset, batch_size= CFG['batch_size'], shuffle=True, num_workers=0)\n",
    "valid_loader= DataLoader(valid_dataset, batch_size=32, shuffle=False, num_workers=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5d46d5ad",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data= train_dataset[0]\n",
    "img= data['image']\n",
    "plt.imshow(img.permute(1,2,0).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd8144c",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ce46fc57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_model: ./train_model_copy/cv0_best.pth\n",
      "\n",
      "ep: 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb3072be1d1740d1b555dc8ea5a571ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/884 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_10796\\1559028917.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'image': torch.tensor(img/255, dtype=torch.float32),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49293aa4f88f4dbda990534bd2018799",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/819 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7019546461021609\n",
      "mean_recall: 0.47578966661754085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmap: 0.6817369969793188\n",
      "train loss: 0.00829\n",
      "valid loss: 0.00768, valid_acc: 0.68174\n",
      "model save at score: 0.68174\n",
      "\n",
      "ep: 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1025f7afaddf41139366c362fae52401",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/884 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_10796\\1559028917.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'image': torch.tensor(img/255, dtype=torch.float32),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51d75a25e397491bb916e63289df9e77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/819 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7080247384897305\n",
      "mean_recall: 0.48194144379373216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmap: 0.6863668863862408\n",
      "train loss: 0.00791\n",
      "valid loss: 0.00769, valid_acc: 0.68637\n",
      "model save at score: 0.68637\n",
      "\n",
      "ep: 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1add42d7a0a4d87a7ba64c0788a89bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/884 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_10796\\1559028917.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'image': torch.tensor(img/255, dtype=torch.float32),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee98951097794ff387bb2534dbfa666c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/819 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7084828586699244\n",
      "mean_recall: 0.47741638286722865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmap: 0.6884001994917938\n",
      "train loss: 0.00759\n",
      "valid loss: 0.00765, valid_acc: 0.6884\n",
      "model save at score: 0.6884\n",
      "\n",
      "ep: 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b41d0a7bdb414fcdb989faf535f6f03b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/884 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_10796\\1559028917.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'image': torch.tensor(img/255, dtype=torch.float32),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "679441e8c58a4f1b9d007cfc80f03540",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/819 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7151637779644193\n",
      "mean_recall: 0.5091291246697786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmap: 0.6947256976579207\n",
      "train loss: 0.00738\n",
      "valid loss: 0.00761, valid_acc: 0.69473\n",
      "model save at score: 0.69473\n",
      "\n",
      "ep: 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7542ad44ec70426dab2074174b3b5f10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/884 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_10796\\1559028917.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'image': torch.tensor(img/255, dtype=torch.float32),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "726a25213ab64d148bf47f4e1ec1e32e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/819 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7171107887302436\n",
      "mean_recall: 0.5105893449999795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmap: 0.6949599599271963\n",
      "train loss: 0.00717\n",
      "valid loss: 0.00755, valid_acc: 0.69496\n",
      "model save at score: 0.69496\n",
      "\n",
      "ep: 6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d04dbcc8f4443629f3973f0a473e6fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/884 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_10796\\1559028917.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'image': torch.tensor(img/255, dtype=torch.float32),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8da2e7a228843a6922ebda15239b540",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/819 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7153546613728334\n",
      "mean_recall: 0.5117708765859798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmap: 0.6969983859413061\n",
      "train loss: 0.0069\n",
      "valid loss: 0.00766, valid_acc: 0.697\n",
      "model save at score: 0.697\n",
      "\n",
      "ep: 7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67b7b7a724ec4a47bf89b4087900afce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/884 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_10796\\1559028917.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'image': torch.tensor(img/255, dtype=torch.float32),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b771f6c1b8904075899cb1fd70bf2567",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/819 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7197831564480416\n",
      "mean_recall: 0.5005977269148385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmap: 0.6972220134828994\n",
      "train loss: 0.00672\n",
      "valid loss: 0.00782, valid_acc: 0.69722\n",
      "model save at score: 0.69722\n",
      "\n",
      "ep: 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4891df9ee1b4483da126f317f4a9d7f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/884 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_10796\\1559028917.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'image': torch.tensor(img/255, dtype=torch.float32),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0515ff17dfd045f4ba0bbec4ead85d12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/819 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7224173474841566\n",
      "mean_recall: 0.5072696813852001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmap: 0.6993173379680099\n",
      "train loss: 0.00656\n",
      "valid loss: 0.00768, valid_acc: 0.69932\n",
      "model save at score: 0.69932\n",
      "\n",
      "ep: 9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bce863bf512d45a7a1a86b081cf35022",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/884 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_10796\\1559028917.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'image': torch.tensor(img/255, dtype=torch.float32),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c51056f40af47ec8e028d7d5bfba940",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/819 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7218446972589142\n",
      "mean_recall: 0.5080566657148827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmap: 0.6974312090551568\n",
      "train loss: 0.00645\n",
      "valid loss: 0.00778, valid_acc: 0.69743\n",
      "\n",
      "ep: 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c13543cc16041d7ab0445d98f00b449",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/884 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_10796\\1559028917.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'image': torch.tensor(img/255, dtype=torch.float32),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54cb11cb65fa4955a54eaaadaff91369",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/819 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7237153546613728\n",
      "mean_recall: 0.5130110181821426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmap: 0.6967080637820638\n",
      "train loss: 0.00631\n",
      "valid loss: 0.0078, valid_acc: 0.69671\n",
      "\n",
      "ep: 11\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aef4b259610b479080fc33164a6d464a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/884 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_10796\\1559028917.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'image': torch.tensor(img/255, dtype=torch.float32),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a429835c32624dbb896b4841d6e1ba72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/819 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7266549591509506\n",
      "mean_recall: 0.5021698062765252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmap: 0.6974965979211961\n",
      "train loss: 0.0062\n",
      "valid loss: 0.00769, valid_acc: 0.6975\n",
      "\n",
      "ep: 12\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec75b0ba1ce84ee29b2776f32d1a5c50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/884 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_10796\\1559028917.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'image': torch.tensor(img/255, dtype=torch.float32),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ff8a968d24948fa9056af2568e17a3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/819 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7268458425593647\n",
      "mean_recall: 0.5092377352063244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmap: 0.6998754501076626\n",
      "train loss: 0.00614\n",
      "valid loss: 0.00788, valid_acc: 0.69988\n",
      "model save at score: 0.69988\n",
      "\n",
      "ep: 13\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b56ce536f2b4195a9c2b5d3a5c66c8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/884 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_10796\\1559028917.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'image': torch.tensor(img/255, dtype=torch.float32),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "663194092c174cadbf6a95a13a91af28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/819 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7268458425593647\n",
      "mean_recall: 0.5150499658780049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmap: 0.7004305624805904\n",
      "train loss: 0.00595\n",
      "valid loss: 0.00789, valid_acc: 0.70043\n",
      "model save at score: 0.70043\n",
      "\n",
      "ep: 14\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d66145c1031f42068c79113dca6dfa65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/884 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_10796\\1559028917.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'image': torch.tensor(img/255, dtype=torch.float32),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "844d5d010aef4fa083e33525adfd2903",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/819 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7236008246163244\n",
      "mean_recall: 0.51112853934026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmap: 0.7012322883923343\n",
      "train loss: 0.00588\n",
      "valid loss: 0.00793, valid_acc: 0.70123\n",
      "model save at score: 0.70123\n",
      "\n",
      "ep: 15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f18169258eb440c09fcf44902684e3ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/884 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_10796\\1559028917.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'image': torch.tensor(img/255, dtype=torch.float32),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9f1d472df20409f9ed725a663eb6db8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/819 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7253187752920516\n",
      "mean_recall: 0.5094079971686896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmap: 0.7013022740571201\n",
      "train loss: 0.00588\n",
      "valid loss: 0.00796, valid_acc: 0.7013\n",
      "model save at score: 0.7013\n",
      "\n",
      "ep: 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e69bf057002467ebdec8bc04d5e2506",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/884 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_10796\\1559028917.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'image': torch.tensor(img/255, dtype=torch.float32),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "563891cb50994897a8b4c17e32160b18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/819 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.73123616095289\n",
      "mean_recall: 0.5218715988868173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmap: 0.7073358176265881\n",
      "train loss: 0.00573\n",
      "valid loss: 0.00775, valid_acc: 0.70734\n",
      "model save at score: 0.70734\n",
      "\n",
      "ep: 17\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52654b5160054f6eb288f7cbba7fbc3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/884 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_10796\\1559028917.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'image': torch.tensor(img/255, dtype=torch.float32),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2930e9fdce1247759da5f87742e6f096",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/819 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7326486981751547\n",
      "mean_recall: 0.5286607017316085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmap: 0.7070461282953873\n",
      "train loss: 0.00573\n",
      "valid loss: 0.00773, valid_acc: 0.70705\n",
      "\n",
      "ep: 18\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c56289aeb584518871bfae39de70091",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/884 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_10796\\1559028917.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'image': torch.tensor(img/255, dtype=torch.float32),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e7cc827aeee48fab112883ca249c021",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/819 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7292127968237001\n",
      "mean_recall: 0.5155268078522613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmap: 0.7043245674257903\n",
      "train loss: 0.00564\n",
      "valid loss: 0.00794, valid_acc: 0.70432\n",
      "\n",
      "ep: 19\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf927d5a826a48f8bbe3ea3f6fd5b751",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/884 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_10796\\1559028917.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'image': torch.tensor(img/255, dtype=torch.float32),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d41e97eacf5b44b9a438fb58caf108b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/819 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7350920058028556\n",
      "mean_recall: 0.5229795729339843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmap: 0.7098007196316781\n",
      "train loss: 0.00558\n",
      "valid loss: 0.00789, valid_acc: 0.7098\n",
      "model save at score: 0.7098\n",
      "\n",
      "ep: 20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "986058cbd4124376a42c74c18f859479",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/884 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_10796\\1559028917.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'image': torch.tensor(img/255, dtype=torch.float32),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d6f01836a7e4b95af4cc698312f6082",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/819 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7352065358479041\n",
      "mean_recall: 0.5206471580015911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmap: 0.705061049450623\n",
      "train loss: 0.00556\n",
      "valid loss: 0.00788, valid_acc: 0.70506\n",
      "\n",
      "ep: 21\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bd30bb766b64801b97746bb55585dc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/884 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_10796\\1559028917.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'image': torch.tensor(img/255, dtype=torch.float32),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "613fc1db678a467091a09c27c956c5ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/819 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7321524013132779\n",
      "mean_recall: 0.5308838842590011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmap: 0.7064305285240886\n",
      "train loss: 0.00548\n",
      "valid loss: 0.00804, valid_acc: 0.70643\n",
      "\n",
      "ep: 22\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f14b5e9e1abe4e7388d05e264df14594",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/884 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_10796\\1559028917.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'image': torch.tensor(img/255, dtype=torch.float32),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab704dd5b22b427f93ef3982a73f51fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/819 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7394059708330152\n",
      "mean_recall: 0.5299534028617006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmap: 0.7143823185170052\n",
      "train loss: 0.00544\n",
      "valid loss: 0.00766, valid_acc: 0.71438\n",
      "model save at score: 0.71438\n",
      "\n",
      "ep: 23\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69104977fd12411f8e2def986361226e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/884 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_10796\\1559028917.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'image': torch.tensor(img/255, dtype=torch.float32),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0e2b1e27c054297b4147e73bfa814e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/819 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7335649385355425\n",
      "mean_recall: 0.5219647551308494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmap: 0.7093621925251338\n",
      "train loss: 0.00542\n",
      "valid loss: 0.00798, valid_acc: 0.70936\n",
      "\n",
      "ep: 24\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b821549f52d940a9af8a0574038dad7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/884 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_10796\\1559028917.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'image': torch.tensor(img/255, dtype=torch.float32),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26f7230b185f47a5b7365d0b82ac3cad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/819 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7380316102924334\n",
      "mean_recall: 0.5277545484447043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmap: 0.7104279907275635\n",
      "train loss: 0.00536\n",
      "valid loss: 0.00796, valid_acc: 0.71043\n",
      "\n",
      "ep: 25\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6c541c1aea24a1db2c5e295e7d4d8d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/884 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_10796\\1559028917.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'image': torch.tensor(img/255, dtype=torch.float32),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6e4ac4b116e46b7aa8ac8656e15c3d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/819 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7374207833855081\n",
      "mean_recall: 0.5236720126877487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmap: 0.7076013277710884\n",
      "train loss: 0.0053\n",
      "valid loss: 0.00815, valid_acc: 0.7076\n",
      "\n",
      "ep: 26\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "863b22f4d92844a6ad5f5488530d572b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/884 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_10796\\1559028917.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'image': torch.tensor(img/255, dtype=torch.float32),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8b5b2410e3d4cdc91983fc831e2ae90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/819 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7368863098419486\n",
      "mean_recall: 0.5186923649543126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmap: 0.7110331154078996\n",
      "train loss: 0.00531\n",
      "valid loss: 0.008, valid_acc: 0.71103\n",
      "\n",
      "ep: 27\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "064aff35d95044848434e0bcf512abbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/884 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_10796\\1559028917.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'image': torch.tensor(img/255, dtype=torch.float32),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "085dc8f26e0c4e83a21312ba5ca0f091",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/819 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7402840345117202\n",
      "mean_recall: 0.529864770014244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmap: 0.712194864596219\n",
      "train loss: 0.00528\n",
      "valid loss: 0.00785, valid_acc: 0.71219\n",
      "\n",
      "ep: 28\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89620633960f4668895697a113402c01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/884 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_10796\\1559028917.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'image': torch.tensor(img/255, dtype=torch.float32),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6b608ab7290437d923bf82f5d4a019b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/819 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.735893716118195\n",
      "mean_recall: 0.5209921546961565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmap: 0.7081359562091877\n",
      "train loss: 0.00521\n",
      "valid loss: 0.00815, valid_acc: 0.70814\n",
      "\n",
      "ep: 29\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67074eebd13d4637901e2c6b5e6ba67c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/884 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_10796\\1559028917.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'image': torch.tensor(img/255, dtype=torch.float32),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9231d2461c2b4c099f31d0bf7a4fa5de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/819 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7405130946018172\n",
      "mean_recall: 0.5357224725425089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmap: 0.7147058515138672\n",
      "train loss: 0.0052\n",
      "valid loss: 0.00785, valid_acc: 0.71471\n",
      "model save at score: 0.71471\n",
      "\n",
      "ep: 30\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "977dd7da5122425981d7bd8fc362e392",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/884 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_10796\\1559028917.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'image': torch.tensor(img/255, dtype=torch.float32),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ed9f8996b0646b68a889558dc548258",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/819 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7370771932503627\n",
      "mean_recall: 0.5349779826216502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmap: 0.7124046865622629\n",
      "train loss: 0.00518\n",
      "valid loss: 0.00818, valid_acc: 0.7124\n"
     ]
    }
   ],
   "source": [
    "## create model\n",
    "if CFG['load_model']:\n",
    "    print(f\"load_model: {CFG['load_model']}\")\n",
    "    model= torch.load(CFG['load_model'], map_location= 'cuda')\n",
    "else:\n",
    "    model= Customize_Model(CFG['model_name'], CFG['num_classes'])\n",
    "model.to('cuda')\n",
    "    \n",
    "## hyperparameter\n",
    "criterion= Customize_loss()\n",
    "optimizer= optim.AdamW(model.parameters(), lr= CFG['lr'], weight_decay= CFG['weight_decay'])\n",
    "\n",
    "## start training\n",
    "best_score= 0\n",
    "for ep in range(1, CFG['epoch']+1):\n",
    "    print(f'\\nep: {ep}')\n",
    "    \n",
    "    train_loss= train_epoch(train_loader, model, criterion, optimizer)\n",
    "    valid_loss, valid_acc= valid_epoch(valid_loader, model, criterion)\n",
    "    print(f'train loss: {round(train_loss, 5)}')\n",
    "    print(f'valid loss: {round(valid_loss, 5)}, valid_acc: {round(valid_acc, 5)}')\n",
    "    \n",
    "    if valid_acc >= best_score:\n",
    "        best_score= valid_acc\n",
    "        torch.save(model, f\"{CFG['save_model']}/cv{CFG['fold']}_best.pth\")\n",
    "        print(f'model save at score: {round(best_score, 5)}')\n",
    "        \n",
    "    ## save model every epoch\n",
    "    torch.save(model, f\"{CFG['save_model']}/cv{CFG['fold']}_ep{ep}.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
