{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ab1420b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import cv2\n",
    "import time\n",
    "import random\n",
    "\n",
    "# For data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Pytorch Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda import amp\n",
    "from pytorch_toolbelt import losses as L\n",
    "\n",
    "# Utils\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# For Image Models\n",
    "import timm\n",
    "\n",
    "# Albumentations for augmentations\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "## using gpu:1\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "def seed_everything(seed=123):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "seed_everything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85ceec4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Customize_Model(nn.Module):\n",
    "    def __init__(self, model_name, cls):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(model_name, \n",
    "                                       pretrained=True, \n",
    "                                       num_classes=cls, \n",
    "                                       drop_rate= CFG['drop_out'], \n",
    "                                       drop_path_rate= CFG['drop_path'])\n",
    "        \n",
    "    def forward(self, image):\n",
    "        x = self.model(image)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8881b53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_transform(img_size):\n",
    "    return A.Compose([\n",
    "        A.SmallestMaxSize(max_size=img_size, interpolation=3, p=1),\n",
    "#         A.Resize(img_size, img_size),\n",
    "        \n",
    "        A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),\n",
    "#         A.HorizontalFlip(p=0.5),\n",
    "#         A.VerticalFlip(p=0.5),\n",
    "#         A.Blur(blur_limit= 3, p=0.3), \n",
    "        A.GaussNoise(p=0.3),\n",
    "        A.OneOf([\n",
    "                A.Cutout(max_h_size=10, max_w_size=16),\n",
    "                A.CoarseDropout(max_holes=4),\n",
    "            ], p=0.5),\n",
    "        A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit= 0,\n",
    "                                        interpolation=cv2.INTER_LINEAR, border_mode=0, p=0.7),\n",
    "        ToTensorV2(p=1.0),\n",
    "    ])\n",
    "\n",
    "\n",
    "def get_test_transform(img_size):\n",
    "    return A.Compose([\n",
    "        A.SmallestMaxSize(max_size=img_size, interpolation=3, p=1),\n",
    "#         A.Resize(img_size, img_size),\n",
    "        ToTensorV2(p=1.0),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a153977",
   "metadata": {},
   "outputs": [],
   "source": [
    "from toolbox.audio_aug import *\n",
    "\n",
    "class Customize_Dataset(Dataset):\n",
    "    def __init__(self, df, transforms=None, mixup=0):\n",
    "        self.df = df\n",
    "        self.transforms = transforms\n",
    "        self.mixup= mixup\n",
    "        \n",
    "    def mixup_aug(self, img_1, mask_1, \n",
    "                        img_2, mask_2):\n",
    "        \"\"\"\n",
    "        img: numpy array of shape (height, width,channel)\n",
    "        mask: numpy array of shape (height, width,channel)\n",
    "        \"\"\"\n",
    "        ## mixup\n",
    "        weight= np.random.beta(a=0.5, b=0.5)\n",
    "        img= img_1*weight + img_2*(1-weight)\n",
    "        mask= mask_1*weight + mask_2*(1-weight)\n",
    "        return img.astype(np.uint8), mask\n",
    "    \n",
    "    def read_data(self, data):\n",
    "        img = cv2.imread(data['image_path'])\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        label= [0]*CFG['num_classes']\n",
    "        cls = data['label']\n",
    "        \n",
    "        ## make soft_label\n",
    "        sec_indx= eval(data['2nd_label'])\n",
    "        if len(sec_indx)!=0:\n",
    "            sec_label= (1-CFG['soft_target']) / len(sec_indx)\n",
    "            for indx in sec_indx: label[indx]= sec_label\n",
    "            label[cls]= CFG['soft_target']\n",
    "        else:\n",
    "            label[cls]= 1\n",
    "        label= np.array(label)\n",
    "        \n",
    "        return img, label\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        data = self.df.loc[index]\n",
    "        img, label= self.read_data(data)\n",
    "        \n",
    "        # use mixup\n",
    "        if self.mixup and np.random.rand() >= (1-self.mixup):\n",
    "            img_1= img\n",
    "            label_1= np.array(label)\n",
    "            while True:\n",
    "                indx= np.random.randint(len(self.df))\n",
    "                data= self.df.loc[indx]\n",
    "                img_2, label_2= self.read_data(data)\n",
    "                if label_1.argmax(0)!=label_2.argmax(0): break\n",
    "            img, label= self.mixup_aug(img_1, label_1, \n",
    "                                       img_2, label_2)\n",
    "        \n",
    "        if self.transforms:\n",
    "            img = self.transforms(image=img)[\"image\"]\n",
    "            \n",
    "        return {\n",
    "            'image': torch.tensor(img/255, dtype=torch.float32),\n",
    "            'label': torch.tensor(label, dtype=torch.float32),\n",
    "        }\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25e62a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Customize_loss(nn.Module):\n",
    "    def  __init__(self):\n",
    "        super().__init__()\n",
    "        self.CrossEntropy= nn.CrossEntropyLoss(weight= None, label_smoothing=0.25)\n",
    "        self.FocalCosineLoss= L.FocalCosineLoss()\n",
    "        self.soft_ce= L.SoftCrossEntropyLoss(smooth_factor=0.25)\n",
    "        self.bi_temp= L.BiTemperedLogisticLoss(t1=0.8, t2=1.2)\n",
    "        self.soft_bce= L.SoftBCEWithLogitsLoss(smooth_factor= 0.03)\n",
    "    \n",
    "    def forward(self, y_pred, y_true):\n",
    "        loss= self.soft_bce(y_pred, y_true)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8f51ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(dataloader, model, criterion, optimizer):\n",
    "    scaler= amp.GradScaler()\n",
    "    model.train()\n",
    "\n",
    "    ep_loss= []\n",
    "    for i, data in enumerate(tqdm(dataloader)):\n",
    "\n",
    "        imgs= data['image'].to('cuda')\n",
    "        labels= data['label'].to('cuda')\n",
    "        \n",
    "        with amp.autocast():\n",
    "            preds= model(imgs)\n",
    "            loss= criterion(preds, labels)\n",
    "            ep_loss.append(loss.item())\n",
    "            loss/= CFG['gradient_accumulation']\n",
    "            scaler.scale(loss).backward()\n",
    "            \n",
    "            if (i+1) % CFG['gradient_accumulation']== 0:\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "    return np.mean(ep_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4efbece7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from metrics import *\n",
    "\n",
    "def valid_epoch(dataloader, model, criterion):\n",
    "    model.eval()\n",
    "    \n",
    "    ep_loss= []\n",
    "    all_pred= []\n",
    "    all_label= []\n",
    "    for i, data in enumerate(tqdm(dataloader)):\n",
    "\n",
    "        imgs= data['image'].to('cuda')\n",
    "        labels= data['label'].to('cuda')\n",
    "        all_label.extend(labels.cpu().numpy())\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            preds= model(imgs)\n",
    "            loss= criterion(preds, labels)\n",
    "            ep_loss.append(loss.item())\n",
    "        all_pred.extend(preds.cpu().softmax(dim=-1).numpy())\n",
    "        \n",
    "    \n",
    "    ## caculate metrics\n",
    "    all_label= np.array(all_label).argmax(1)\n",
    "    all_pred= np.array(all_pred)\n",
    "    \n",
    "    acc= Accuracy(all_pred, all_label)\n",
    "    print(f'accuracy: {acc}')\n",
    "    recall= Mean_Recall(all_pred, all_label)\n",
    "    print(f'mean_recall: {recall}')\n",
    "    \n",
    "    cmap= padded_cmap(all_pred, all_label)\n",
    "    print(f'cmap: {cmap}')\n",
    "    \n",
    "    score= cmap\n",
    "    return np.mean(ep_loss), score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1bde5f",
   "metadata": {},
   "source": [
    "# CFG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e809850e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adv_inception_v3',\n",
       " 'bat_resnext26ts.ch_in1k',\n",
       " 'beit_base_patch16_224.in22k_ft_in22k',\n",
       " 'beit_base_patch16_224.in22k_ft_in22k_in1k',\n",
       " 'beit_base_patch16_384.in22k_ft_in22k_in1k',\n",
       " 'beit_large_patch16_224.in22k_ft_in22k',\n",
       " 'beit_large_patch16_224.in22k_ft_in22k_in1k',\n",
       " 'beit_large_patch16_384.in22k_ft_in22k_in1k',\n",
       " 'beit_large_patch16_512.in22k_ft_in22k_in1k',\n",
       " 'beitv2_base_patch16_224.in1k_ft_in22k',\n",
       " 'beitv2_base_patch16_224.in1k_ft_in22k_in1k',\n",
       " 'beitv2_large_patch16_224.in1k_ft_in22k',\n",
       " 'beitv2_large_patch16_224.in1k_ft_in22k_in1k',\n",
       " 'botnet26t_256',\n",
       " 'cait_m36_384',\n",
       " 'cait_m48_448',\n",
       " 'cait_s24_224',\n",
       " 'cait_s24_384',\n",
       " 'cait_s36_384',\n",
       " 'cait_xs24_384',\n",
       " 'cait_xxs24_224',\n",
       " 'cait_xxs24_384',\n",
       " 'cait_xxs36_224',\n",
       " 'cait_xxs36_384',\n",
       " 'coat_lite_mini',\n",
       " 'coat_lite_small',\n",
       " 'coat_lite_tiny',\n",
       " 'coat_mini',\n",
       " 'coat_tiny',\n",
       " 'coatnet_0_rw_224.sw_in1k',\n",
       " 'coatnet_1_rw_224.sw_in1k',\n",
       " 'coatnet_2_rw_224.sw_in12k',\n",
       " 'coatnet_2_rw_224.sw_in12k_ft_in1k',\n",
       " 'coatnet_3_rw_224.sw_in12k',\n",
       " 'coatnet_bn_0_rw_224.sw_in1k',\n",
       " 'coatnet_nano_rw_224.sw_in1k',\n",
       " 'coatnet_rmlp_1_rw2_224.sw_in12k',\n",
       " 'coatnet_rmlp_1_rw2_224.sw_in12k_ft_in1k',\n",
       " 'coatnet_rmlp_1_rw_224.sw_in1k',\n",
       " 'coatnet_rmlp_2_rw_224.sw_in1k',\n",
       " 'coatnet_rmlp_2_rw_224.sw_in12k',\n",
       " 'coatnet_rmlp_2_rw_224.sw_in12k_ft_in1k',\n",
       " 'coatnet_rmlp_2_rw_384.sw_in12k_ft_in1k',\n",
       " 'coatnet_rmlp_nano_rw_224.sw_in1k',\n",
       " 'coatnext_nano_rw_224.sw_in1k',\n",
       " 'convit_base',\n",
       " 'convit_small',\n",
       " 'convit_tiny',\n",
       " 'convmixer_768_32',\n",
       " 'convmixer_1024_20_ks9_p14',\n",
       " 'convmixer_1536_20',\n",
       " 'convnext_atto.d2_in1k',\n",
       " 'convnext_atto_ols.a2_in1k',\n",
       " 'convnext_base.clip_laion2b',\n",
       " 'convnext_base.clip_laion2b_augreg',\n",
       " 'convnext_base.clip_laion2b_augreg_ft_in1k',\n",
       " 'convnext_base.clip_laiona',\n",
       " 'convnext_base.clip_laiona_320',\n",
       " 'convnext_base.clip_laiona_augreg_320',\n",
       " 'convnext_base.clip_laiona_augreg_ft_in1k_384',\n",
       " 'convnext_base.fb_in1k',\n",
       " 'convnext_base.fb_in22k',\n",
       " 'convnext_base.fb_in22k_ft_in1k',\n",
       " 'convnext_base.fb_in22k_ft_in1k_384',\n",
       " 'convnext_femto.d1_in1k',\n",
       " 'convnext_femto_ols.d1_in1k',\n",
       " 'convnext_large.fb_in1k',\n",
       " 'convnext_large.fb_in22k',\n",
       " 'convnext_large.fb_in22k_ft_in1k',\n",
       " 'convnext_large.fb_in22k_ft_in1k_384',\n",
       " 'convnext_large_mlp.clip_laion2b_augreg',\n",
       " 'convnext_large_mlp.clip_laion2b_augreg_ft_in1k',\n",
       " 'convnext_large_mlp.clip_laion2b_augreg_ft_in1k_384',\n",
       " 'convnext_large_mlp.clip_laion2b_ft_320',\n",
       " 'convnext_large_mlp.clip_laion2b_ft_soup_320',\n",
       " 'convnext_nano.d1h_in1k',\n",
       " 'convnext_nano.in12k',\n",
       " 'convnext_nano.in12k_ft_in1k',\n",
       " 'convnext_nano_ols.d1h_in1k',\n",
       " 'convnext_pico.d1_in1k',\n",
       " 'convnext_pico_ols.d1_in1k',\n",
       " 'convnext_small.fb_in1k',\n",
       " 'convnext_small.fb_in22k',\n",
       " 'convnext_small.fb_in22k_ft_in1k',\n",
       " 'convnext_small.fb_in22k_ft_in1k_384',\n",
       " 'convnext_small.in12k',\n",
       " 'convnext_small.in12k_ft_in1k',\n",
       " 'convnext_small.in12k_ft_in1k_384',\n",
       " 'convnext_tiny.fb_in1k',\n",
       " 'convnext_tiny.fb_in22k',\n",
       " 'convnext_tiny.fb_in22k_ft_in1k',\n",
       " 'convnext_tiny.fb_in22k_ft_in1k_384',\n",
       " 'convnext_tiny.in12k',\n",
       " 'convnext_tiny.in12k_ft_in1k',\n",
       " 'convnext_tiny.in12k_ft_in1k_384',\n",
       " 'convnext_tiny_hnf.a2h_in1k',\n",
       " 'convnext_xlarge.fb_in22k',\n",
       " 'convnext_xlarge.fb_in22k_ft_in1k',\n",
       " 'convnext_xlarge.fb_in22k_ft_in1k_384',\n",
       " 'convnext_xxlarge.clip_laion2b_rewind',\n",
       " 'convnext_xxlarge.clip_laion2b_soup',\n",
       " 'convnextv2_atto.fcmae',\n",
       " 'convnextv2_atto.fcmae_ft_in1k',\n",
       " 'convnextv2_base.fcmae',\n",
       " 'convnextv2_base.fcmae_ft_in1k',\n",
       " 'convnextv2_base.fcmae_ft_in22k_in1k',\n",
       " 'convnextv2_base.fcmae_ft_in22k_in1k_384',\n",
       " 'convnextv2_femto.fcmae',\n",
       " 'convnextv2_femto.fcmae_ft_in1k',\n",
       " 'convnextv2_huge.fcmae',\n",
       " 'convnextv2_huge.fcmae_ft_in1k',\n",
       " 'convnextv2_huge.fcmae_ft_in22k_in1k_384',\n",
       " 'convnextv2_huge.fcmae_ft_in22k_in1k_512',\n",
       " 'convnextv2_large.fcmae',\n",
       " 'convnextv2_large.fcmae_ft_in1k',\n",
       " 'convnextv2_large.fcmae_ft_in22k_in1k',\n",
       " 'convnextv2_large.fcmae_ft_in22k_in1k_384',\n",
       " 'convnextv2_nano.fcmae',\n",
       " 'convnextv2_nano.fcmae_ft_in1k',\n",
       " 'convnextv2_nano.fcmae_ft_in22k_in1k',\n",
       " 'convnextv2_nano.fcmae_ft_in22k_in1k_384',\n",
       " 'convnextv2_pico.fcmae',\n",
       " 'convnextv2_pico.fcmae_ft_in1k',\n",
       " 'convnextv2_tiny.fcmae',\n",
       " 'convnextv2_tiny.fcmae_ft_in1k',\n",
       " 'convnextv2_tiny.fcmae_ft_in22k_in1k',\n",
       " 'convnextv2_tiny.fcmae_ft_in22k_in1k_384',\n",
       " 'crossvit_9_240',\n",
       " 'crossvit_9_dagger_240',\n",
       " 'crossvit_15_240',\n",
       " 'crossvit_15_dagger_240',\n",
       " 'crossvit_15_dagger_408',\n",
       " 'crossvit_18_240',\n",
       " 'crossvit_18_dagger_240',\n",
       " 'crossvit_18_dagger_408',\n",
       " 'crossvit_base_240',\n",
       " 'crossvit_small_240',\n",
       " 'crossvit_tiny_240',\n",
       " 'cs3darknet_focus_l',\n",
       " 'cs3darknet_focus_m',\n",
       " 'cs3darknet_l',\n",
       " 'cs3darknet_m',\n",
       " 'cs3darknet_x',\n",
       " 'cs3edgenet_x',\n",
       " 'cs3se_edgenet_x',\n",
       " 'cs3sedarknet_l',\n",
       " 'cs3sedarknet_x',\n",
       " 'cspdarknet53',\n",
       " 'cspresnet50',\n",
       " 'cspresnext50',\n",
       " 'darknet53',\n",
       " 'darknetaa53',\n",
       " 'davit_base.msft_in1k',\n",
       " 'davit_small.msft_in1k',\n",
       " 'davit_tiny.msft_in1k',\n",
       " 'deit3_base_patch16_224.fb_in1k',\n",
       " 'deit3_base_patch16_224.fb_in22k_ft_in1k',\n",
       " 'deit3_base_patch16_384.fb_in1k',\n",
       " 'deit3_base_patch16_384.fb_in22k_ft_in1k',\n",
       " 'deit3_huge_patch14_224.fb_in1k',\n",
       " 'deit3_huge_patch14_224.fb_in22k_ft_in1k',\n",
       " 'deit3_large_patch16_224.fb_in1k',\n",
       " 'deit3_large_patch16_224.fb_in22k_ft_in1k',\n",
       " 'deit3_large_patch16_384.fb_in1k',\n",
       " 'deit3_large_patch16_384.fb_in22k_ft_in1k',\n",
       " 'deit3_medium_patch16_224.fb_in1k',\n",
       " 'deit3_medium_patch16_224.fb_in22k_ft_in1k',\n",
       " 'deit3_small_patch16_224.fb_in1k',\n",
       " 'deit3_small_patch16_224.fb_in22k_ft_in1k',\n",
       " 'deit3_small_patch16_384.fb_in1k',\n",
       " 'deit3_small_patch16_384.fb_in22k_ft_in1k',\n",
       " 'deit_base_distilled_patch16_224.fb_in1k',\n",
       " 'deit_base_distilled_patch16_384.fb_in1k',\n",
       " 'deit_base_patch16_224.fb_in1k',\n",
       " 'deit_base_patch16_384.fb_in1k',\n",
       " 'deit_small_distilled_patch16_224.fb_in1k',\n",
       " 'deit_small_patch16_224.fb_in1k',\n",
       " 'deit_tiny_distilled_patch16_224.fb_in1k',\n",
       " 'deit_tiny_patch16_224.fb_in1k',\n",
       " 'densenet121',\n",
       " 'densenet161',\n",
       " 'densenet169',\n",
       " 'densenet201',\n",
       " 'densenetblur121d',\n",
       " 'dla34',\n",
       " 'dla46_c',\n",
       " 'dla46x_c',\n",
       " 'dla60',\n",
       " 'dla60_res2net',\n",
       " 'dla60_res2next',\n",
       " 'dla60x',\n",
       " 'dla60x_c',\n",
       " 'dla102',\n",
       " 'dla102x',\n",
       " 'dla102x2',\n",
       " 'dla169',\n",
       " 'dm_nfnet_f0.dm_in1k',\n",
       " 'dm_nfnet_f1.dm_in1k',\n",
       " 'dm_nfnet_f2.dm_in1k',\n",
       " 'dm_nfnet_f3.dm_in1k',\n",
       " 'dm_nfnet_f4.dm_in1k',\n",
       " 'dm_nfnet_f5.dm_in1k',\n",
       " 'dm_nfnet_f6.dm_in1k',\n",
       " 'dpn68',\n",
       " 'dpn68b',\n",
       " 'dpn92',\n",
       " 'dpn98',\n",
       " 'dpn107',\n",
       " 'dpn131',\n",
       " 'eca_botnext26ts_256',\n",
       " 'eca_halonext26ts',\n",
       " 'eca_nfnet_l0.ra2_in1k',\n",
       " 'eca_nfnet_l1.ra2_in1k',\n",
       " 'eca_nfnet_l2.ra3_in1k',\n",
       " 'eca_resnet33ts.ra2_in1k',\n",
       " 'eca_resnext26ts.ch_in1k',\n",
       " 'ecaresnet26t',\n",
       " 'ecaresnet50d',\n",
       " 'ecaresnet50d_pruned',\n",
       " 'ecaresnet50t',\n",
       " 'ecaresnet101d',\n",
       " 'ecaresnet101d_pruned',\n",
       " 'ecaresnet269d',\n",
       " 'ecaresnetlight',\n",
       " 'edgenext_base',\n",
       " 'edgenext_small',\n",
       " 'edgenext_small_rw',\n",
       " 'edgenext_x_small',\n",
       " 'edgenext_xx_small',\n",
       " 'efficientformer_l1.snap_dist_in1k',\n",
       " 'efficientformer_l3.snap_dist_in1k',\n",
       " 'efficientformer_l7.snap_dist_in1k',\n",
       " 'efficientformerv2_l.snap_dist_in1k',\n",
       " 'efficientformerv2_s0.snap_dist_in1k',\n",
       " 'efficientformerv2_s1.snap_dist_in1k',\n",
       " 'efficientformerv2_s2.snap_dist_in1k',\n",
       " 'efficientnet_b0.ra_in1k',\n",
       " 'efficientnet_b1.ft_in1k',\n",
       " 'efficientnet_b1_pruned.in1k',\n",
       " 'efficientnet_b2.ra_in1k',\n",
       " 'efficientnet_b2_pruned.in1k',\n",
       " 'efficientnet_b3.ra2_in1k',\n",
       " 'efficientnet_b3_pruned.in1k',\n",
       " 'efficientnet_b4.ra2_in1k',\n",
       " 'efficientnet_b5.in12k',\n",
       " 'efficientnet_b5.in12k_ft_in1k',\n",
       " 'efficientnet_el.ra_in1k',\n",
       " 'efficientnet_el_pruned.in1k',\n",
       " 'efficientnet_em.ra2_in1k',\n",
       " 'efficientnet_es.ra_in1k',\n",
       " 'efficientnet_es_pruned.in1k',\n",
       " 'efficientnet_lite0.ra_in1k',\n",
       " 'efficientnetv2_rw_m.agc_in1k',\n",
       " 'efficientnetv2_rw_s.ra2_in1k',\n",
       " 'efficientnetv2_rw_t.ra2_in1k',\n",
       " 'ens_adv_inception_resnet_v2',\n",
       " 'ese_vovnet19b_dw',\n",
       " 'ese_vovnet39b',\n",
       " 'eva_giant_patch14_224.clip_ft_in1k',\n",
       " 'eva_giant_patch14_336.clip_ft_in1k',\n",
       " 'eva_giant_patch14_336.m30m_ft_in22k_in1k',\n",
       " 'eva_giant_patch14_560.m30m_ft_in22k_in1k',\n",
       " 'eva_large_patch14_196.in22k_ft_in1k',\n",
       " 'eva_large_patch14_196.in22k_ft_in22k_in1k',\n",
       " 'eva_large_patch14_336.in22k_ft_in1k',\n",
       " 'eva_large_patch14_336.in22k_ft_in22k_in1k',\n",
       " 'fbnetc_100.rmsp_in1k',\n",
       " 'fbnetv3_b.ra2_in1k',\n",
       " 'fbnetv3_d.ra2_in1k',\n",
       " 'fbnetv3_g.ra2_in1k',\n",
       " 'flexivit_base.300ep_in1k',\n",
       " 'flexivit_base.300ep_in21k',\n",
       " 'flexivit_base.600ep_in1k',\n",
       " 'flexivit_base.1000ep_in21k',\n",
       " 'flexivit_base.1200ep_in1k',\n",
       " 'flexivit_base.patch16_in21k',\n",
       " 'flexivit_base.patch30_in21k',\n",
       " 'flexivit_large.300ep_in1k',\n",
       " 'flexivit_large.600ep_in1k',\n",
       " 'flexivit_large.1200ep_in1k',\n",
       " 'flexivit_small.300ep_in1k',\n",
       " 'flexivit_small.600ep_in1k',\n",
       " 'flexivit_small.1200ep_in1k',\n",
       " 'focalnet_base_lrf.ms_in1k',\n",
       " 'focalnet_base_srf.ms_in1k',\n",
       " 'focalnet_huge_fl3.ms_in22k',\n",
       " 'focalnet_huge_fl4.ms_in22k',\n",
       " 'focalnet_large_fl3.ms_in22k',\n",
       " 'focalnet_large_fl4.ms_in22k',\n",
       " 'focalnet_small_lrf.ms_in1k',\n",
       " 'focalnet_small_srf.ms_in1k',\n",
       " 'focalnet_tiny_lrf.ms_in1k',\n",
       " 'focalnet_tiny_srf.ms_in1k',\n",
       " 'focalnet_xlarge_fl3.ms_in22k',\n",
       " 'focalnet_xlarge_fl4.ms_in22k',\n",
       " 'gc_efficientnetv2_rw_t.agc_in1k',\n",
       " 'gcresnet33ts.ra2_in1k',\n",
       " 'gcresnet50t.ra2_in1k',\n",
       " 'gcresnext26ts.ch_in1k',\n",
       " 'gcresnext50ts.ch_in1k',\n",
       " 'gcvit_base',\n",
       " 'gcvit_small',\n",
       " 'gcvit_tiny',\n",
       " 'gcvit_xtiny',\n",
       " 'gcvit_xxtiny',\n",
       " 'gernet_l.idstcv_in1k',\n",
       " 'gernet_m.idstcv_in1k',\n",
       " 'gernet_s.idstcv_in1k',\n",
       " 'ghostnet_100',\n",
       " 'gluon_inception_v3',\n",
       " 'gluon_resnet18_v1b',\n",
       " 'gluon_resnet34_v1b',\n",
       " 'gluon_resnet50_v1b',\n",
       " 'gluon_resnet50_v1c',\n",
       " 'gluon_resnet50_v1d',\n",
       " 'gluon_resnet50_v1s',\n",
       " 'gluon_resnet101_v1b',\n",
       " 'gluon_resnet101_v1c',\n",
       " 'gluon_resnet101_v1d',\n",
       " 'gluon_resnet101_v1s',\n",
       " 'gluon_resnet152_v1b',\n",
       " 'gluon_resnet152_v1c',\n",
       " 'gluon_resnet152_v1d',\n",
       " 'gluon_resnet152_v1s',\n",
       " 'gluon_resnext50_32x4d',\n",
       " 'gluon_resnext101_32x4d',\n",
       " 'gluon_resnext101_64x4d',\n",
       " 'gluon_senet154',\n",
       " 'gluon_seresnext50_32x4d',\n",
       " 'gluon_seresnext101_32x4d',\n",
       " 'gluon_seresnext101_64x4d',\n",
       " 'gluon_xception65',\n",
       " 'gmixer_24_224.ra3_in1k',\n",
       " 'gmlp_s16_224.ra3_in1k',\n",
       " 'halo2botnet50ts_256',\n",
       " 'halonet26t',\n",
       " 'halonet50ts',\n",
       " 'haloregnetz_b',\n",
       " 'hardcorenas_a',\n",
       " 'hardcorenas_b',\n",
       " 'hardcorenas_c',\n",
       " 'hardcorenas_d',\n",
       " 'hardcorenas_e',\n",
       " 'hardcorenas_f',\n",
       " 'hrnet_w18',\n",
       " 'hrnet_w18_small',\n",
       " 'hrnet_w18_small_v2',\n",
       " 'hrnet_w30',\n",
       " 'hrnet_w32',\n",
       " 'hrnet_w40',\n",
       " 'hrnet_w44',\n",
       " 'hrnet_w48',\n",
       " 'hrnet_w64',\n",
       " 'ig_resnext101_32x8d',\n",
       " 'ig_resnext101_32x16d',\n",
       " 'ig_resnext101_32x32d',\n",
       " 'ig_resnext101_32x48d',\n",
       " 'inception_resnet_v2',\n",
       " 'inception_v3',\n",
       " 'inception_v4',\n",
       " 'jx_nest_base',\n",
       " 'jx_nest_small',\n",
       " 'jx_nest_tiny',\n",
       " 'lambda_resnet26rpt_256',\n",
       " 'lambda_resnet26t',\n",
       " 'lambda_resnet50ts',\n",
       " 'lamhalobotnet50ts_256',\n",
       " 'lcnet_050.ra2_in1k',\n",
       " 'lcnet_075.ra2_in1k',\n",
       " 'lcnet_100.ra2_in1k',\n",
       " 'legacy_senet154',\n",
       " 'legacy_seresnet18',\n",
       " 'legacy_seresnet34',\n",
       " 'legacy_seresnet50',\n",
       " 'legacy_seresnet101',\n",
       " 'legacy_seresnet152',\n",
       " 'legacy_seresnext26_32x4d',\n",
       " 'legacy_seresnext50_32x4d',\n",
       " 'legacy_seresnext101_32x4d',\n",
       " 'levit_128.fb_dist_in1k',\n",
       " 'levit_128s.fb_dist_in1k',\n",
       " 'levit_192.fb_dist_in1k',\n",
       " 'levit_256.fb_dist_in1k',\n",
       " 'levit_384.fb_dist_in1k',\n",
       " 'levit_conv_128.fb_dist_in1k',\n",
       " 'levit_conv_128s.fb_dist_in1k',\n",
       " 'levit_conv_192.fb_dist_in1k',\n",
       " 'levit_conv_256.fb_dist_in1k',\n",
       " 'levit_conv_384.fb_dist_in1k',\n",
       " 'maxvit_base_tf_224.in1k',\n",
       " 'maxvit_base_tf_384.in1k',\n",
       " 'maxvit_base_tf_384.in21k_ft_in1k',\n",
       " 'maxvit_base_tf_512.in1k',\n",
       " 'maxvit_base_tf_512.in21k_ft_in1k',\n",
       " 'maxvit_large_tf_224.in1k',\n",
       " 'maxvit_large_tf_384.in1k',\n",
       " 'maxvit_large_tf_384.in21k_ft_in1k',\n",
       " 'maxvit_large_tf_512.in1k',\n",
       " 'maxvit_large_tf_512.in21k_ft_in1k',\n",
       " 'maxvit_nano_rw_256.sw_in1k',\n",
       " 'maxvit_rmlp_base_rw_224.sw_in12k',\n",
       " 'maxvit_rmlp_base_rw_224.sw_in12k_ft_in1k',\n",
       " 'maxvit_rmlp_base_rw_384.sw_in12k_ft_in1k',\n",
       " 'maxvit_rmlp_nano_rw_256.sw_in1k',\n",
       " 'maxvit_rmlp_pico_rw_256.sw_in1k',\n",
       " 'maxvit_rmlp_small_rw_224.sw_in1k',\n",
       " 'maxvit_rmlp_tiny_rw_256.sw_in1k',\n",
       " 'maxvit_small_tf_224.in1k',\n",
       " 'maxvit_small_tf_384.in1k',\n",
       " 'maxvit_small_tf_512.in1k',\n",
       " 'maxvit_tiny_rw_224.sw_in1k',\n",
       " 'maxvit_tiny_tf_224.in1k',\n",
       " 'maxvit_tiny_tf_384.in1k',\n",
       " 'maxvit_tiny_tf_512.in1k',\n",
       " 'maxvit_xlarge_tf_384.in21k_ft_in1k',\n",
       " 'maxvit_xlarge_tf_512.in21k_ft_in1k',\n",
       " 'maxxvit_rmlp_nano_rw_256.sw_in1k',\n",
       " 'maxxvit_rmlp_small_rw_256.sw_in1k',\n",
       " 'maxxvitv2_nano_rw_256.sw_in1k',\n",
       " 'maxxvitv2_rmlp_base_rw_224.sw_in12k',\n",
       " 'maxxvitv2_rmlp_base_rw_224.sw_in12k_ft_in1k',\n",
       " 'maxxvitv2_rmlp_base_rw_384.sw_in12k_ft_in1k',\n",
       " 'mixer_b16_224.goog_in21k',\n",
       " 'mixer_b16_224.goog_in21k_ft_in1k',\n",
       " 'mixer_b16_224.miil_in21k',\n",
       " 'mixer_b16_224.miil_in21k_ft_in1k',\n",
       " 'mixer_l16_224.goog_in21k',\n",
       " 'mixer_l16_224.goog_in21k_ft_in1k',\n",
       " 'mixnet_l.ft_in1k',\n",
       " 'mixnet_m.ft_in1k',\n",
       " 'mixnet_s.ft_in1k',\n",
       " 'mixnet_xl.ra_in1k',\n",
       " 'mnasnet_100.rmsp_in1k',\n",
       " 'mnasnet_small.lamb_in1k',\n",
       " 'mobilenetv2_050.lamb_in1k',\n",
       " 'mobilenetv2_100.ra_in1k',\n",
       " 'mobilenetv2_110d.ra_in1k',\n",
       " 'mobilenetv2_120d.ra_in1k',\n",
       " 'mobilenetv2_140.ra_in1k',\n",
       " 'mobilenetv3_large_100.miil_in21k',\n",
       " 'mobilenetv3_large_100.miil_in21k_ft_in1k',\n",
       " 'mobilenetv3_large_100.ra_in1k',\n",
       " 'mobilenetv3_rw.rmsp_in1k',\n",
       " 'mobilenetv3_small_050.lamb_in1k',\n",
       " 'mobilenetv3_small_075.lamb_in1k',\n",
       " 'mobilenetv3_small_100.lamb_in1k',\n",
       " 'mobilevit_s',\n",
       " 'mobilevit_xs',\n",
       " 'mobilevit_xxs',\n",
       " 'mobilevitv2_050',\n",
       " 'mobilevitv2_075',\n",
       " 'mobilevitv2_100',\n",
       " 'mobilevitv2_125',\n",
       " 'mobilevitv2_150',\n",
       " 'mobilevitv2_150_384_in22ft1k',\n",
       " 'mobilevitv2_150_in22ft1k',\n",
       " 'mobilevitv2_175',\n",
       " 'mobilevitv2_175_384_in22ft1k',\n",
       " 'mobilevitv2_175_in22ft1k',\n",
       " 'mobilevitv2_200',\n",
       " 'mobilevitv2_200_384_in22ft1k',\n",
       " 'mobilevitv2_200_in22ft1k',\n",
       " 'mvitv2_base',\n",
       " 'mvitv2_large',\n",
       " 'mvitv2_small',\n",
       " 'mvitv2_tiny',\n",
       " 'nasnetalarge',\n",
       " 'nf_regnet_b1.ra2_in1k',\n",
       " 'nf_resnet50.ra2_in1k',\n",
       " 'nfnet_l0.ra2_in1k',\n",
       " 'pit_b_224',\n",
       " 'pit_b_distilled_224',\n",
       " 'pit_s_224',\n",
       " 'pit_s_distilled_224',\n",
       " 'pit_ti_224',\n",
       " 'pit_ti_distilled_224',\n",
       " 'pit_xs_224',\n",
       " 'pit_xs_distilled_224',\n",
       " 'pnasnet5large',\n",
       " 'poolformer_m36',\n",
       " 'poolformer_m48',\n",
       " 'poolformer_s12',\n",
       " 'poolformer_s24',\n",
       " 'poolformer_s36',\n",
       " 'pvt_v2_b0',\n",
       " 'pvt_v2_b1',\n",
       " 'pvt_v2_b2',\n",
       " 'pvt_v2_b2_li',\n",
       " 'pvt_v2_b3',\n",
       " 'pvt_v2_b4',\n",
       " 'pvt_v2_b5',\n",
       " 'regnetv_040.ra3_in1k',\n",
       " 'regnetv_064.ra3_in1k',\n",
       " 'regnetx_002.pycls_in1k',\n",
       " 'regnetx_004.pycls_in1k',\n",
       " 'regnetx_004_tv.tv2_in1k',\n",
       " 'regnetx_006.pycls_in1k',\n",
       " 'regnetx_008.pycls_in1k',\n",
       " 'regnetx_008.tv2_in1k',\n",
       " 'regnetx_016.pycls_in1k',\n",
       " 'regnetx_016.tv2_in1k',\n",
       " 'regnetx_032.pycls_in1k',\n",
       " 'regnetx_032.tv2_in1k',\n",
       " 'regnetx_040.pycls_in1k',\n",
       " 'regnetx_064.pycls_in1k',\n",
       " 'regnetx_080.pycls_in1k',\n",
       " 'regnetx_080.tv2_in1k',\n",
       " 'regnetx_120.pycls_in1k',\n",
       " 'regnetx_160.pycls_in1k',\n",
       " 'regnetx_160.tv2_in1k',\n",
       " 'regnetx_320.pycls_in1k',\n",
       " 'regnetx_320.tv2_in1k',\n",
       " 'regnety_002.pycls_in1k',\n",
       " 'regnety_004.pycls_in1k',\n",
       " 'regnety_004.tv2_in1k',\n",
       " 'regnety_006.pycls_in1k',\n",
       " 'regnety_008.pycls_in1k',\n",
       " 'regnety_008_tv.tv2_in1k',\n",
       " 'regnety_016.pycls_in1k',\n",
       " 'regnety_016.tv2_in1k',\n",
       " 'regnety_032.pycls_in1k',\n",
       " 'regnety_032.ra_in1k',\n",
       " 'regnety_032.tv2_in1k',\n",
       " 'regnety_040.pycls_in1k',\n",
       " 'regnety_040.ra3_in1k',\n",
       " 'regnety_064.pycls_in1k',\n",
       " 'regnety_064.ra3_in1k',\n",
       " 'regnety_080.pycls_in1k',\n",
       " 'regnety_080.ra3_in1k',\n",
       " 'regnety_080_tv.tv2_in1k',\n",
       " 'regnety_120.pycls_in1k',\n",
       " 'regnety_120.sw_in12k',\n",
       " 'regnety_120.sw_in12k_ft_in1k',\n",
       " 'regnety_160.deit_in1k',\n",
       " 'regnety_160.lion_in12k_ft_in1k',\n",
       " 'regnety_160.pycls_in1k',\n",
       " 'regnety_160.sw_in12k',\n",
       " 'regnety_160.sw_in12k_ft_in1k',\n",
       " 'regnety_160.swag_ft_in1k',\n",
       " 'regnety_160.swag_lc_in1k',\n",
       " 'regnety_160.tv2_in1k',\n",
       " 'regnety_320.pycls_in1k',\n",
       " 'regnety_320.seer',\n",
       " 'regnety_320.seer_ft_in1k',\n",
       " 'regnety_320.swag_ft_in1k',\n",
       " 'regnety_320.swag_lc_in1k',\n",
       " 'regnety_320.tv2_in1k',\n",
       " 'regnety_640.seer',\n",
       " 'regnety_640.seer_ft_in1k',\n",
       " 'regnety_1280.seer',\n",
       " 'regnety_1280.seer_ft_in1k',\n",
       " 'regnety_1280.swag_ft_in1k',\n",
       " 'regnety_1280.swag_lc_in1k',\n",
       " 'regnety_2560.seer_ft_in1k',\n",
       " 'regnetz_040.ra3_in1k',\n",
       " 'regnetz_040_h.ra3_in1k',\n",
       " 'regnetz_b16.ra3_in1k',\n",
       " 'regnetz_c16.ra3_in1k',\n",
       " 'regnetz_c16_evos.ch_in1k',\n",
       " 'regnetz_d8.ra3_in1k',\n",
       " 'regnetz_d8_evos.ch_in1k',\n",
       " 'regnetz_d32.ra3_in1k',\n",
       " 'regnetz_e8.ra3_in1k',\n",
       " 'repvgg_a2.rvgg_in1k',\n",
       " 'repvgg_b0.rvgg_in1k',\n",
       " 'repvgg_b1.rvgg_in1k',\n",
       " 'repvgg_b1g4.rvgg_in1k',\n",
       " 'repvgg_b2.rvgg_in1k',\n",
       " 'repvgg_b2g4.rvgg_in1k',\n",
       " 'repvgg_b3.rvgg_in1k',\n",
       " 'repvgg_b3g4.rvgg_in1k',\n",
       " 'res2net50_14w_8s',\n",
       " 'res2net50_26w_4s',\n",
       " 'res2net50_26w_6s',\n",
       " 'res2net50_26w_8s',\n",
       " 'res2net50_48w_2s',\n",
       " 'res2net101_26w_4s',\n",
       " 'res2next50',\n",
       " 'resmlp_12_224.fb_dino',\n",
       " 'resmlp_12_224.fb_distilled_in1k',\n",
       " 'resmlp_12_224.fb_in1k',\n",
       " 'resmlp_24_224.fb_dino',\n",
       " 'resmlp_24_224.fb_distilled_in1k',\n",
       " 'resmlp_24_224.fb_in1k',\n",
       " 'resmlp_36_224.fb_distilled_in1k',\n",
       " 'resmlp_36_224.fb_in1k',\n",
       " 'resmlp_big_24_224.fb_distilled_in1k',\n",
       " 'resmlp_big_24_224.fb_in1k',\n",
       " 'resmlp_big_24_224.fb_in22k_ft_in1k',\n",
       " 'resnest14d',\n",
       " 'resnest26d',\n",
       " 'resnest50d',\n",
       " 'resnest50d_1s4x24d',\n",
       " 'resnest50d_4s2x40d',\n",
       " 'resnest101e',\n",
       " 'resnest200e',\n",
       " 'resnest269e',\n",
       " 'resnet10t',\n",
       " 'resnet14t',\n",
       " 'resnet18',\n",
       " 'resnet18d',\n",
       " 'resnet26',\n",
       " 'resnet26d',\n",
       " 'resnet26t',\n",
       " 'resnet32ts.ra2_in1k',\n",
       " 'resnet33ts.ra2_in1k',\n",
       " 'resnet34',\n",
       " 'resnet34d',\n",
       " 'resnet50',\n",
       " 'resnet50_gn',\n",
       " 'resnet50d',\n",
       " 'resnet51q.ra2_in1k',\n",
       " 'resnet61q.ra2_in1k',\n",
       " 'resnet101',\n",
       " 'resnet101d',\n",
       " 'resnet152',\n",
       " 'resnet152d',\n",
       " 'resnet200d',\n",
       " 'resnetaa50',\n",
       " 'resnetblur50',\n",
       " 'resnetrs50',\n",
       " 'resnetrs101',\n",
       " 'resnetrs152',\n",
       " 'resnetrs200',\n",
       " 'resnetrs270',\n",
       " 'resnetrs350',\n",
       " 'resnetrs420',\n",
       " 'resnetv2_50.a1h_in1k',\n",
       " 'resnetv2_50d_evos.ah_in1k',\n",
       " 'resnetv2_50d_gn.ah_in1k',\n",
       " 'resnetv2_50x1_bit.goog_distilled_in1k',\n",
       " 'resnetv2_50x1_bit.goog_in21k',\n",
       " 'resnetv2_50x1_bit.goog_in21k_ft_in1k',\n",
       " 'resnetv2_50x3_bit.goog_in21k',\n",
       " 'resnetv2_50x3_bit.goog_in21k_ft_in1k',\n",
       " 'resnetv2_101.a1h_in1k',\n",
       " 'resnetv2_101x1_bit.goog_in21k',\n",
       " 'resnetv2_101x1_bit.goog_in21k_ft_in1k',\n",
       " 'resnetv2_101x3_bit.goog_in21k',\n",
       " 'resnetv2_101x3_bit.goog_in21k_ft_in1k',\n",
       " 'resnetv2_152x2_bit.goog_in21k',\n",
       " 'resnetv2_152x2_bit.goog_in21k_ft_in1k',\n",
       " 'resnetv2_152x2_bit.goog_teacher_in21k_ft_in1k',\n",
       " 'resnetv2_152x2_bit.goog_teacher_in21k_ft_in1k_384',\n",
       " 'resnetv2_152x4_bit.goog_in21k',\n",
       " 'resnetv2_152x4_bit.goog_in21k_ft_in1k',\n",
       " 'resnext26ts.ra2_in1k',\n",
       " 'resnext50_32x4d',\n",
       " 'resnext50d_32x4d',\n",
       " 'resnext101_32x8d',\n",
       " 'resnext101_64x4d',\n",
       " 'rexnet_100.nav_in1k',\n",
       " 'rexnet_130.nav_in1k',\n",
       " 'rexnet_150.nav_in1k',\n",
       " 'rexnet_200.nav_in1k',\n",
       " 'rexnet_300.nav_in1k',\n",
       " 'rexnetr_200.sw_in12k',\n",
       " 'rexnetr_200.sw_in12k_ft_in1k',\n",
       " 'rexnetr_300.sw_in12k',\n",
       " 'rexnetr_300.sw_in12k_ft_in1k',\n",
       " 'sebotnet33ts_256',\n",
       " 'sehalonet33ts',\n",
       " 'selecsls42b',\n",
       " 'selecsls60',\n",
       " 'selecsls60b',\n",
       " 'semnasnet_075.rmsp_in1k',\n",
       " 'semnasnet_100.rmsp_in1k',\n",
       " 'sequencer2d_l',\n",
       " 'sequencer2d_m',\n",
       " 'sequencer2d_s',\n",
       " 'seresnet33ts.ra2_in1k',\n",
       " 'seresnet50',\n",
       " 'seresnet152d',\n",
       " 'seresnext26d_32x4d',\n",
       " 'seresnext26t_32x4d',\n",
       " 'seresnext26ts.ch_in1k',\n",
       " 'seresnext50_32x4d',\n",
       " 'seresnext101_32x8d',\n",
       " 'seresnext101d_32x8d',\n",
       " 'seresnextaa101d_32x8d',\n",
       " 'skresnet18',\n",
       " 'skresnet34',\n",
       " 'skresnext50_32x4d',\n",
       " 'spnasnet_100.rmsp_in1k',\n",
       " 'ssl_resnet18',\n",
       " 'ssl_resnet50',\n",
       " 'ssl_resnext50_32x4d',\n",
       " 'ssl_resnext101_32x4d',\n",
       " 'ssl_resnext101_32x8d',\n",
       " 'ssl_resnext101_32x16d',\n",
       " 'swin_base_patch4_window7_224.ms_in1k',\n",
       " 'swin_base_patch4_window7_224.ms_in22k',\n",
       " 'swin_base_patch4_window7_224.ms_in22k_ft_in1k',\n",
       " 'swin_base_patch4_window12_384.ms_in1k',\n",
       " 'swin_base_patch4_window12_384.ms_in22k',\n",
       " 'swin_base_patch4_window12_384.ms_in22k_ft_in1k',\n",
       " 'swin_large_patch4_window7_224.ms_in22k',\n",
       " 'swin_large_patch4_window7_224.ms_in22k_ft_in1k',\n",
       " 'swin_large_patch4_window12_384.ms_in22k',\n",
       " 'swin_large_patch4_window12_384.ms_in22k_ft_in1k',\n",
       " 'swin_s3_base_224.ms_in1k',\n",
       " 'swin_s3_small_224.ms_in1k',\n",
       " 'swin_s3_tiny_224.ms_in1k',\n",
       " 'swin_small_patch4_window7_224.ms_in1k',\n",
       " 'swin_small_patch4_window7_224.ms_in22k',\n",
       " 'swin_small_patch4_window7_224.ms_in22k_ft_in1k',\n",
       " 'swin_tiny_patch4_window7_224.ms_in1k',\n",
       " 'swin_tiny_patch4_window7_224.ms_in22k',\n",
       " 'swin_tiny_patch4_window7_224.ms_in22k_ft_in1k',\n",
       " 'swinv2_base_window8_256.ms_in1k',\n",
       " 'swinv2_base_window12_192.ms_in22k',\n",
       " 'swinv2_base_window12to16_192to256.ms_in22k_ft_in1k',\n",
       " 'swinv2_base_window12to24_192to384.ms_in22k_ft_in1k',\n",
       " 'swinv2_base_window16_256.ms_in1k',\n",
       " 'swinv2_cr_small_224.sw_in1k',\n",
       " 'swinv2_cr_small_ns_224.sw_in1k',\n",
       " 'swinv2_cr_tiny_ns_224.sw_in1k',\n",
       " 'swinv2_large_window12_192.ms_in22k',\n",
       " 'swinv2_large_window12to16_192to256.ms_in22k_ft_in1k',\n",
       " 'swinv2_large_window12to24_192to384.ms_in22k_ft_in1k',\n",
       " 'swinv2_small_window8_256.ms_in1k',\n",
       " 'swinv2_small_window16_256.ms_in1k',\n",
       " 'swinv2_tiny_window8_256.ms_in1k',\n",
       " 'swinv2_tiny_window16_256.ms_in1k',\n",
       " 'swsl_resnet18',\n",
       " 'swsl_resnet50',\n",
       " 'swsl_resnext50_32x4d',\n",
       " 'swsl_resnext101_32x4d',\n",
       " 'swsl_resnext101_32x8d',\n",
       " 'swsl_resnext101_32x16d',\n",
       " 'tf_efficientnet_b0.aa_in1k',\n",
       " 'tf_efficientnet_b0.ap_in1k',\n",
       " 'tf_efficientnet_b0.ns_jft_in1k',\n",
       " 'tf_efficientnet_b1.aa_in1k',\n",
       " 'tf_efficientnet_b1.ap_in1k',\n",
       " 'tf_efficientnet_b1.ns_jft_in1k',\n",
       " 'tf_efficientnet_b2.aa_in1k',\n",
       " 'tf_efficientnet_b2.ap_in1k',\n",
       " 'tf_efficientnet_b2.ns_jft_in1k',\n",
       " 'tf_efficientnet_b3.aa_in1k',\n",
       " 'tf_efficientnet_b3.ap_in1k',\n",
       " 'tf_efficientnet_b3.ns_jft_in1k',\n",
       " 'tf_efficientnet_b4.aa_in1k',\n",
       " 'tf_efficientnet_b4.ap_in1k',\n",
       " 'tf_efficientnet_b4.ns_jft_in1k',\n",
       " 'tf_efficientnet_b5.ap_in1k',\n",
       " 'tf_efficientnet_b5.ns_jft_in1k',\n",
       " 'tf_efficientnet_b5.ra_in1k',\n",
       " 'tf_efficientnet_b6.aa_in1k',\n",
       " 'tf_efficientnet_b6.ap_in1k',\n",
       " 'tf_efficientnet_b6.ns_jft_in1k',\n",
       " 'tf_efficientnet_b7.ap_in1k',\n",
       " 'tf_efficientnet_b7.ns_jft_in1k',\n",
       " 'tf_efficientnet_b7.ra_in1k',\n",
       " 'tf_efficientnet_b8.ap_in1k',\n",
       " 'tf_efficientnet_b8.ra_in1k',\n",
       " 'tf_efficientnet_cc_b0_4e.in1k',\n",
       " 'tf_efficientnet_cc_b0_8e.in1k',\n",
       " 'tf_efficientnet_cc_b1_8e.in1k',\n",
       " 'tf_efficientnet_el.in1k',\n",
       " 'tf_efficientnet_em.in1k',\n",
       " 'tf_efficientnet_es.in1k',\n",
       " 'tf_efficientnet_l2.ns_jft_in1k',\n",
       " 'tf_efficientnet_l2.ns_jft_in1k_475',\n",
       " 'tf_efficientnet_lite0.in1k',\n",
       " 'tf_efficientnet_lite1.in1k',\n",
       " 'tf_efficientnet_lite2.in1k',\n",
       " 'tf_efficientnet_lite3.in1k',\n",
       " 'tf_efficientnet_lite4.in1k',\n",
       " 'tf_efficientnetv2_b0.in1k',\n",
       " 'tf_efficientnetv2_b1.in1k',\n",
       " 'tf_efficientnetv2_b2.in1k',\n",
       " 'tf_efficientnetv2_b3.in1k',\n",
       " 'tf_efficientnetv2_b3.in21k',\n",
       " 'tf_efficientnetv2_b3.in21k_ft_in1k',\n",
       " 'tf_efficientnetv2_l.in1k',\n",
       " 'tf_efficientnetv2_l.in21k',\n",
       " 'tf_efficientnetv2_l.in21k_ft_in1k',\n",
       " 'tf_efficientnetv2_m.in1k',\n",
       " 'tf_efficientnetv2_m.in21k',\n",
       " 'tf_efficientnetv2_m.in21k_ft_in1k',\n",
       " 'tf_efficientnetv2_s.in1k',\n",
       " 'tf_efficientnetv2_s.in21k',\n",
       " 'tf_efficientnetv2_s.in21k_ft_in1k',\n",
       " 'tf_efficientnetv2_xl.in21k',\n",
       " 'tf_efficientnetv2_xl.in21k_ft_in1k',\n",
       " 'tf_inception_v3',\n",
       " 'tf_mixnet_l.in1k',\n",
       " 'tf_mixnet_m.in1k',\n",
       " 'tf_mixnet_s.in1k',\n",
       " 'tf_mobilenetv3_large_075.in1k',\n",
       " 'tf_mobilenetv3_large_100.in1k',\n",
       " 'tf_mobilenetv3_large_minimal_100.in1k',\n",
       " 'tf_mobilenetv3_small_075.in1k',\n",
       " 'tf_mobilenetv3_small_100.in1k',\n",
       " 'tf_mobilenetv3_small_minimal_100.in1k',\n",
       " 'tinynet_a.in1k',\n",
       " 'tinynet_b.in1k',\n",
       " 'tinynet_c.in1k',\n",
       " 'tinynet_d.in1k',\n",
       " 'tinynet_e.in1k',\n",
       " 'tnt_s_patch16_224',\n",
       " 'tresnet_l',\n",
       " 'tresnet_l_448',\n",
       " 'tresnet_m',\n",
       " 'tresnet_m_448',\n",
       " 'tresnet_m_miil_in21k',\n",
       " 'tresnet_v2_l',\n",
       " 'tresnet_xl',\n",
       " 'tresnet_xl_448',\n",
       " 'tv_densenet121',\n",
       " 'tv_resnet34',\n",
       " 'tv_resnet50',\n",
       " 'tv_resnet101',\n",
       " 'tv_resnet152',\n",
       " 'tv_resnext50_32x4d',\n",
       " 'twins_pcpvt_base',\n",
       " 'twins_pcpvt_large',\n",
       " 'twins_pcpvt_small',\n",
       " 'twins_svt_base',\n",
       " 'twins_svt_large',\n",
       " 'twins_svt_small',\n",
       " 'vgg11',\n",
       " 'vgg11_bn',\n",
       " 'vgg13',\n",
       " 'vgg13_bn',\n",
       " 'vgg16',\n",
       " 'vgg16_bn',\n",
       " 'vgg19',\n",
       " 'vgg19_bn',\n",
       " 'visformer_small',\n",
       " 'vit_base_patch8_224.augreg2_in21k_ft_in1k',\n",
       " 'vit_base_patch8_224.augreg_in21k',\n",
       " 'vit_base_patch8_224.augreg_in21k_ft_in1k',\n",
       " 'vit_base_patch8_224.dino',\n",
       " 'vit_base_patch16_224.augreg2_in21k_ft_in1k',\n",
       " 'vit_base_patch16_224.augreg_in1k',\n",
       " 'vit_base_patch16_224.augreg_in21k',\n",
       " 'vit_base_patch16_224.augreg_in21k_ft_in1k',\n",
       " 'vit_base_patch16_224.dino',\n",
       " 'vit_base_patch16_224.orig_in21k_ft_in1k',\n",
       " 'vit_base_patch16_224.sam',\n",
       " 'vit_base_patch16_224_miil.in21k',\n",
       " 'vit_base_patch16_224_miil.in21k_ft_in1k',\n",
       " 'vit_base_patch16_384.augreg_in1k',\n",
       " 'vit_base_patch16_384.augreg_in21k_ft_in1k',\n",
       " 'vit_base_patch16_384.orig_in21k_ft_in1k',\n",
       " 'vit_base_patch16_clip_224.laion2b_ft_in1k',\n",
       " 'vit_base_patch16_clip_224.laion2b_ft_in12k',\n",
       " 'vit_base_patch16_clip_224.laion2b_ft_in12k_in1k',\n",
       " 'vit_base_patch16_clip_224.openai',\n",
       " 'vit_base_patch16_clip_224.openai_ft_in1k',\n",
       " 'vit_base_patch16_clip_224.openai_ft_in12k',\n",
       " 'vit_base_patch16_clip_224.openai_ft_in12k_in1k',\n",
       " 'vit_base_patch16_clip_384.laion2b_ft_in1k',\n",
       " 'vit_base_patch16_clip_384.laion2b_ft_in12k_in1k',\n",
       " 'vit_base_patch16_clip_384.openai_ft_in1k',\n",
       " 'vit_base_patch16_clip_384.openai_ft_in12k_in1k',\n",
       " 'vit_base_patch16_rpn_224.in1k',\n",
       " 'vit_base_patch32_224.augreg_in1k',\n",
       " 'vit_base_patch32_224.augreg_in21k',\n",
       " 'vit_base_patch32_224.augreg_in21k_ft_in1k',\n",
       " 'vit_base_patch32_224.sam',\n",
       " 'vit_base_patch32_384.augreg_in1k',\n",
       " 'vit_base_patch32_384.augreg_in21k_ft_in1k',\n",
       " 'vit_base_patch32_clip_224.laion2b',\n",
       " 'vit_base_patch32_clip_224.laion2b_ft_in1k',\n",
       " 'vit_base_patch32_clip_224.laion2b_ft_in12k_in1k',\n",
       " 'vit_base_patch32_clip_224.openai',\n",
       " 'vit_base_patch32_clip_224.openai_ft_in1k',\n",
       " 'vit_base_patch32_clip_384.laion2b_ft_in12k_in1k',\n",
       " 'vit_base_patch32_clip_384.openai_ft_in12k_in1k',\n",
       " 'vit_base_patch32_clip_448.laion2b_ft_in12k_in1k',\n",
       " 'vit_base_r50_s16_224.orig_in21k',\n",
       " 'vit_base_r50_s16_384.orig_in21k_ft_in1k',\n",
       " 'vit_giant_patch14_clip_224.laion2b',\n",
       " 'vit_gigantic_patch14_clip_224.laion2b',\n",
       " 'vit_huge_patch14_224.orig_in21k',\n",
       " 'vit_huge_patch14_clip_224.laion2b',\n",
       " 'vit_huge_patch14_clip_224.laion2b_ft_in1k',\n",
       " 'vit_huge_patch14_clip_224.laion2b_ft_in12k',\n",
       " 'vit_huge_patch14_clip_224.laion2b_ft_in12k_in1k',\n",
       " 'vit_huge_patch14_clip_336.laion2b_ft_in12k_in1k',\n",
       " 'vit_large_patch14_clip_224.laion2b',\n",
       " 'vit_large_patch14_clip_224.laion2b_ft_in1k',\n",
       " 'vit_large_patch14_clip_224.laion2b_ft_in12k',\n",
       " 'vit_large_patch14_clip_224.laion2b_ft_in12k_in1k',\n",
       " 'vit_large_patch14_clip_224.openai',\n",
       " 'vit_large_patch14_clip_224.openai_ft_in1k',\n",
       " 'vit_large_patch14_clip_224.openai_ft_in12k',\n",
       " 'vit_large_patch14_clip_224.openai_ft_in12k_in1k',\n",
       " 'vit_large_patch14_clip_336.laion2b_ft_in1k',\n",
       " 'vit_large_patch14_clip_336.laion2b_ft_in12k_in1k',\n",
       " 'vit_large_patch14_clip_336.openai_ft_in12k_in1k',\n",
       " 'vit_large_patch16_224.augreg_in21k',\n",
       " 'vit_large_patch16_224.augreg_in21k_ft_in1k',\n",
       " 'vit_large_patch16_384.augreg_in21k_ft_in1k',\n",
       " 'vit_large_patch32_224.orig_in21k',\n",
       " 'vit_large_patch32_384.orig_in21k_ft_in1k',\n",
       " 'vit_large_r50_s32_224.augreg_in21k',\n",
       " 'vit_large_r50_s32_224.augreg_in21k_ft_in1k',\n",
       " 'vit_large_r50_s32_384.augreg_in21k_ft_in1k',\n",
       " 'vit_medium_patch16_gap_240.in12k',\n",
       " 'vit_medium_patch16_gap_256.in12k_ft_in1k',\n",
       " 'vit_medium_patch16_gap_384.in12k_ft_in1k',\n",
       " 'vit_relpos_base_patch16_224.sw_in1k',\n",
       " 'vit_relpos_base_patch16_clsgap_224.sw_in1k',\n",
       " 'vit_relpos_base_patch32_plus_rpn_256.sw_in1k',\n",
       " 'vit_relpos_medium_patch16_224.sw_in1k',\n",
       " 'vit_relpos_medium_patch16_cls_224.sw_in1k',\n",
       " 'vit_relpos_medium_patch16_rpn_224.sw_in1k',\n",
       " 'vit_relpos_small_patch16_224.sw_in1k',\n",
       " 'vit_small_patch8_224.dino',\n",
       " 'vit_small_patch16_224.augreg_in1k',\n",
       " 'vit_small_patch16_224.augreg_in21k',\n",
       " 'vit_small_patch16_224.augreg_in21k_ft_in1k',\n",
       " 'vit_small_patch16_224.dino',\n",
       " 'vit_small_patch16_384.augreg_in1k',\n",
       " 'vit_small_patch16_384.augreg_in21k_ft_in1k',\n",
       " 'vit_small_patch32_224.augreg_in21k',\n",
       " 'vit_small_patch32_224.augreg_in21k_ft_in1k',\n",
       " 'vit_small_patch32_384.augreg_in21k_ft_in1k',\n",
       " 'vit_small_r26_s32_224.augreg_in21k',\n",
       " 'vit_small_r26_s32_224.augreg_in21k_ft_in1k',\n",
       " 'vit_small_r26_s32_384.augreg_in21k_ft_in1k',\n",
       " 'vit_srelpos_medium_patch16_224.sw_in1k',\n",
       " 'vit_srelpos_small_patch16_224.sw_in1k',\n",
       " 'vit_tiny_patch16_224.augreg_in21k',\n",
       " 'vit_tiny_patch16_224.augreg_in21k_ft_in1k',\n",
       " 'vit_tiny_patch16_384.augreg_in21k_ft_in1k',\n",
       " 'vit_tiny_r_s16_p8_224.augreg_in21k',\n",
       " 'vit_tiny_r_s16_p8_224.augreg_in21k_ft_in1k',\n",
       " 'vit_tiny_r_s16_p8_384.augreg_in21k_ft_in1k',\n",
       " 'volo_d1_224',\n",
       " 'volo_d1_384',\n",
       " 'volo_d2_224',\n",
       " 'volo_d2_384',\n",
       " 'volo_d3_224',\n",
       " 'volo_d3_448',\n",
       " 'volo_d4_224',\n",
       " 'volo_d4_448',\n",
       " 'volo_d5_224',\n",
       " 'volo_d5_448',\n",
       " 'volo_d5_512',\n",
       " 'wide_resnet50_2',\n",
       " 'wide_resnet101_2',\n",
       " 'xception',\n",
       " 'xception41',\n",
       " 'xception41p',\n",
       " 'xception65',\n",
       " 'xception65p',\n",
       " 'xception71',\n",
       " 'xcit_large_24_p8_224',\n",
       " 'xcit_large_24_p8_224_dist',\n",
       " 'xcit_large_24_p8_384_dist',\n",
       " 'xcit_large_24_p16_224',\n",
       " 'xcit_large_24_p16_224_dist',\n",
       " 'xcit_large_24_p16_384_dist',\n",
       " 'xcit_medium_24_p8_224',\n",
       " 'xcit_medium_24_p8_224_dist',\n",
       " 'xcit_medium_24_p8_384_dist',\n",
       " 'xcit_medium_24_p16_224',\n",
       " 'xcit_medium_24_p16_224_dist',\n",
       " 'xcit_medium_24_p16_384_dist',\n",
       " 'xcit_nano_12_p8_224',\n",
       " 'xcit_nano_12_p8_224_dist',\n",
       " 'xcit_nano_12_p8_384_dist',\n",
       " 'xcit_nano_12_p16_224',\n",
       " 'xcit_nano_12_p16_224_dist',\n",
       " 'xcit_nano_12_p16_384_dist',\n",
       " 'xcit_small_12_p8_224',\n",
       " 'xcit_small_12_p8_224_dist',\n",
       " 'xcit_small_12_p8_384_dist',\n",
       " 'xcit_small_12_p16_224',\n",
       " 'xcit_small_12_p16_224_dist',\n",
       " 'xcit_small_12_p16_384_dist',\n",
       " 'xcit_small_24_p8_224',\n",
       " 'xcit_small_24_p8_224_dist',\n",
       " 'xcit_small_24_p8_384_dist',\n",
       " 'xcit_small_24_p16_224',\n",
       " 'xcit_small_24_p16_224_dist',\n",
       " 'xcit_small_24_p16_384_dist',\n",
       " 'xcit_tiny_12_p8_224',\n",
       " 'xcit_tiny_12_p8_224_dist',\n",
       " 'xcit_tiny_12_p8_384_dist',\n",
       " 'xcit_tiny_12_p16_224',\n",
       " 'xcit_tiny_12_p16_224_dist',\n",
       " 'xcit_tiny_12_p16_384_dist',\n",
       " 'xcit_tiny_24_p8_224',\n",
       " 'xcit_tiny_24_p8_224_dist',\n",
       " 'xcit_tiny_24_p8_384_dist',\n",
       " 'xcit_tiny_24_p16_224',\n",
       " 'xcit_tiny_24_p16_224_dist',\n",
       " 'xcit_tiny_24_p16_384_dist']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timm.list_models(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d8029a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fold': 0,\n",
       " 'epoch': 50,\n",
       " 'model_name': 'tf_efficientnet_b0_ns',\n",
       " 'soft_target': 0.9,\n",
       " 'finetune': False,\n",
       " 'img_size': 128,\n",
       " 'batch_size': 64,\n",
       " 'gradient_accumulation': 1,\n",
       " 'gradient_checkpoint': False,\n",
       " 'drop_out': 0.3,\n",
       " 'drop_path': 0.2,\n",
       " 'mixup': 0.65,\n",
       " 'lr': 6e-05,\n",
       " 'weight_decay': 0.0005,\n",
       " 'num_classes': 264,\n",
       " 'load_model': 'pretrained/nfnet_l0.pth',\n",
       " 'save_model': './train_model'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CFG= {\n",
    "    'fold': 0,\n",
    "    'epoch': 50,\n",
    "    'model_name': 'tf_efficientnet_b0_ns',\n",
    "    'soft_target': 0.9,\n",
    "    'finetune': False,\n",
    "    \n",
    "    'img_size': 128,\n",
    "    'batch_size': 64,\n",
    "    'gradient_accumulation': 1,\n",
    "    'gradient_checkpoint': False,\n",
    "    'drop_out': 0.3,\n",
    "    'drop_path': 0.2,\n",
    "    'mixup': 0.65,\n",
    "    \n",
    "    'lr': 6e-5,\n",
    "    'weight_decay': 5e-4,\n",
    "    \n",
    "    'num_classes': 264,\n",
    "    'load_model': 'pretrained/nfnet_l0.pth',\n",
    "    'save_model': './train_model'\n",
    "}\n",
    "\n",
    "if CFG['finetune']:\n",
    "    CFG['lr']= 6e-6\n",
    "    CFG['load_model']= f\"./train_model/cv{CFG['fold']}_best.pth\"\n",
    "#     CFG['load_model']= f\"./train_model/cv{CFG['fold']}_ep30.pth\"\n",
    "CFG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3aa7835",
   "metadata": {},
   "source": [
    "# Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9be52de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>label</th>\n",
       "      <th>label_name</th>\n",
       "      <th>group</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data/train_img_ex2020\\barswa\\XC134349._15804.png</td>\n",
       "      <td>20</td>\n",
       "      <td>barswa</td>\n",
       "      <td>XC134349.</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data/train_img_ex2020\\barswa\\XC134349._15805.png</td>\n",
       "      <td>20</td>\n",
       "      <td>barswa</td>\n",
       "      <td>XC134349.</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data/train_img_ex2020\\barswa\\XC134349._15806.png</td>\n",
       "      <td>20</td>\n",
       "      <td>barswa</td>\n",
       "      <td>XC134349.</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data/train_img_ex2020\\barswa\\XC134349._15807.png</td>\n",
       "      <td>20</td>\n",
       "      <td>barswa</td>\n",
       "      <td>XC134349.</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data/train_img_ex2020\\barswa\\XC134349._15808.png</td>\n",
       "      <td>20</td>\n",
       "      <td>barswa</td>\n",
       "      <td>XC134349.</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17325</th>\n",
       "      <td>Data/train_img_ex1\\greegr\\XC58490._95648.png</td>\n",
       "      <td>106</td>\n",
       "      <td>greegr</td>\n",
       "      <td>XC58490.</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17326</th>\n",
       "      <td>Data/train_img_ex1\\greegr\\XC586205._95649.png</td>\n",
       "      <td>106</td>\n",
       "      <td>greegr</td>\n",
       "      <td>XC586205.</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17327</th>\n",
       "      <td>Data/train_img_ex1\\greegr\\XC84914._95650.png</td>\n",
       "      <td>106</td>\n",
       "      <td>greegr</td>\n",
       "      <td>XC84914.</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17328</th>\n",
       "      <td>Data/train_img_ex1\\greegr\\XC84914._95651.png</td>\n",
       "      <td>106</td>\n",
       "      <td>greegr</td>\n",
       "      <td>XC84914.</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17329</th>\n",
       "      <td>Data/train_img_ex1\\greegr\\XC84914._95652.png</td>\n",
       "      <td>106</td>\n",
       "      <td>greegr</td>\n",
       "      <td>XC84914.</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17330 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             image_path  label label_name   \n",
       "0      Data/train_img_ex2020\\barswa\\XC134349._15804.png     20     barswa  \\\n",
       "1      Data/train_img_ex2020\\barswa\\XC134349._15805.png     20     barswa   \n",
       "2      Data/train_img_ex2020\\barswa\\XC134349._15806.png     20     barswa   \n",
       "3      Data/train_img_ex2020\\barswa\\XC134349._15807.png     20     barswa   \n",
       "4      Data/train_img_ex2020\\barswa\\XC134349._15808.png     20     barswa   \n",
       "...                                                 ...    ...        ...   \n",
       "17325      Data/train_img_ex1\\greegr\\XC58490._95648.png    106     greegr   \n",
       "17326     Data/train_img_ex1\\greegr\\XC586205._95649.png    106     greegr   \n",
       "17327      Data/train_img_ex1\\greegr\\XC84914._95650.png    106     greegr   \n",
       "17328      Data/train_img_ex1\\greegr\\XC84914._95651.png    106     greegr   \n",
       "17329      Data/train_img_ex1\\greegr\\XC84914._95652.png    106     greegr   \n",
       "\n",
       "           group  fold  \n",
       "0      XC134349.   1.0  \n",
       "1      XC134349.   1.0  \n",
       "2      XC134349.   1.0  \n",
       "3      XC134349.   1.0  \n",
       "4      XC134349.   1.0  \n",
       "...          ...   ...  \n",
       "17325   XC58490.   2.0  \n",
       "17326  XC586205.   4.0  \n",
       "17327   XC84914.   2.0  \n",
       "17328   XC84914.   2.0  \n",
       "17329   XC84914.   2.0  \n",
       "\n",
       "[17330 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.read_csv('Data/train.csv')\n",
    "label_name= list(df['label_name'].unique())\n",
    "\n",
    "df_1= pd.read_csv('Data/train_ex2020.csv')\n",
    "df_2= pd.read_csv('Data/train_ex2021.csv')\n",
    "df_3= pd.read_csv('Data/train_ex2022.csv')\n",
    "df_4= pd.read_csv('Data/train_ex1.csv')\n",
    "ex_df= pd.concat([df_1, df_2, df_3, df_4], axis=0)\n",
    "ex_df= ex_df[ex_df['label_name'].isin(label_name)].reset_index(drop=True)\n",
    "\n",
    "la= list(ex_df['label_name'].unique())\n",
    "for l in la:\n",
    "    ex_df.loc[ ex_df['label_name']==l, 'label' ]= label_name.index(l)\n",
    "ex_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0010c7a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9d7fbac9ae04ed9911806b111016cf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/264 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataset: 56644\n",
      "valid dataset: 26194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\kaggle_smbcd\\lib\\site-packages\\albumentations\\augmentations\\dropout\\cutout.py:49: FutureWarning: Cutout has been deprecated. Please use CoarseDropout\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>label</th>\n",
       "      <th>label_name</th>\n",
       "      <th>group</th>\n",
       "      <th>fold</th>\n",
       "      <th>2nd_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data/train_img\\abethr1\\XC128013._0.png</td>\n",
       "      <td>0</td>\n",
       "      <td>abethr1</td>\n",
       "      <td>XC128013.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data/train_img\\abethr1\\XC128013._1.png</td>\n",
       "      <td>0</td>\n",
       "      <td>abethr1</td>\n",
       "      <td>XC128013.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data/train_img\\abethr1\\XC128013._2.png</td>\n",
       "      <td>0</td>\n",
       "      <td>abethr1</td>\n",
       "      <td>XC128013.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data/train_img\\abethr1\\XC128013._3.png</td>\n",
       "      <td>0</td>\n",
       "      <td>abethr1</td>\n",
       "      <td>XC128013.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data/train_img\\abethr1\\XC128013._4.png</td>\n",
       "      <td>0</td>\n",
       "      <td>abethr1</td>\n",
       "      <td>XC128013.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               image_path  label label_name      group  fold   \n",
       "0  Data/train_img\\abethr1\\XC128013._0.png      0    abethr1  XC128013.   1.0  \\\n",
       "1  Data/train_img\\abethr1\\XC128013._1.png      0    abethr1  XC128013.   1.0   \n",
       "2  Data/train_img\\abethr1\\XC128013._2.png      0    abethr1  XC128013.   1.0   \n",
       "3  Data/train_img\\abethr1\\XC128013._3.png      0    abethr1  XC128013.   1.0   \n",
       "4  Data/train_img\\abethr1\\XC128013._4.png      0    abethr1  XC128013.   1.0   \n",
       "\n",
       "  2nd_label  \n",
       "0        []  \n",
       "1        []  \n",
       "2        []  \n",
       "3        []  \n",
       "4        []  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.read_csv('Data/train_2nd_label.csv')\n",
    "\n",
    "train_dataset= df[df['fold']!=CFG['fold']].reset_index(drop=True)\n",
    "train_dataset= pd.concat([train_dataset, ex_df],axis=0).reset_index(drop=True).fillna('[]')\n",
    "label= train_dataset['label'].unique().tolist()\n",
    "n= 500\n",
    "for i,g in enumerate(tqdm(label)):\n",
    "    sample_df= train_dataset[train_dataset['label']==g]\n",
    "    if len(sample_df)>=500: sample_df= sample_df.sample(n=n, replace=False, random_state=1).reset_index(drop=True)\n",
    "    elif len(sample_df)<50: sample_df= sample_df.sample(n=50, replace=True, random_state=1).reset_index(drop=True)\n",
    "    if i==0: new_df= sample_df\n",
    "    else: new_df= pd.concat([new_df, sample_df], axis=0).reset_index(drop=True)\n",
    "train_dataset= new_df\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "cls_weight= compute_class_weight(class_weight='balanced', classes=list(range(264)), y=train_dataset['label'].values)\n",
    "cls_weight= torch.tensor(cls_weight).cuda()\n",
    "\n",
    "valid_dataset= df[df['fold']==CFG['fold']].reset_index(drop=True)\n",
    "print(f'train dataset: {len(train_dataset)}')\n",
    "print(f'valid dataset: {len(valid_dataset)}')\n",
    "\n",
    "train_dataset= Customize_Dataset(train_dataset, get_train_transform(CFG['img_size']), mixup=CFG['mixup'])\n",
    "valid_dataset= Customize_Dataset(valid_dataset, get_test_transform(CFG['img_size']), mixup=False)\n",
    "\n",
    "train_loader= DataLoader(train_dataset, batch_size= CFG['batch_size'], shuffle=True, num_workers=0)\n",
    "valid_loader= DataLoader(valid_dataset, batch_size=32, shuffle=False, num_workers=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "32077713",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data= train_dataset[0]\n",
    "img= data['image']\n",
    "label= data['label']\n",
    "plt.imshow(img.permute(1,2,0).numpy())\n",
    "label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd8144c",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce46fc57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_model: pretrained/nfnet_l0.pth\n",
      "use bird pretrained\n",
      "\n",
      "ep: 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5029ecee26f7458c86949664b0d3d000",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/886 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23296\\2664467966.py:60: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'image': torch.tensor(img/255, dtype=torch.float32),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e089ea550ef47a1a8ebc0330b0c0b90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/819 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.38852408948614187\n",
      "mean_recall: 0.12453142134681713\n",
      "cmap: 0.3885111783305845\n",
      "train loss: 0.16207\n",
      "valid loss: 0.14529, valid_acc: 0.38851\n",
      "model save at score: 0.38851\n",
      "\n",
      "ep: 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecb481c2663446e39a26467624cf726e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/886 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23296\\2664467966.py:60: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'image': torch.tensor(img/255, dtype=torch.float32),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c2d058927a840ed83b4ecb32013ce00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/819 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.5592502099717492\n",
      "mean_recall: 0.22867048730164244\n",
      "cmap: 0.518290045300589\n",
      "train loss: 0.14589\n",
      "valid loss: 0.14306, valid_acc: 0.51829\n",
      "model save at score: 0.51829\n",
      "\n",
      "ep: 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daccef35bce34ee69c110ad9a8abc1c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/886 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23296\\2664467966.py:60: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'image': torch.tensor(img/255, dtype=torch.float32),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e37c30fad6949b28ae05f63c9337da0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/819 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.627281056730549\n",
      "mean_recall: 0.2991856885359952\n",
      "cmap: 0.609298725215347\n",
      "train loss: 0.14443\n",
      "valid loss: 0.14154, valid_acc: 0.6093\n",
      "model save at score: 0.6093\n",
      "\n",
      "ep: 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10774bbac57d4ecf8437baa83bae2959",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/886 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23296\\2664467966.py:60: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'image': torch.tensor(img/255, dtype=torch.float32),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1b47f3befb3452597076c071bc03985",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/819 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.666373978773765\n",
      "mean_recall: 0.36014297416554847\n",
      "cmap: 0.6630564361496777\n",
      "train loss: 0.14332\n",
      "valid loss: 0.14067, valid_acc: 0.66306\n",
      "model save at score: 0.66306\n",
      "\n",
      "ep: 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b8dbee3a9374371a5b52b7f6a6d6065",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/886 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23296\\2664467966.py:60: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'image': torch.tensor(img/255, dtype=torch.float32),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34f60c0974534e008b93ba401c2b2f04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/819 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.6961136138046881\n",
      "mean_recall: 0.40884979551559236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmap: 0.6948345906418776\n",
      "train loss: 0.14251\n",
      "valid loss: 0.14007, valid_acc: 0.69483\n",
      "model save at score: 0.69483\n",
      "\n",
      "ep: 6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "600312666f1145f2944dccb3845c0e1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/886 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23296\\2664467966.py:60: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'image': torch.tensor(img/255, dtype=torch.float32),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ea71017090e4983bbe31e2b67ad029f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/819 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7174162021837062\n",
      "mean_recall: 0.44397590207063004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmap: 0.7124490130728295\n",
      "train loss: 0.14185\n",
      "valid loss: 0.13977, valid_acc: 0.71245\n",
      "model save at score: 0.71245\n",
      "\n",
      "ep: 7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9190744651ad4ac3aa547ac23a92b74d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/886 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23296\\2664467966.py:60: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'image': torch.tensor(img/255, dtype=torch.float32),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "501f1e2b428941cebc6c63590ee99657",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/819 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7282583797816293\n",
      "mean_recall: 0.4632926714651898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmap: 0.7242083400838243\n",
      "train loss: 0.14132\n",
      "valid loss: 0.13939, valid_acc: 0.72421\n",
      "model save at score: 0.72421\n",
      "\n",
      "ep: 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05db2c8d3287436ca88a7101b4a92a88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/886 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23296\\2664467966.py:60: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'image': torch.tensor(img/255, dtype=torch.float32),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92e0c623a9ac4e25b57b84c515a8e1f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/819 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7384133771092617\n",
      "mean_recall: 0.48179926705233245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmap: 0.7357487918258522\n",
      "train loss: 0.14091\n",
      "valid loss: 0.13918, valid_acc: 0.73575\n",
      "model save at score: 0.73575\n",
      "\n",
      "ep: 9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa15d4144d9340febac7cafbb880f3cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/886 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23296\\2664467966.py:60: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'image': torch.tensor(img/255, dtype=torch.float32),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25526cf96ee44ce99d4bf1ef3f1cc61f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/819 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7463923035809727\n",
      "mean_recall: 0.49592340368163385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmap: 0.7437333033093807\n",
      "train loss: 0.14057\n",
      "valid loss: 0.13901, valid_acc: 0.74373\n",
      "model save at score: 0.74373\n",
      "\n",
      "ep: 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cea5905b6b154b75991c944bdece0884",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/886 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23296\\2664467966.py:60: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'image': torch.tensor(img/255, dtype=torch.float32),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e5b0f164f9841c7a864c7640f99f9a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/819 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.750782621974498\n",
      "mean_recall: 0.5116482802992808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmap: 0.7480222391040616\n",
      "train loss: 0.14028\n",
      "valid loss: 0.13891, valid_acc: 0.74802\n",
      "model save at score: 0.74802\n",
      "\n",
      "ep: 11\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c656a6190f54fe680de89a79454e319",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/886 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23296\\2664467966.py:60: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'image': torch.tensor(img/255, dtype=torch.float32),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66b607e3fca447e58369c6eb86a3ca2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/819 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7530350461937848\n",
      "mean_recall: 0.5216999357544921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmap: 0.7516153638878497\n",
      "train loss: 0.14001\n",
      "valid loss: 0.13883, valid_acc: 0.75162\n",
      "model save at score: 0.75162\n",
      "\n",
      "ep: 12\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccb43251fb5247469d773af7f52b4e78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/886 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23296\\2664467966.py:60: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'image': torch.tensor(img/255, dtype=torch.float32),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4e9257e942043de9b2d89d9c51cb30f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/819 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7545621134610979\n",
      "mean_recall: 0.5218016127630221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmap: 0.7558119831396451\n",
      "train loss: 0.1398\n",
      "valid loss: 0.1388, valid_acc: 0.75581\n",
      "model save at score: 0.75581\n",
      "\n",
      "ep: 13\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dc7e48399e94370b9de8dc92d3d71f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/886 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23296\\2664467966.py:60: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'image': torch.tensor(img/255, dtype=torch.float32),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f320af95fd0344689f072a51bfc41b41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/819 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.758341604947698\n",
      "mean_recall: 0.5435329619370621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmap: 0.7583304286037832\n",
      "train loss: 0.13959\n",
      "valid loss: 0.13874, valid_acc: 0.75833\n",
      "model save at score: 0.75833\n",
      "\n",
      "ep: 14\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03e11b76169b406691a648249c725b86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/886 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23296\\2664467966.py:60: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'image': torch.tensor(img/255, dtype=torch.float32),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7753c6a4f8754ed99b157b8373235419",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/819 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7573108345422616\n",
      "mean_recall: 0.5386247476368623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmap: 0.7593173825326343\n",
      "train loss: 0.1394\n",
      "valid loss: 0.13873, valid_acc: 0.75932\n",
      "model save at score: 0.75932\n",
      "\n",
      "ep: 15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bb6ebcfcecc42d098a32fa75dc03781",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/886 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23296\\2664467966.py:60: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'image': torch.tensor(img/255, dtype=torch.float32),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e48558294d934c18a475491023b74edf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/819 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7621592731159808\n",
      "mean_recall: 0.5522131597232511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmap: 0.7609988280779488\n",
      "train loss: 0.13929\n",
      "valid loss: 0.13866, valid_acc: 0.761\n",
      "model save at score: 0.761\n",
      "\n",
      "ep: 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3e8718d15d84423944942e04628b37b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/886 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23296\\2664467966.py:60: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'image': torch.tensor(img/255, dtype=torch.float32),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02e100127ad943e495a0984087ffcc05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/819 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7612430327555929\n",
      "mean_recall: 0.5541382834127221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmap: 0.7616832910444963\n",
      "train loss: 0.13914\n",
      "valid loss: 0.13863, valid_acc: 0.76168\n",
      "model save at score: 0.76168\n",
      "\n",
      "ep: 17\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe5186a5f417448e9774bd80b38634a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/886 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23296\\2664467966.py:60: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'image': torch.tensor(img/255, dtype=torch.float32),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "784df0cb5e46450cbb937b995de42eb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/819 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.762770100022906\n",
      "mean_recall: 0.5514113534787323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmap: 0.763613609421449\n",
      "train loss: 0.13904\n",
      "valid loss: 0.13858, valid_acc: 0.76361\n",
      "model save at score: 0.76361\n",
      "\n",
      "ep: 18\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4a58843ebcb41d09d5fa8d96a128e2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/886 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23296\\2664467966.py:60: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'image': torch.tensor(img/255, dtype=torch.float32),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cd4c6dbe2ae4a97bc222430a3c0d662",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/819 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.761892036344201\n",
      "mean_recall: 0.5518895645922052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmap: 0.7616188462132154\n",
      "train loss: 0.13893\n",
      "valid loss: 0.1386, valid_acc: 0.76162\n",
      "\n",
      "ep: 19\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a82c4a553032499b8fda74b56336d766",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/886 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23296\\2664467966.py:60: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'image': torch.tensor(img/255, dtype=torch.float32),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f36104852632442dac43cdfcecd255e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/819 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7607085592120333\n",
      "mean_recall: 0.5486639669426459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmap: 0.7626421604192477\n",
      "train loss: 0.13883\n",
      "valid loss: 0.13863, valid_acc: 0.76264\n",
      "\n",
      "ep: 20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ba17c205ff942febefad6d8fc938cf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/886 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23296\\2664467966.py:60: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'image': torch.tensor(img/255, dtype=torch.float32),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6669cb06bf4e4a9ea40ed96bde8f8d26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/819 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7633809269298313\n",
      "mean_recall: 0.559770486158627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmap: 0.7642163373556449\n",
      "train loss: 0.13876\n",
      "valid loss: 0.13855, valid_acc: 0.76422\n",
      "model save at score: 0.76422\n",
      "\n",
      "ep: 21\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "629bbabb6c5945909bad71cc3753ebdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/886 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23296\\2664467966.py:60: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'image': torch.tensor(img/255, dtype=torch.float32),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4efffe83fe514df391edaf0f8484277e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/819 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7589524318546232\n",
      "mean_recall: 0.551639602062529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmap: 0.7606736173686836\n",
      "train loss: 0.13867\n",
      "valid loss: 0.13864, valid_acc: 0.76067\n",
      "\n",
      "ep: 22\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2542936bdfa45418ea405366667fdb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/886 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23296\\2664467966.py:60: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'image': torch.tensor(img/255, dtype=torch.float32),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47a0b44f6c9140f3872eedc56bb746e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/819 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7588760784912575\n",
      "mean_recall: 0.564431642750634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmap: 0.7635704226160063\n",
      "train loss: 0.1386\n",
      "valid loss: 0.13861, valid_acc: 0.76357\n",
      "\n",
      "ep: 23\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52f51a3b9671460d825549f2f7c35b6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/886 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23296\\2664467966.py:60: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'image': torch.tensor(img/255, dtype=torch.float32),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c70095c23d14a31a125e81cd5c1e520",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/819 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7590287852179889\n",
      "mean_recall: 0.5583556343758252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmap: 0.7602781534619696\n",
      "train loss: 0.13854\n",
      "valid loss: 0.13866, valid_acc: 0.76028\n",
      "\n",
      "ep: 24\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38604d7d28c1449eaea3b3a09a7e50ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/886 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23296\\2664467966.py:60: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'image': torch.tensor(img/255, dtype=torch.float32),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc25ed8f914549f6a9d1523b121a2708",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/819 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7612048560739101\n",
      "mean_recall: 0.5575850017612668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmap: 0.7600687949738856\n",
      "train loss: 0.13849\n",
      "valid loss: 0.13859, valid_acc: 0.76007\n",
      "\n",
      "ep: 25\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7a213ccc6224c59bc8d5240cd4c63af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/886 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23296\\2664467966.py:60: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'image': torch.tensor(img/255, dtype=torch.float32),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5726fbc9bae4d5a896c9ad9722b2e9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/819 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7659769412842635\n",
      "mean_recall: 0.5695494465726684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmap: 0.7637176609493188\n",
      "train loss: 0.13841\n",
      "valid loss: 0.13853, valid_acc: 0.76372\n",
      "\n",
      "ep: 26\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc0ba965e09d4c60a8d83dccffafc05e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/886 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23296\\2664467966.py:60: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'image': torch.tensor(img/255, dtype=torch.float32),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08b250f336fb45f19b936a9683e7a5e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/819 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7672749484614797\n",
      "mean_recall: 0.5615466818897484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmap: 0.7657076548585048\n",
      "train loss: 0.13838\n",
      "valid loss: 0.13851, valid_acc: 0.76571\n",
      "model save at score: 0.76571\n",
      "\n",
      "ep: 27\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1adcf3b8eeb24f788622962f9ac91270",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/886 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23296\\2664467966.py:60: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'image': torch.tensor(img/255, dtype=torch.float32),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "926cca5858744bb494962b1336a2f973",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/819 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.764106283881805\n",
      "mean_recall: 0.5582566579492476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmap: 0.76179554106113\n",
      "train loss: 0.13833\n",
      "valid loss: 0.13856, valid_acc: 0.7618\n",
      "\n",
      "ep: 28\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5f390b310b04f4ebc695ae381d34208",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/886 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23296\\2664467966.py:60: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'image': torch.tensor(img/255, dtype=torch.float32),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f90ca0fbf65945aaae75df8966caa909",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/819 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7636099870199282\n",
      "mean_recall: 0.5665726832642128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmap: 0.7606723155063024\n",
      "train loss: 0.13828\n",
      "valid loss: 0.13855, valid_acc: 0.76067\n",
      "\n",
      "ep: 29\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e438598a793492f919d79c888f030b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/886 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23296\\2664467966.py:60: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'image': torch.tensor(img/255, dtype=torch.float32),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "896bee8010874666b2dfaee132ccf253",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/819 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7540658165992212\n",
      "mean_recall: 0.5720027850040091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmap: 0.7574094813638019\n",
      "train loss: 0.13826\n",
      "valid loss: 0.13868, valid_acc: 0.75741\n",
      "\n",
      "ep: 30\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a95053051c6e4c10bbb8bfa6dfddcc3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/886 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23296\\2664467966.py:60: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'image': torch.tensor(img/255, dtype=torch.float32),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7d5c63cd707445186e5ce006ea9ff38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/819 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7640299305184394\n",
      "mean_recall: 0.5675664987296634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmap: 0.7613228938393841\n",
      "train loss: 0.13822\n",
      "valid loss: 0.13859, valid_acc: 0.76132\n",
      "\n",
      "ep: 31\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cec7c0cca5044b26a25f5095df87238d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/886 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23296\\2664467966.py:60: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'image': torch.tensor(img/255, dtype=torch.float32),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba0794f736cc432b8b81f6d894ed32ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/819 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7631518668397342\n",
      "mean_recall: 0.5665872227058686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmap: 0.7618861431762668\n",
      "train loss: 0.13817\n",
      "valid loss: 0.1386, valid_acc: 0.76189\n",
      "\n",
      "ep: 32\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dedc7f5148464788bcb3dd4314f4f65b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/886 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23296\\2664467966.py:60: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'image': torch.tensor(img/255, dtype=torch.float32),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9cc89403c3b45f89327f57a5b388d8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/819 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7634572802931969\n",
      "mean_recall: 0.5725486916857692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmap: 0.7604400052196422\n",
      "train loss: 0.13814\n",
      "valid loss: 0.13854, valid_acc: 0.76044\n",
      "\n",
      "ep: 33\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08dc8208393649818fd92ee261529d4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/886 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23296\\2664467966.py:60: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'image': torch.tensor(img/255, dtype=torch.float32),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa6549ad5305495fbce9c11254af085b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/819 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7676948919599909\n",
      "mean_recall: 0.5721642830476232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmap: 0.7618570004247437\n",
      "train loss: 0.13811\n",
      "valid loss: 0.13851, valid_acc: 0.76186\n",
      "\n",
      "ep: 34\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "352d2488c09645d68c8c3434b5b197d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/886 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23296\\2664467966.py:60: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'image': torch.tensor(img/255, dtype=torch.float32),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b9e7514f8ba4d9188b22ec865ede3e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/819 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7648316408337787\n",
      "mean_recall: 0.5666502665057197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmap: 0.7587068356695214\n",
      "train loss: 0.13805\n",
      "valid loss: 0.13856, valid_acc: 0.75871\n",
      "\n",
      "ep: 35\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ab0bb264308451c894050bbf2ca7175",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/886 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23296\\2664467966.py:60: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'image': torch.tensor(img/255, dtype=torch.float32),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf805a72b47a48319bb3c3f2e30f1e3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/819 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7661678246926777\n",
      "mean_recall: 0.5615196890134375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmap: 0.7574548772634913\n",
      "train loss: 0.13806\n",
      "valid loss: 0.13858, valid_acc: 0.75745\n",
      "\n",
      "ep: 36\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ca2b81cc3e24a6288365ffce76c124e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/886 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23296\\2664467966.py:60: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'image': torch.tensor(img/255, dtype=torch.float32),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "405283e6d3a54a939c3911b63fc5f62e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/819 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7647171107887303\n",
      "mean_recall: 0.5670704628358445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmap: 0.7578090096973639\n",
      "train loss: 0.13806\n",
      "valid loss: 0.13859, valid_acc: 0.75781\n",
      "\n",
      "ep: 37\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09e74844170b4c21a9d9d560e17cf847",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/886 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23296\\2664467966.py:60: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'image': torch.tensor(img/255, dtype=torch.float32),\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_23296\\1104306403.py\u001b[0m in \u001b[0;36m<cell line: 24>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'\\nep: {ep}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m     \u001b[0mtrain_loss\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m     \u001b[0mvalid_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_acc\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mvalid_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'train loss: {round(train_loss, 5)}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_23296\\4254015569.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[1;34m(dataloader, model, criterion, optimizer)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mep_loss\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mimgs\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'image'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cuda'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\kaggle_smbcd\\lib\\site-packages\\tqdm\\notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    257\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m             \u001b[0mit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 259\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    260\u001b[0m                 \u001b[1;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\kaggle_smbcd\\lib\\site-packages\\tqdm\\std.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1194\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1195\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1196\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1197\u001b[0m                 \u001b[1;31m# Update and possibly print the progressbar.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\kaggle_smbcd\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    632\u001b[0m                 \u001b[1;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    633\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 634\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    635\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    636\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\kaggle_smbcd\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    676\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    677\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\kaggle_smbcd\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\kaggle_smbcd\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_23296\\2664467966.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m             \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"image\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m         return {\n",
      "\u001b[1;32m~\\anaconda3\\envs\\kaggle_smbcd\\lib\\site-packages\\albumentations\\core\\composition.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, force_apply, *args, **data)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 205\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mcheck_each_transform\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\kaggle_smbcd\\lib\\site-packages\\albumentations\\core\\transforms_interface.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, force_apply, *args, **kwargs)\u001b[0m\n\u001b[0;32m    107\u001b[0m                 )\n\u001b[0;32m    108\u001b[0m                 \u001b[0mtargets_as_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtargets_as_params\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 109\u001b[1;33m                 \u001b[0mparams_dependent_on_targets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_params_dependent_on_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtargets_as_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    110\u001b[0m                 \u001b[0mparams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams_dependent_on_targets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeterministic\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\kaggle_smbcd\\lib\\site-packages\\albumentations\\augmentations\\transforms.py\u001b[0m in \u001b[0;36mget_params_dependent_on_targets\u001b[1;34m(self, params)\u001b[0m\n\u001b[0;32m   1230\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1231\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mper_channel\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1232\u001b[1;33m             \u001b[0mgauss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1233\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1234\u001b[0m             \u001b[0mgauss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\kaggle_smbcd\\lib\\site-packages\\albumentations\\random_utils.py\u001b[0m in \u001b[0;36mnormal\u001b[1;34m(loc, scale, size, random_state)\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_random_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## create model\n",
    "if CFG['load_model']:\n",
    "    print(f\"load_model: {CFG['load_model']}\")\n",
    "    model= torch.load(CFG['load_model'], map_location= 'cuda')\n",
    "else:\n",
    "    model= Customize_Model(CFG['model_name'], CFG['num_classes'])\n",
    "    \n",
    "if CFG['gradient_checkpoint']: \n",
    "    print('use gradient checkpoint')\n",
    "    model.model.set_grad_checkpointing(enable=True)\n",
    "    \n",
    "if 'pretrained' in str(CFG['load_model']): \n",
    "    print('use bird pretrained')\n",
    "#     model.model.classifier= nn.Linear(in_features=1280, out_features=264, bias=True)\n",
    "    model.model.head.fc= nn.Linear(in_features=2304, out_features=264, bias=True)\n",
    "model.to('cuda')\n",
    "    \n",
    "## hyperparameter\n",
    "criterion= Customize_loss()\n",
    "optimizer= optim.AdamW(model.parameters(), lr= CFG['lr'], weight_decay= CFG['weight_decay'])\n",
    "\n",
    "## start training\n",
    "best_score= 0\n",
    "for ep in range(1, CFG['epoch']+1):\n",
    "    print(f'\\nep: {ep}')\n",
    "    \n",
    "    train_loss= train_epoch(train_loader, model, criterion, optimizer)\n",
    "    valid_loss, valid_acc= valid_epoch(valid_loader, model, criterion)\n",
    "    print(f'train loss: {round(train_loss, 5)}')\n",
    "    print(f'valid loss: {round(valid_loss, 5)}, valid_acc: {round(valid_acc, 5)}')\n",
    "    \n",
    "    if valid_acc >= best_score:\n",
    "        best_score= valid_acc\n",
    "        torch.save(model, f\"{CFG['save_model']}/cv{CFG['fold']}_best.pth\")\n",
    "        print(f'model save at score: {round(best_score, 5)}')\n",
    "        \n",
    "    ## save model every epoch\n",
    "    torch.save(model, f\"{CFG['save_model']}/cv{CFG['fold']}_ep{ep}.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
