{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d34221",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from toolbox.audio2img import audio_to_img\n",
    "\n",
    "path= 'Data/test/soundscape_29201.ogg'\n",
    "img= audio_to_img(path,\n",
    "                  period= 5,\n",
    "                  sr= 32000,\n",
    "                  n_mels= 128,\n",
    "                  fmin = 20,\n",
    "                  fmax = 16000)\n",
    "img.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60906c33",
   "metadata": {},
   "source": [
    "# make audio image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d7abfa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "import numpy as np\n",
    "from toolbox.audio2img import audio_to_img\n",
    "import soundfile as sf\n",
    "import librosa\n",
    "\n",
    "c= 0\n",
    "paths= glob.glob('Data/train_origin/**/*ogg', recursive=True)\n",
    "for path in tqdm(paths):\n",
    "    name= path.split('\\\\')[-1].replace('ogg', '')\n",
    "    \n",
    "    new_path= path.replace('train_origin', 'train_img_256')\n",
    "    new_path= new_path.split('\\\\')[:-1]\n",
    "    new_path= '/'.join(new_path)\n",
    "    os.makedirs(new_path, exist_ok=True)\n",
    "    \n",
    "    imgs= audio_to_img(path,\n",
    "                      period= 5,\n",
    "                      sr= 32000,\n",
    "                      n_mels= 256,\n",
    "                      n_fft= 2048,\n",
    "                      hop_length= 512,\n",
    "                      fmin = 16,\n",
    "                      fmax = 16386)\n",
    "\n",
    "    if len(imgs)!=1: imgs= imgs[:-1]\n",
    "    for i in range(len(imgs)):\n",
    "        img= imgs[i]\n",
    "        im= Image.fromarray(img.astype(np.uint8))\n",
    "        im.save(f'{new_path}/{name}_{c}.png')\n",
    "        c+= 1\n",
    "        \n",
    "#     sr= 32000\n",
    "#     period= 5\n",
    "#     data, sr = librosa.load(path, sr= sr)\n",
    "#     max_sec= int( len(data)//sr )+1\n",
    "#     datas = [ data[i * sr: (i+period) * sr] for i in range(0, max_sec, period) ]\n",
    "#     if len(datas[-1])<sr*period: datas[-1]= list(datas[-1]) + [0]*( sr*period-len(datas[-1]) )\n",
    "    \n",
    "#     for i in range(len(datas)):\n",
    "#         data= datas[i]\n",
    "#         sf.write(f'{new_path}/{name}_{c}.ogg', data, sr, format='ogg', subtype='vorbis')\n",
    "#         c+= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3caf95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from io import StringIO\n",
    "from csv import writer \n",
    "\n",
    "paths= glob.glob('Data/train_img_ex1/**/*png', recursive=True)\n",
    "label_name= os.listdir('Data/train_img_ex1')\n",
    "\n",
    "df = StringIO()\n",
    "csv_writer = writer(df)\n",
    "csv_writer.writerow(['image_path', 'label', 'label_name', 'group'])\n",
    "\n",
    "for i, path in enumerate(tqdm(paths)):\n",
    "    group= path.split('\\\\')[-1].split('_')[0]\n",
    "    label= path.split('\\\\')[-2]\n",
    "    label_num= label_name.index(label)\n",
    "    csv_writer.writerow([path, label_num, label, group])\n",
    "    \n",
    "df.seek(0)\n",
    "df= pd.read_csv(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3ce399",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold,StratifiedKFold, GroupKFold\n",
    "\n",
    "group_id= df['group']\n",
    "kf = GroupKFold(n_splits=5)\n",
    "for i, (train_index, test_index) in enumerate(kf.split(group_id, group_id, group_id)):\n",
    "    for indx in tqdm(test_index):\n",
    "        df.loc[indx, 'fold']= i\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2ef9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "label= df['label'].unique().tolist()\n",
    "for l in tqdm(label):\n",
    "    temp_df= df[df['label']==l]\n",
    "    group= temp_df['group'].unique().tolist()\n",
    "    if len(group)<5:\n",
    "        df.loc[ df['label']==l, 'fold' ]= -1\n",
    "df"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a4c85cf2",
   "metadata": {},
   "source": [
    "df.to_csv('Data/train_ex1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcffbca3",
   "metadata": {},
   "source": [
    "# Model Soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9645948e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successful\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Customize_Model(nn.Module):\n",
    "    def __init__(self, model_name, cls):\n",
    "        super().__init__()\n",
    "    def forward(self, image):\n",
    "        x = self.model(image)\n",
    "        return x\n",
    "    \n",
    "def get_soup(state_dicts, alphal):\n",
    "    sd = {k : state_dicts[0][k].clone() * alphal[0] for k in state_dicts[0].keys()}\n",
    "    for i in range(1, len(state_dicts)):\n",
    "        for k in state_dicts[i].keys():\n",
    "            sd[k] = sd[k] + state_dicts[i][k].clone() * alphal[i]\n",
    "    return sd\n",
    "\n",
    "    \n",
    "model_path=[\n",
    "    'test_model/effb0_imgsz128_PL1/model_soup.pth',\n",
    "    'test_model/effb0_imgsz128_PL2/model_soup.pth',\n",
    "#     'test_model/convnextv2_tiny_imgsz128_PL3/cv2_best.pth',\n",
    "#     'test_model/convnextv2_tiny_imgsz128_PL3/cv3_best.pth',\n",
    "#     'test_model/convnextv2_tiny_imgsz128_PL3/cv4_best.pth',\n",
    "]\n",
    "model_weights= [torch.load(path).state_dict() for path in model_path]\n",
    "# alphal= [1/len(model_path)]*len(model_path)\n",
    "alphal= [0.25, 0.75]\n",
    "\n",
    "soup= get_soup(model_weights, alphal)\n",
    "model_soup= torch.load(model_path[0])\n",
    "model_soup.load_state_dict(soup)\n",
    "torch.save(model_soup, 'test_model/model_soup.pth')\n",
    "print('successful')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a5d87f",
   "metadata": {},
   "source": [
    "# PTH2Torchscript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21e2f71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Customize_Model(nn.Module):\n",
    "    def __init__(self, model_name, cls):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, image):\n",
    "        x = self.model(image)\n",
    "        return x\n",
    "\n",
    "# path= 'train_model/cv0_best.pth'\n",
    "path= 'test_model/model_soup.pth'\n",
    "# path= 'test_model/effb0_imgsz192_PL3/cv4_best.pth'\n",
    "\n",
    "example = torch.rand(1, 3, 128, 313)\n",
    "# example = torch.rand(1, 3, 192, 470)\n",
    "\n",
    "model= torch.load(path).cpu().eval()\n",
    "traced_script_module = torch.jit.trace(model, example)\n",
    "traced_script_module.save(path.replace('pth', 'ts'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
