{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ab1420b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import cv2\n",
    "import time\n",
    "import random\n",
    "\n",
    "# For data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Pytorch Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda import amp\n",
    "from pytorch_toolbelt import losses as L\n",
    "\n",
    "# Utils\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# For Image Models\n",
    "import timm\n",
    "\n",
    "# Albumentations for augmentations\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "## using gpu:1\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "def seed_everything(seed=123):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "seed_everything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85ceec4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Customize_Model(nn.Module):\n",
    "    def __init__(self, model_name, cls):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(model_name, \n",
    "                                       pretrained=True, \n",
    "                                       num_classes=cls, \n",
    "                                       drop_rate= CFG['drop_out'], \n",
    "                                       drop_path_rate= CFG['drop_path'])\n",
    "        \n",
    "    def forward(self, image):\n",
    "        x = self.model(image)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8881b53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_transform(img_size):\n",
    "    return A.Compose([\n",
    "        A.SmallestMaxSize(max_size=img_size, interpolation=3, p=1),\n",
    "#         A.Resize(img_size, img_size),\n",
    "        \n",
    "        A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),\n",
    "#         A.HorizontalFlip(p=0.5),\n",
    "#         A.VerticalFlip(p=0.5),\n",
    "#         A.Blur(blur_limit= 3, p=0.3), \n",
    "        A.GaussNoise(p=0.3),\n",
    "        A.OneOf([\n",
    "                A.Cutout(max_h_size=10, max_w_size=16),\n",
    "                A.CoarseDropout(max_holes=4),\n",
    "            ], p=0.5),\n",
    "        A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit= 0,\n",
    "                                        interpolation=cv2.INTER_LINEAR, border_mode=0, p=0.7),\n",
    "        ToTensorV2(p=1.0),\n",
    "    ])\n",
    "\n",
    "\n",
    "def get_test_transform(img_size):\n",
    "    return A.Compose([\n",
    "        A.SmallestMaxSize(max_size=img_size, interpolation=3, p=1),\n",
    "#         A.Resize(img_size, img_size),\n",
    "        ToTensorV2(p=1.0),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a153977",
   "metadata": {},
   "outputs": [],
   "source": [
    "from toolbox.audio_aug import *\n",
    "\n",
    "class Customize_Dataset(Dataset):\n",
    "    def __init__(self, df, transforms=None, mixup=0):\n",
    "        self.df = df\n",
    "        self.transforms = transforms\n",
    "        self.mixup= mixup\n",
    "        \n",
    "    def mixup_aug(self, img_1, mask_1, \n",
    "                        img_2, mask_2):\n",
    "        \"\"\"\n",
    "        img: numpy array of shape (height, width,channel)\n",
    "        mask: numpy array of shape (height, width,channel)\n",
    "        \"\"\"\n",
    "        ## mixup\n",
    "        weight= np.random.beta(a=0.5, b=0.5)\n",
    "        img= img_1*weight + img_2*(1-weight)\n",
    "        mask= mask_1*weight + mask_2*(1-weight)\n",
    "        return img.astype(np.uint8), mask\n",
    "    \n",
    "    def read_data(self, data):\n",
    "        img = cv2.imread(data['image_path'])\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        label= [0]*CFG['num_classes']\n",
    "        cls = data['label']\n",
    "        \n",
    "        ## make soft_label\n",
    "        sec_indx= eval(data['2nd_label'])\n",
    "        if len(sec_indx)!=0:\n",
    "            sec_label= (1-CFG['soft_target']) / len(sec_indx)\n",
    "            for indx in sec_indx: label[indx]= sec_label\n",
    "            label[cls]= CFG['soft_target']\n",
    "        else:\n",
    "            label[cls]= 1\n",
    "        label= np.array(label)\n",
    "        \n",
    "        return img, label\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        data = self.df.loc[index]\n",
    "        img, label= self.read_data(data)\n",
    "        \n",
    "        # use mixup\n",
    "        if self.mixup and np.random.rand() >= (1-self.mixup):\n",
    "            img_1= img\n",
    "            label_1= np.array(label)\n",
    "            while True:\n",
    "                indx= np.random.randint(len(self.df))\n",
    "                data= self.df.loc[indx]\n",
    "                img_2, label_2= self.read_data(data)\n",
    "                if label_1.argmax(0)!=label_2.argmax(0): break\n",
    "            img, label= self.mixup_aug(img_1, label_1, \n",
    "                                       img_2, label_2)\n",
    "        \n",
    "        if self.transforms:\n",
    "            img = self.transforms(image=img)[\"image\"]\n",
    "            \n",
    "        return {\n",
    "            'image': torch.tensor(img/255, dtype=torch.float32),\n",
    "            'label': torch.tensor(label, dtype=torch.float32),\n",
    "        }\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25e62a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Customize_loss(nn.Module):\n",
    "    def  __init__(self):\n",
    "        super().__init__()\n",
    "        self.CrossEntropy= nn.CrossEntropyLoss(weight= None, label_smoothing=0.25)\n",
    "        self.FocalCosineLoss= L.FocalCosineLoss()\n",
    "        self.soft_ce= L.SoftCrossEntropyLoss(smooth_factor=0.25)\n",
    "        self.bi_temp= L.BiTemperedLogisticLoss(t1=0.8, t2=1.2)\n",
    "        self.soft_bce= L.SoftBCEWithLogitsLoss(smooth_factor= 0.01)\n",
    "    \n",
    "    def forward(self, y_pred, y_true):\n",
    "        loss= self.CrossEntropy(y_pred, y_true)#+self.soft_bce(y_pred, y_true)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8f51ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(dataloader, model, criterion, optimizer):\n",
    "    scaler= amp.GradScaler()\n",
    "    model.train()\n",
    "\n",
    "    ep_loss= []\n",
    "    for i, data in enumerate(tqdm(dataloader)):\n",
    "\n",
    "        imgs= data['image'].to('cuda')\n",
    "        labels= data['label'].to('cuda')\n",
    "        \n",
    "        with amp.autocast():\n",
    "            preds= model(imgs)\n",
    "            loss= criterion(preds, labels)\n",
    "            ep_loss.append(loss.item())\n",
    "            loss/= CFG['gradient_accumulation']\n",
    "            scaler.scale(loss).backward()\n",
    "            \n",
    "            if (i+1) % CFG['gradient_accumulation']== 0:\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "    return np.mean(ep_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4efbece7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from metrics import *\n",
    "\n",
    "def valid_epoch(dataloader, model, criterion):\n",
    "    model.eval()\n",
    "    \n",
    "    ep_loss= []\n",
    "    all_pred= []\n",
    "    all_label= []\n",
    "    for i, data in enumerate(tqdm(dataloader)):\n",
    "\n",
    "        imgs= data['image'].to('cuda')\n",
    "        labels= data['label'].to('cuda')\n",
    "        all_label.extend(labels.cpu().numpy())\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            preds= model(imgs)\n",
    "            loss= criterion(preds, labels)\n",
    "            ep_loss.append(loss.item())\n",
    "        all_pred.extend(preds.cpu().softmax(dim=-1).numpy())\n",
    "        \n",
    "    \n",
    "    ## caculate metrics\n",
    "    all_label= np.array(all_label).argmax(1)\n",
    "    all_pred= np.array(all_pred)\n",
    "    \n",
    "    acc= Accuracy(all_pred, all_label)\n",
    "    print(f'accuracy: {acc}')\n",
    "    recall= Mean_Recall(all_pred, all_label)\n",
    "    print(f'mean_recall: {recall}')\n",
    "    \n",
    "    cmap= padded_cmap(all_pred, all_label)\n",
    "    print(f'cmap: {cmap}')\n",
    "    \n",
    "    score= cmap\n",
    "    return np.mean(ep_loss), score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1bde5f",
   "metadata": {},
   "source": [
    "# CFG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e809850e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adv_inception_v3',\n",
       " 'bat_resnext26ts.ch_in1k',\n",
       " 'beit_base_patch16_224.in22k_ft_in22k',\n",
       " 'beit_base_patch16_224.in22k_ft_in22k_in1k',\n",
       " 'beit_base_patch16_384.in22k_ft_in22k_in1k',\n",
       " 'beit_large_patch16_224.in22k_ft_in22k',\n",
       " 'beit_large_patch16_224.in22k_ft_in22k_in1k',\n",
       " 'beit_large_patch16_384.in22k_ft_in22k_in1k',\n",
       " 'beit_large_patch16_512.in22k_ft_in22k_in1k',\n",
       " 'beitv2_base_patch16_224.in1k_ft_in22k',\n",
       " 'beitv2_base_patch16_224.in1k_ft_in22k_in1k',\n",
       " 'beitv2_large_patch16_224.in1k_ft_in22k',\n",
       " 'beitv2_large_patch16_224.in1k_ft_in22k_in1k',\n",
       " 'botnet26t_256',\n",
       " 'cait_m36_384',\n",
       " 'cait_m48_448',\n",
       " 'cait_s24_224',\n",
       " 'cait_s24_384',\n",
       " 'cait_s36_384',\n",
       " 'cait_xs24_384',\n",
       " 'cait_xxs24_224',\n",
       " 'cait_xxs24_384',\n",
       " 'cait_xxs36_224',\n",
       " 'cait_xxs36_384',\n",
       " 'coat_lite_mini',\n",
       " 'coat_lite_small',\n",
       " 'coat_lite_tiny',\n",
       " 'coat_mini',\n",
       " 'coat_tiny',\n",
       " 'coatnet_0_rw_224.sw_in1k',\n",
       " 'coatnet_1_rw_224.sw_in1k',\n",
       " 'coatnet_2_rw_224.sw_in12k',\n",
       " 'coatnet_2_rw_224.sw_in12k_ft_in1k',\n",
       " 'coatnet_3_rw_224.sw_in12k',\n",
       " 'coatnet_bn_0_rw_224.sw_in1k',\n",
       " 'coatnet_nano_rw_224.sw_in1k',\n",
       " 'coatnet_rmlp_1_rw2_224.sw_in12k',\n",
       " 'coatnet_rmlp_1_rw2_224.sw_in12k_ft_in1k',\n",
       " 'coatnet_rmlp_1_rw_224.sw_in1k',\n",
       " 'coatnet_rmlp_2_rw_224.sw_in1k',\n",
       " 'coatnet_rmlp_2_rw_224.sw_in12k',\n",
       " 'coatnet_rmlp_2_rw_224.sw_in12k_ft_in1k',\n",
       " 'coatnet_rmlp_2_rw_384.sw_in12k_ft_in1k',\n",
       " 'coatnet_rmlp_nano_rw_224.sw_in1k',\n",
       " 'coatnext_nano_rw_224.sw_in1k',\n",
       " 'convit_base',\n",
       " 'convit_small',\n",
       " 'convit_tiny',\n",
       " 'convmixer_768_32',\n",
       " 'convmixer_1024_20_ks9_p14',\n",
       " 'convmixer_1536_20',\n",
       " 'convnext_atto.d2_in1k',\n",
       " 'convnext_atto_ols.a2_in1k',\n",
       " 'convnext_base.clip_laion2b',\n",
       " 'convnext_base.clip_laion2b_augreg',\n",
       " 'convnext_base.clip_laion2b_augreg_ft_in1k',\n",
       " 'convnext_base.clip_laiona',\n",
       " 'convnext_base.clip_laiona_320',\n",
       " 'convnext_base.clip_laiona_augreg_320',\n",
       " 'convnext_base.clip_laiona_augreg_ft_in1k_384',\n",
       " 'convnext_base.fb_in1k',\n",
       " 'convnext_base.fb_in22k',\n",
       " 'convnext_base.fb_in22k_ft_in1k',\n",
       " 'convnext_base.fb_in22k_ft_in1k_384',\n",
       " 'convnext_femto.d1_in1k',\n",
       " 'convnext_femto_ols.d1_in1k',\n",
       " 'convnext_large.fb_in1k',\n",
       " 'convnext_large.fb_in22k',\n",
       " 'convnext_large.fb_in22k_ft_in1k',\n",
       " 'convnext_large.fb_in22k_ft_in1k_384',\n",
       " 'convnext_large_mlp.clip_laion2b_augreg',\n",
       " 'convnext_large_mlp.clip_laion2b_augreg_ft_in1k',\n",
       " 'convnext_large_mlp.clip_laion2b_augreg_ft_in1k_384',\n",
       " 'convnext_large_mlp.clip_laion2b_ft_320',\n",
       " 'convnext_large_mlp.clip_laion2b_ft_soup_320',\n",
       " 'convnext_nano.d1h_in1k',\n",
       " 'convnext_nano.in12k',\n",
       " 'convnext_nano.in12k_ft_in1k',\n",
       " 'convnext_nano_ols.d1h_in1k',\n",
       " 'convnext_pico.d1_in1k',\n",
       " 'convnext_pico_ols.d1_in1k',\n",
       " 'convnext_small.fb_in1k',\n",
       " 'convnext_small.fb_in22k',\n",
       " 'convnext_small.fb_in22k_ft_in1k',\n",
       " 'convnext_small.fb_in22k_ft_in1k_384',\n",
       " 'convnext_small.in12k',\n",
       " 'convnext_small.in12k_ft_in1k',\n",
       " 'convnext_small.in12k_ft_in1k_384',\n",
       " 'convnext_tiny.fb_in1k',\n",
       " 'convnext_tiny.fb_in22k',\n",
       " 'convnext_tiny.fb_in22k_ft_in1k',\n",
       " 'convnext_tiny.fb_in22k_ft_in1k_384',\n",
       " 'convnext_tiny.in12k',\n",
       " 'convnext_tiny.in12k_ft_in1k',\n",
       " 'convnext_tiny.in12k_ft_in1k_384',\n",
       " 'convnext_tiny_hnf.a2h_in1k',\n",
       " 'convnext_xlarge.fb_in22k',\n",
       " 'convnext_xlarge.fb_in22k_ft_in1k',\n",
       " 'convnext_xlarge.fb_in22k_ft_in1k_384',\n",
       " 'convnext_xxlarge.clip_laion2b_rewind',\n",
       " 'convnext_xxlarge.clip_laion2b_soup',\n",
       " 'convnextv2_atto.fcmae',\n",
       " 'convnextv2_atto.fcmae_ft_in1k',\n",
       " 'convnextv2_base.fcmae',\n",
       " 'convnextv2_base.fcmae_ft_in1k',\n",
       " 'convnextv2_base.fcmae_ft_in22k_in1k',\n",
       " 'convnextv2_base.fcmae_ft_in22k_in1k_384',\n",
       " 'convnextv2_femto.fcmae',\n",
       " 'convnextv2_femto.fcmae_ft_in1k',\n",
       " 'convnextv2_huge.fcmae',\n",
       " 'convnextv2_huge.fcmae_ft_in1k',\n",
       " 'convnextv2_huge.fcmae_ft_in22k_in1k_384',\n",
       " 'convnextv2_huge.fcmae_ft_in22k_in1k_512',\n",
       " 'convnextv2_large.fcmae',\n",
       " 'convnextv2_large.fcmae_ft_in1k',\n",
       " 'convnextv2_large.fcmae_ft_in22k_in1k',\n",
       " 'convnextv2_large.fcmae_ft_in22k_in1k_384',\n",
       " 'convnextv2_nano.fcmae',\n",
       " 'convnextv2_nano.fcmae_ft_in1k',\n",
       " 'convnextv2_nano.fcmae_ft_in22k_in1k',\n",
       " 'convnextv2_nano.fcmae_ft_in22k_in1k_384',\n",
       " 'convnextv2_pico.fcmae',\n",
       " 'convnextv2_pico.fcmae_ft_in1k',\n",
       " 'convnextv2_tiny.fcmae',\n",
       " 'convnextv2_tiny.fcmae_ft_in1k',\n",
       " 'convnextv2_tiny.fcmae_ft_in22k_in1k',\n",
       " 'convnextv2_tiny.fcmae_ft_in22k_in1k_384',\n",
       " 'crossvit_9_240',\n",
       " 'crossvit_9_dagger_240',\n",
       " 'crossvit_15_240',\n",
       " 'crossvit_15_dagger_240',\n",
       " 'crossvit_15_dagger_408',\n",
       " 'crossvit_18_240',\n",
       " 'crossvit_18_dagger_240',\n",
       " 'crossvit_18_dagger_408',\n",
       " 'crossvit_base_240',\n",
       " 'crossvit_small_240',\n",
       " 'crossvit_tiny_240',\n",
       " 'cs3darknet_focus_l',\n",
       " 'cs3darknet_focus_m',\n",
       " 'cs3darknet_l',\n",
       " 'cs3darknet_m',\n",
       " 'cs3darknet_x',\n",
       " 'cs3edgenet_x',\n",
       " 'cs3se_edgenet_x',\n",
       " 'cs3sedarknet_l',\n",
       " 'cs3sedarknet_x',\n",
       " 'cspdarknet53',\n",
       " 'cspresnet50',\n",
       " 'cspresnext50',\n",
       " 'darknet53',\n",
       " 'darknetaa53',\n",
       " 'davit_base.msft_in1k',\n",
       " 'davit_small.msft_in1k',\n",
       " 'davit_tiny.msft_in1k',\n",
       " 'deit3_base_patch16_224.fb_in1k',\n",
       " 'deit3_base_patch16_224.fb_in22k_ft_in1k',\n",
       " 'deit3_base_patch16_384.fb_in1k',\n",
       " 'deit3_base_patch16_384.fb_in22k_ft_in1k',\n",
       " 'deit3_huge_patch14_224.fb_in1k',\n",
       " 'deit3_huge_patch14_224.fb_in22k_ft_in1k',\n",
       " 'deit3_large_patch16_224.fb_in1k',\n",
       " 'deit3_large_patch16_224.fb_in22k_ft_in1k',\n",
       " 'deit3_large_patch16_384.fb_in1k',\n",
       " 'deit3_large_patch16_384.fb_in22k_ft_in1k',\n",
       " 'deit3_medium_patch16_224.fb_in1k',\n",
       " 'deit3_medium_patch16_224.fb_in22k_ft_in1k',\n",
       " 'deit3_small_patch16_224.fb_in1k',\n",
       " 'deit3_small_patch16_224.fb_in22k_ft_in1k',\n",
       " 'deit3_small_patch16_384.fb_in1k',\n",
       " 'deit3_small_patch16_384.fb_in22k_ft_in1k',\n",
       " 'deit_base_distilled_patch16_224.fb_in1k',\n",
       " 'deit_base_distilled_patch16_384.fb_in1k',\n",
       " 'deit_base_patch16_224.fb_in1k',\n",
       " 'deit_base_patch16_384.fb_in1k',\n",
       " 'deit_small_distilled_patch16_224.fb_in1k',\n",
       " 'deit_small_patch16_224.fb_in1k',\n",
       " 'deit_tiny_distilled_patch16_224.fb_in1k',\n",
       " 'deit_tiny_patch16_224.fb_in1k',\n",
       " 'densenet121',\n",
       " 'densenet161',\n",
       " 'densenet169',\n",
       " 'densenet201',\n",
       " 'densenetblur121d',\n",
       " 'dla34',\n",
       " 'dla46_c',\n",
       " 'dla46x_c',\n",
       " 'dla60',\n",
       " 'dla60_res2net',\n",
       " 'dla60_res2next',\n",
       " 'dla60x',\n",
       " 'dla60x_c',\n",
       " 'dla102',\n",
       " 'dla102x',\n",
       " 'dla102x2',\n",
       " 'dla169',\n",
       " 'dm_nfnet_f0.dm_in1k',\n",
       " 'dm_nfnet_f1.dm_in1k',\n",
       " 'dm_nfnet_f2.dm_in1k',\n",
       " 'dm_nfnet_f3.dm_in1k',\n",
       " 'dm_nfnet_f4.dm_in1k',\n",
       " 'dm_nfnet_f5.dm_in1k',\n",
       " 'dm_nfnet_f6.dm_in1k',\n",
       " 'dpn68',\n",
       " 'dpn68b',\n",
       " 'dpn92',\n",
       " 'dpn98',\n",
       " 'dpn107',\n",
       " 'dpn131',\n",
       " 'eca_botnext26ts_256',\n",
       " 'eca_halonext26ts',\n",
       " 'eca_nfnet_l0.ra2_in1k',\n",
       " 'eca_nfnet_l1.ra2_in1k',\n",
       " 'eca_nfnet_l2.ra3_in1k',\n",
       " 'eca_resnet33ts.ra2_in1k',\n",
       " 'eca_resnext26ts.ch_in1k',\n",
       " 'ecaresnet26t',\n",
       " 'ecaresnet50d',\n",
       " 'ecaresnet50d_pruned',\n",
       " 'ecaresnet50t',\n",
       " 'ecaresnet101d',\n",
       " 'ecaresnet101d_pruned',\n",
       " 'ecaresnet269d',\n",
       " 'ecaresnetlight',\n",
       " 'edgenext_base',\n",
       " 'edgenext_small',\n",
       " 'edgenext_small_rw',\n",
       " 'edgenext_x_small',\n",
       " 'edgenext_xx_small',\n",
       " 'efficientformer_l1.snap_dist_in1k',\n",
       " 'efficientformer_l3.snap_dist_in1k',\n",
       " 'efficientformer_l7.snap_dist_in1k',\n",
       " 'efficientformerv2_l.snap_dist_in1k',\n",
       " 'efficientformerv2_s0.snap_dist_in1k',\n",
       " 'efficientformerv2_s1.snap_dist_in1k',\n",
       " 'efficientformerv2_s2.snap_dist_in1k',\n",
       " 'efficientnet_b0.ra_in1k',\n",
       " 'efficientnet_b1.ft_in1k',\n",
       " 'efficientnet_b1_pruned.in1k',\n",
       " 'efficientnet_b2.ra_in1k',\n",
       " 'efficientnet_b2_pruned.in1k',\n",
       " 'efficientnet_b3.ra2_in1k',\n",
       " 'efficientnet_b3_pruned.in1k',\n",
       " 'efficientnet_b4.ra2_in1k',\n",
       " 'efficientnet_b5.in12k',\n",
       " 'efficientnet_b5.in12k_ft_in1k',\n",
       " 'efficientnet_el.ra_in1k',\n",
       " 'efficientnet_el_pruned.in1k',\n",
       " 'efficientnet_em.ra2_in1k',\n",
       " 'efficientnet_es.ra_in1k',\n",
       " 'efficientnet_es_pruned.in1k',\n",
       " 'efficientnet_lite0.ra_in1k',\n",
       " 'efficientnetv2_rw_m.agc_in1k',\n",
       " 'efficientnetv2_rw_s.ra2_in1k',\n",
       " 'efficientnetv2_rw_t.ra2_in1k',\n",
       " 'ens_adv_inception_resnet_v2',\n",
       " 'ese_vovnet19b_dw',\n",
       " 'ese_vovnet39b',\n",
       " 'eva_giant_patch14_224.clip_ft_in1k',\n",
       " 'eva_giant_patch14_336.clip_ft_in1k',\n",
       " 'eva_giant_patch14_336.m30m_ft_in22k_in1k',\n",
       " 'eva_giant_patch14_560.m30m_ft_in22k_in1k',\n",
       " 'eva_large_patch14_196.in22k_ft_in1k',\n",
       " 'eva_large_patch14_196.in22k_ft_in22k_in1k',\n",
       " 'eva_large_patch14_336.in22k_ft_in1k',\n",
       " 'eva_large_patch14_336.in22k_ft_in22k_in1k',\n",
       " 'fbnetc_100.rmsp_in1k',\n",
       " 'fbnetv3_b.ra2_in1k',\n",
       " 'fbnetv3_d.ra2_in1k',\n",
       " 'fbnetv3_g.ra2_in1k',\n",
       " 'flexivit_base.300ep_in1k',\n",
       " 'flexivit_base.300ep_in21k',\n",
       " 'flexivit_base.600ep_in1k',\n",
       " 'flexivit_base.1000ep_in21k',\n",
       " 'flexivit_base.1200ep_in1k',\n",
       " 'flexivit_base.patch16_in21k',\n",
       " 'flexivit_base.patch30_in21k',\n",
       " 'flexivit_large.300ep_in1k',\n",
       " 'flexivit_large.600ep_in1k',\n",
       " 'flexivit_large.1200ep_in1k',\n",
       " 'flexivit_small.300ep_in1k',\n",
       " 'flexivit_small.600ep_in1k',\n",
       " 'flexivit_small.1200ep_in1k',\n",
       " 'focalnet_base_lrf.ms_in1k',\n",
       " 'focalnet_base_srf.ms_in1k',\n",
       " 'focalnet_huge_fl3.ms_in22k',\n",
       " 'focalnet_huge_fl4.ms_in22k',\n",
       " 'focalnet_large_fl3.ms_in22k',\n",
       " 'focalnet_large_fl4.ms_in22k',\n",
       " 'focalnet_small_lrf.ms_in1k',\n",
       " 'focalnet_small_srf.ms_in1k',\n",
       " 'focalnet_tiny_lrf.ms_in1k',\n",
       " 'focalnet_tiny_srf.ms_in1k',\n",
       " 'focalnet_xlarge_fl3.ms_in22k',\n",
       " 'focalnet_xlarge_fl4.ms_in22k',\n",
       " 'gc_efficientnetv2_rw_t.agc_in1k',\n",
       " 'gcresnet33ts.ra2_in1k',\n",
       " 'gcresnet50t.ra2_in1k',\n",
       " 'gcresnext26ts.ch_in1k',\n",
       " 'gcresnext50ts.ch_in1k',\n",
       " 'gcvit_base',\n",
       " 'gcvit_small',\n",
       " 'gcvit_tiny',\n",
       " 'gcvit_xtiny',\n",
       " 'gcvit_xxtiny',\n",
       " 'gernet_l.idstcv_in1k',\n",
       " 'gernet_m.idstcv_in1k',\n",
       " 'gernet_s.idstcv_in1k',\n",
       " 'ghostnet_100',\n",
       " 'gluon_inception_v3',\n",
       " 'gluon_resnet18_v1b',\n",
       " 'gluon_resnet34_v1b',\n",
       " 'gluon_resnet50_v1b',\n",
       " 'gluon_resnet50_v1c',\n",
       " 'gluon_resnet50_v1d',\n",
       " 'gluon_resnet50_v1s',\n",
       " 'gluon_resnet101_v1b',\n",
       " 'gluon_resnet101_v1c',\n",
       " 'gluon_resnet101_v1d',\n",
       " 'gluon_resnet101_v1s',\n",
       " 'gluon_resnet152_v1b',\n",
       " 'gluon_resnet152_v1c',\n",
       " 'gluon_resnet152_v1d',\n",
       " 'gluon_resnet152_v1s',\n",
       " 'gluon_resnext50_32x4d',\n",
       " 'gluon_resnext101_32x4d',\n",
       " 'gluon_resnext101_64x4d',\n",
       " 'gluon_senet154',\n",
       " 'gluon_seresnext50_32x4d',\n",
       " 'gluon_seresnext101_32x4d',\n",
       " 'gluon_seresnext101_64x4d',\n",
       " 'gluon_xception65',\n",
       " 'gmixer_24_224.ra3_in1k',\n",
       " 'gmlp_s16_224.ra3_in1k',\n",
       " 'halo2botnet50ts_256',\n",
       " 'halonet26t',\n",
       " 'halonet50ts',\n",
       " 'haloregnetz_b',\n",
       " 'hardcorenas_a',\n",
       " 'hardcorenas_b',\n",
       " 'hardcorenas_c',\n",
       " 'hardcorenas_d',\n",
       " 'hardcorenas_e',\n",
       " 'hardcorenas_f',\n",
       " 'hrnet_w18',\n",
       " 'hrnet_w18_small',\n",
       " 'hrnet_w18_small_v2',\n",
       " 'hrnet_w30',\n",
       " 'hrnet_w32',\n",
       " 'hrnet_w40',\n",
       " 'hrnet_w44',\n",
       " 'hrnet_w48',\n",
       " 'hrnet_w64',\n",
       " 'ig_resnext101_32x8d',\n",
       " 'ig_resnext101_32x16d',\n",
       " 'ig_resnext101_32x32d',\n",
       " 'ig_resnext101_32x48d',\n",
       " 'inception_resnet_v2',\n",
       " 'inception_v3',\n",
       " 'inception_v4',\n",
       " 'jx_nest_base',\n",
       " 'jx_nest_small',\n",
       " 'jx_nest_tiny',\n",
       " 'lambda_resnet26rpt_256',\n",
       " 'lambda_resnet26t',\n",
       " 'lambda_resnet50ts',\n",
       " 'lamhalobotnet50ts_256',\n",
       " 'lcnet_050.ra2_in1k',\n",
       " 'lcnet_075.ra2_in1k',\n",
       " 'lcnet_100.ra2_in1k',\n",
       " 'legacy_senet154',\n",
       " 'legacy_seresnet18',\n",
       " 'legacy_seresnet34',\n",
       " 'legacy_seresnet50',\n",
       " 'legacy_seresnet101',\n",
       " 'legacy_seresnet152',\n",
       " 'legacy_seresnext26_32x4d',\n",
       " 'legacy_seresnext50_32x4d',\n",
       " 'legacy_seresnext101_32x4d',\n",
       " 'levit_128.fb_dist_in1k',\n",
       " 'levit_128s.fb_dist_in1k',\n",
       " 'levit_192.fb_dist_in1k',\n",
       " 'levit_256.fb_dist_in1k',\n",
       " 'levit_384.fb_dist_in1k',\n",
       " 'levit_conv_128.fb_dist_in1k',\n",
       " 'levit_conv_128s.fb_dist_in1k',\n",
       " 'levit_conv_192.fb_dist_in1k',\n",
       " 'levit_conv_256.fb_dist_in1k',\n",
       " 'levit_conv_384.fb_dist_in1k',\n",
       " 'maxvit_base_tf_224.in1k',\n",
       " 'maxvit_base_tf_384.in1k',\n",
       " 'maxvit_base_tf_384.in21k_ft_in1k',\n",
       " 'maxvit_base_tf_512.in1k',\n",
       " 'maxvit_base_tf_512.in21k_ft_in1k',\n",
       " 'maxvit_large_tf_224.in1k',\n",
       " 'maxvit_large_tf_384.in1k',\n",
       " 'maxvit_large_tf_384.in21k_ft_in1k',\n",
       " 'maxvit_large_tf_512.in1k',\n",
       " 'maxvit_large_tf_512.in21k_ft_in1k',\n",
       " 'maxvit_nano_rw_256.sw_in1k',\n",
       " 'maxvit_rmlp_base_rw_224.sw_in12k',\n",
       " 'maxvit_rmlp_base_rw_224.sw_in12k_ft_in1k',\n",
       " 'maxvit_rmlp_base_rw_384.sw_in12k_ft_in1k',\n",
       " 'maxvit_rmlp_nano_rw_256.sw_in1k',\n",
       " 'maxvit_rmlp_pico_rw_256.sw_in1k',\n",
       " 'maxvit_rmlp_small_rw_224.sw_in1k',\n",
       " 'maxvit_rmlp_tiny_rw_256.sw_in1k',\n",
       " 'maxvit_small_tf_224.in1k',\n",
       " 'maxvit_small_tf_384.in1k',\n",
       " 'maxvit_small_tf_512.in1k',\n",
       " 'maxvit_tiny_rw_224.sw_in1k',\n",
       " 'maxvit_tiny_tf_224.in1k',\n",
       " 'maxvit_tiny_tf_384.in1k',\n",
       " 'maxvit_tiny_tf_512.in1k',\n",
       " 'maxvit_xlarge_tf_384.in21k_ft_in1k',\n",
       " 'maxvit_xlarge_tf_512.in21k_ft_in1k',\n",
       " 'maxxvit_rmlp_nano_rw_256.sw_in1k',\n",
       " 'maxxvit_rmlp_small_rw_256.sw_in1k',\n",
       " 'maxxvitv2_nano_rw_256.sw_in1k',\n",
       " 'maxxvitv2_rmlp_base_rw_224.sw_in12k',\n",
       " 'maxxvitv2_rmlp_base_rw_224.sw_in12k_ft_in1k',\n",
       " 'maxxvitv2_rmlp_base_rw_384.sw_in12k_ft_in1k',\n",
       " 'mixer_b16_224.goog_in21k',\n",
       " 'mixer_b16_224.goog_in21k_ft_in1k',\n",
       " 'mixer_b16_224.miil_in21k',\n",
       " 'mixer_b16_224.miil_in21k_ft_in1k',\n",
       " 'mixer_l16_224.goog_in21k',\n",
       " 'mixer_l16_224.goog_in21k_ft_in1k',\n",
       " 'mixnet_l.ft_in1k',\n",
       " 'mixnet_m.ft_in1k',\n",
       " 'mixnet_s.ft_in1k',\n",
       " 'mixnet_xl.ra_in1k',\n",
       " 'mnasnet_100.rmsp_in1k',\n",
       " 'mnasnet_small.lamb_in1k',\n",
       " 'mobilenetv2_050.lamb_in1k',\n",
       " 'mobilenetv2_100.ra_in1k',\n",
       " 'mobilenetv2_110d.ra_in1k',\n",
       " 'mobilenetv2_120d.ra_in1k',\n",
       " 'mobilenetv2_140.ra_in1k',\n",
       " 'mobilenetv3_large_100.miil_in21k',\n",
       " 'mobilenetv3_large_100.miil_in21k_ft_in1k',\n",
       " 'mobilenetv3_large_100.ra_in1k',\n",
       " 'mobilenetv3_rw.rmsp_in1k',\n",
       " 'mobilenetv3_small_050.lamb_in1k',\n",
       " 'mobilenetv3_small_075.lamb_in1k',\n",
       " 'mobilenetv3_small_100.lamb_in1k',\n",
       " 'mobilevit_s',\n",
       " 'mobilevit_xs',\n",
       " 'mobilevit_xxs',\n",
       " 'mobilevitv2_050',\n",
       " 'mobilevitv2_075',\n",
       " 'mobilevitv2_100',\n",
       " 'mobilevitv2_125',\n",
       " 'mobilevitv2_150',\n",
       " 'mobilevitv2_150_384_in22ft1k',\n",
       " 'mobilevitv2_150_in22ft1k',\n",
       " 'mobilevitv2_175',\n",
       " 'mobilevitv2_175_384_in22ft1k',\n",
       " 'mobilevitv2_175_in22ft1k',\n",
       " 'mobilevitv2_200',\n",
       " 'mobilevitv2_200_384_in22ft1k',\n",
       " 'mobilevitv2_200_in22ft1k',\n",
       " 'mvitv2_base',\n",
       " 'mvitv2_large',\n",
       " 'mvitv2_small',\n",
       " 'mvitv2_tiny',\n",
       " 'nasnetalarge',\n",
       " 'nf_regnet_b1.ra2_in1k',\n",
       " 'nf_resnet50.ra2_in1k',\n",
       " 'nfnet_l0.ra2_in1k',\n",
       " 'pit_b_224',\n",
       " 'pit_b_distilled_224',\n",
       " 'pit_s_224',\n",
       " 'pit_s_distilled_224',\n",
       " 'pit_ti_224',\n",
       " 'pit_ti_distilled_224',\n",
       " 'pit_xs_224',\n",
       " 'pit_xs_distilled_224',\n",
       " 'pnasnet5large',\n",
       " 'poolformer_m36',\n",
       " 'poolformer_m48',\n",
       " 'poolformer_s12',\n",
       " 'poolformer_s24',\n",
       " 'poolformer_s36',\n",
       " 'pvt_v2_b0',\n",
       " 'pvt_v2_b1',\n",
       " 'pvt_v2_b2',\n",
       " 'pvt_v2_b2_li',\n",
       " 'pvt_v2_b3',\n",
       " 'pvt_v2_b4',\n",
       " 'pvt_v2_b5',\n",
       " 'regnetv_040.ra3_in1k',\n",
       " 'regnetv_064.ra3_in1k',\n",
       " 'regnetx_002.pycls_in1k',\n",
       " 'regnetx_004.pycls_in1k',\n",
       " 'regnetx_004_tv.tv2_in1k',\n",
       " 'regnetx_006.pycls_in1k',\n",
       " 'regnetx_008.pycls_in1k',\n",
       " 'regnetx_008.tv2_in1k',\n",
       " 'regnetx_016.pycls_in1k',\n",
       " 'regnetx_016.tv2_in1k',\n",
       " 'regnetx_032.pycls_in1k',\n",
       " 'regnetx_032.tv2_in1k',\n",
       " 'regnetx_040.pycls_in1k',\n",
       " 'regnetx_064.pycls_in1k',\n",
       " 'regnetx_080.pycls_in1k',\n",
       " 'regnetx_080.tv2_in1k',\n",
       " 'regnetx_120.pycls_in1k',\n",
       " 'regnetx_160.pycls_in1k',\n",
       " 'regnetx_160.tv2_in1k',\n",
       " 'regnetx_320.pycls_in1k',\n",
       " 'regnetx_320.tv2_in1k',\n",
       " 'regnety_002.pycls_in1k',\n",
       " 'regnety_004.pycls_in1k',\n",
       " 'regnety_004.tv2_in1k',\n",
       " 'regnety_006.pycls_in1k',\n",
       " 'regnety_008.pycls_in1k',\n",
       " 'regnety_008_tv.tv2_in1k',\n",
       " 'regnety_016.pycls_in1k',\n",
       " 'regnety_016.tv2_in1k',\n",
       " 'regnety_032.pycls_in1k',\n",
       " 'regnety_032.ra_in1k',\n",
       " 'regnety_032.tv2_in1k',\n",
       " 'regnety_040.pycls_in1k',\n",
       " 'regnety_040.ra3_in1k',\n",
       " 'regnety_064.pycls_in1k',\n",
       " 'regnety_064.ra3_in1k',\n",
       " 'regnety_080.pycls_in1k',\n",
       " 'regnety_080.ra3_in1k',\n",
       " 'regnety_080_tv.tv2_in1k',\n",
       " 'regnety_120.pycls_in1k',\n",
       " 'regnety_120.sw_in12k',\n",
       " 'regnety_120.sw_in12k_ft_in1k',\n",
       " 'regnety_160.deit_in1k',\n",
       " 'regnety_160.lion_in12k_ft_in1k',\n",
       " 'regnety_160.pycls_in1k',\n",
       " 'regnety_160.sw_in12k',\n",
       " 'regnety_160.sw_in12k_ft_in1k',\n",
       " 'regnety_160.swag_ft_in1k',\n",
       " 'regnety_160.swag_lc_in1k',\n",
       " 'regnety_160.tv2_in1k',\n",
       " 'regnety_320.pycls_in1k',\n",
       " 'regnety_320.seer',\n",
       " 'regnety_320.seer_ft_in1k',\n",
       " 'regnety_320.swag_ft_in1k',\n",
       " 'regnety_320.swag_lc_in1k',\n",
       " 'regnety_320.tv2_in1k',\n",
       " 'regnety_640.seer',\n",
       " 'regnety_640.seer_ft_in1k',\n",
       " 'regnety_1280.seer',\n",
       " 'regnety_1280.seer_ft_in1k',\n",
       " 'regnety_1280.swag_ft_in1k',\n",
       " 'regnety_1280.swag_lc_in1k',\n",
       " 'regnety_2560.seer_ft_in1k',\n",
       " 'regnetz_040.ra3_in1k',\n",
       " 'regnetz_040_h.ra3_in1k',\n",
       " 'regnetz_b16.ra3_in1k',\n",
       " 'regnetz_c16.ra3_in1k',\n",
       " 'regnetz_c16_evos.ch_in1k',\n",
       " 'regnetz_d8.ra3_in1k',\n",
       " 'regnetz_d8_evos.ch_in1k',\n",
       " 'regnetz_d32.ra3_in1k',\n",
       " 'regnetz_e8.ra3_in1k',\n",
       " 'repvgg_a2.rvgg_in1k',\n",
       " 'repvgg_b0.rvgg_in1k',\n",
       " 'repvgg_b1.rvgg_in1k',\n",
       " 'repvgg_b1g4.rvgg_in1k',\n",
       " 'repvgg_b2.rvgg_in1k',\n",
       " 'repvgg_b2g4.rvgg_in1k',\n",
       " 'repvgg_b3.rvgg_in1k',\n",
       " 'repvgg_b3g4.rvgg_in1k',\n",
       " 'res2net50_14w_8s',\n",
       " 'res2net50_26w_4s',\n",
       " 'res2net50_26w_6s',\n",
       " 'res2net50_26w_8s',\n",
       " 'res2net50_48w_2s',\n",
       " 'res2net101_26w_4s',\n",
       " 'res2next50',\n",
       " 'resmlp_12_224.fb_dino',\n",
       " 'resmlp_12_224.fb_distilled_in1k',\n",
       " 'resmlp_12_224.fb_in1k',\n",
       " 'resmlp_24_224.fb_dino',\n",
       " 'resmlp_24_224.fb_distilled_in1k',\n",
       " 'resmlp_24_224.fb_in1k',\n",
       " 'resmlp_36_224.fb_distilled_in1k',\n",
       " 'resmlp_36_224.fb_in1k',\n",
       " 'resmlp_big_24_224.fb_distilled_in1k',\n",
       " 'resmlp_big_24_224.fb_in1k',\n",
       " 'resmlp_big_24_224.fb_in22k_ft_in1k',\n",
       " 'resnest14d',\n",
       " 'resnest26d',\n",
       " 'resnest50d',\n",
       " 'resnest50d_1s4x24d',\n",
       " 'resnest50d_4s2x40d',\n",
       " 'resnest101e',\n",
       " 'resnest200e',\n",
       " 'resnest269e',\n",
       " 'resnet10t',\n",
       " 'resnet14t',\n",
       " 'resnet18',\n",
       " 'resnet18d',\n",
       " 'resnet26',\n",
       " 'resnet26d',\n",
       " 'resnet26t',\n",
       " 'resnet32ts.ra2_in1k',\n",
       " 'resnet33ts.ra2_in1k',\n",
       " 'resnet34',\n",
       " 'resnet34d',\n",
       " 'resnet50',\n",
       " 'resnet50_gn',\n",
       " 'resnet50d',\n",
       " 'resnet51q.ra2_in1k',\n",
       " 'resnet61q.ra2_in1k',\n",
       " 'resnet101',\n",
       " 'resnet101d',\n",
       " 'resnet152',\n",
       " 'resnet152d',\n",
       " 'resnet200d',\n",
       " 'resnetaa50',\n",
       " 'resnetblur50',\n",
       " 'resnetrs50',\n",
       " 'resnetrs101',\n",
       " 'resnetrs152',\n",
       " 'resnetrs200',\n",
       " 'resnetrs270',\n",
       " 'resnetrs350',\n",
       " 'resnetrs420',\n",
       " 'resnetv2_50.a1h_in1k',\n",
       " 'resnetv2_50d_evos.ah_in1k',\n",
       " 'resnetv2_50d_gn.ah_in1k',\n",
       " 'resnetv2_50x1_bit.goog_distilled_in1k',\n",
       " 'resnetv2_50x1_bit.goog_in21k',\n",
       " 'resnetv2_50x1_bit.goog_in21k_ft_in1k',\n",
       " 'resnetv2_50x3_bit.goog_in21k',\n",
       " 'resnetv2_50x3_bit.goog_in21k_ft_in1k',\n",
       " 'resnetv2_101.a1h_in1k',\n",
       " 'resnetv2_101x1_bit.goog_in21k',\n",
       " 'resnetv2_101x1_bit.goog_in21k_ft_in1k',\n",
       " 'resnetv2_101x3_bit.goog_in21k',\n",
       " 'resnetv2_101x3_bit.goog_in21k_ft_in1k',\n",
       " 'resnetv2_152x2_bit.goog_in21k',\n",
       " 'resnetv2_152x2_bit.goog_in21k_ft_in1k',\n",
       " 'resnetv2_152x2_bit.goog_teacher_in21k_ft_in1k',\n",
       " 'resnetv2_152x2_bit.goog_teacher_in21k_ft_in1k_384',\n",
       " 'resnetv2_152x4_bit.goog_in21k',\n",
       " 'resnetv2_152x4_bit.goog_in21k_ft_in1k',\n",
       " 'resnext26ts.ra2_in1k',\n",
       " 'resnext50_32x4d',\n",
       " 'resnext50d_32x4d',\n",
       " 'resnext101_32x8d',\n",
       " 'resnext101_64x4d',\n",
       " 'rexnet_100.nav_in1k',\n",
       " 'rexnet_130.nav_in1k',\n",
       " 'rexnet_150.nav_in1k',\n",
       " 'rexnet_200.nav_in1k',\n",
       " 'rexnet_300.nav_in1k',\n",
       " 'rexnetr_200.sw_in12k',\n",
       " 'rexnetr_200.sw_in12k_ft_in1k',\n",
       " 'rexnetr_300.sw_in12k',\n",
       " 'rexnetr_300.sw_in12k_ft_in1k',\n",
       " 'sebotnet33ts_256',\n",
       " 'sehalonet33ts',\n",
       " 'selecsls42b',\n",
       " 'selecsls60',\n",
       " 'selecsls60b',\n",
       " 'semnasnet_075.rmsp_in1k',\n",
       " 'semnasnet_100.rmsp_in1k',\n",
       " 'sequencer2d_l',\n",
       " 'sequencer2d_m',\n",
       " 'sequencer2d_s',\n",
       " 'seresnet33ts.ra2_in1k',\n",
       " 'seresnet50',\n",
       " 'seresnet152d',\n",
       " 'seresnext26d_32x4d',\n",
       " 'seresnext26t_32x4d',\n",
       " 'seresnext26ts.ch_in1k',\n",
       " 'seresnext50_32x4d',\n",
       " 'seresnext101_32x8d',\n",
       " 'seresnext101d_32x8d',\n",
       " 'seresnextaa101d_32x8d',\n",
       " 'skresnet18',\n",
       " 'skresnet34',\n",
       " 'skresnext50_32x4d',\n",
       " 'spnasnet_100.rmsp_in1k',\n",
       " 'ssl_resnet18',\n",
       " 'ssl_resnet50',\n",
       " 'ssl_resnext50_32x4d',\n",
       " 'ssl_resnext101_32x4d',\n",
       " 'ssl_resnext101_32x8d',\n",
       " 'ssl_resnext101_32x16d',\n",
       " 'swin_base_patch4_window7_224.ms_in1k',\n",
       " 'swin_base_patch4_window7_224.ms_in22k',\n",
       " 'swin_base_patch4_window7_224.ms_in22k_ft_in1k',\n",
       " 'swin_base_patch4_window12_384.ms_in1k',\n",
       " 'swin_base_patch4_window12_384.ms_in22k',\n",
       " 'swin_base_patch4_window12_384.ms_in22k_ft_in1k',\n",
       " 'swin_large_patch4_window7_224.ms_in22k',\n",
       " 'swin_large_patch4_window7_224.ms_in22k_ft_in1k',\n",
       " 'swin_large_patch4_window12_384.ms_in22k',\n",
       " 'swin_large_patch4_window12_384.ms_in22k_ft_in1k',\n",
       " 'swin_s3_base_224.ms_in1k',\n",
       " 'swin_s3_small_224.ms_in1k',\n",
       " 'swin_s3_tiny_224.ms_in1k',\n",
       " 'swin_small_patch4_window7_224.ms_in1k',\n",
       " 'swin_small_patch4_window7_224.ms_in22k',\n",
       " 'swin_small_patch4_window7_224.ms_in22k_ft_in1k',\n",
       " 'swin_tiny_patch4_window7_224.ms_in1k',\n",
       " 'swin_tiny_patch4_window7_224.ms_in22k',\n",
       " 'swin_tiny_patch4_window7_224.ms_in22k_ft_in1k',\n",
       " 'swinv2_base_window8_256.ms_in1k',\n",
       " 'swinv2_base_window12_192.ms_in22k',\n",
       " 'swinv2_base_window12to16_192to256.ms_in22k_ft_in1k',\n",
       " 'swinv2_base_window12to24_192to384.ms_in22k_ft_in1k',\n",
       " 'swinv2_base_window16_256.ms_in1k',\n",
       " 'swinv2_cr_small_224.sw_in1k',\n",
       " 'swinv2_cr_small_ns_224.sw_in1k',\n",
       " 'swinv2_cr_tiny_ns_224.sw_in1k',\n",
       " 'swinv2_large_window12_192.ms_in22k',\n",
       " 'swinv2_large_window12to16_192to256.ms_in22k_ft_in1k',\n",
       " 'swinv2_large_window12to24_192to384.ms_in22k_ft_in1k',\n",
       " 'swinv2_small_window8_256.ms_in1k',\n",
       " 'swinv2_small_window16_256.ms_in1k',\n",
       " 'swinv2_tiny_window8_256.ms_in1k',\n",
       " 'swinv2_tiny_window16_256.ms_in1k',\n",
       " 'swsl_resnet18',\n",
       " 'swsl_resnet50',\n",
       " 'swsl_resnext50_32x4d',\n",
       " 'swsl_resnext101_32x4d',\n",
       " 'swsl_resnext101_32x8d',\n",
       " 'swsl_resnext101_32x16d',\n",
       " 'tf_efficientnet_b0.aa_in1k',\n",
       " 'tf_efficientnet_b0.ap_in1k',\n",
       " 'tf_efficientnet_b0.ns_jft_in1k',\n",
       " 'tf_efficientnet_b1.aa_in1k',\n",
       " 'tf_efficientnet_b1.ap_in1k',\n",
       " 'tf_efficientnet_b1.ns_jft_in1k',\n",
       " 'tf_efficientnet_b2.aa_in1k',\n",
       " 'tf_efficientnet_b2.ap_in1k',\n",
       " 'tf_efficientnet_b2.ns_jft_in1k',\n",
       " 'tf_efficientnet_b3.aa_in1k',\n",
       " 'tf_efficientnet_b3.ap_in1k',\n",
       " 'tf_efficientnet_b3.ns_jft_in1k',\n",
       " 'tf_efficientnet_b4.aa_in1k',\n",
       " 'tf_efficientnet_b4.ap_in1k',\n",
       " 'tf_efficientnet_b4.ns_jft_in1k',\n",
       " 'tf_efficientnet_b5.ap_in1k',\n",
       " 'tf_efficientnet_b5.ns_jft_in1k',\n",
       " 'tf_efficientnet_b5.ra_in1k',\n",
       " 'tf_efficientnet_b6.aa_in1k',\n",
       " 'tf_efficientnet_b6.ap_in1k',\n",
       " 'tf_efficientnet_b6.ns_jft_in1k',\n",
       " 'tf_efficientnet_b7.ap_in1k',\n",
       " 'tf_efficientnet_b7.ns_jft_in1k',\n",
       " 'tf_efficientnet_b7.ra_in1k',\n",
       " 'tf_efficientnet_b8.ap_in1k',\n",
       " 'tf_efficientnet_b8.ra_in1k',\n",
       " 'tf_efficientnet_cc_b0_4e.in1k',\n",
       " 'tf_efficientnet_cc_b0_8e.in1k',\n",
       " 'tf_efficientnet_cc_b1_8e.in1k',\n",
       " 'tf_efficientnet_el.in1k',\n",
       " 'tf_efficientnet_em.in1k',\n",
       " 'tf_efficientnet_es.in1k',\n",
       " 'tf_efficientnet_l2.ns_jft_in1k',\n",
       " 'tf_efficientnet_l2.ns_jft_in1k_475',\n",
       " 'tf_efficientnet_lite0.in1k',\n",
       " 'tf_efficientnet_lite1.in1k',\n",
       " 'tf_efficientnet_lite2.in1k',\n",
       " 'tf_efficientnet_lite3.in1k',\n",
       " 'tf_efficientnet_lite4.in1k',\n",
       " 'tf_efficientnetv2_b0.in1k',\n",
       " 'tf_efficientnetv2_b1.in1k',\n",
       " 'tf_efficientnetv2_b2.in1k',\n",
       " 'tf_efficientnetv2_b3.in1k',\n",
       " 'tf_efficientnetv2_b3.in21k',\n",
       " 'tf_efficientnetv2_b3.in21k_ft_in1k',\n",
       " 'tf_efficientnetv2_l.in1k',\n",
       " 'tf_efficientnetv2_l.in21k',\n",
       " 'tf_efficientnetv2_l.in21k_ft_in1k',\n",
       " 'tf_efficientnetv2_m.in1k',\n",
       " 'tf_efficientnetv2_m.in21k',\n",
       " 'tf_efficientnetv2_m.in21k_ft_in1k',\n",
       " 'tf_efficientnetv2_s.in1k',\n",
       " 'tf_efficientnetv2_s.in21k',\n",
       " 'tf_efficientnetv2_s.in21k_ft_in1k',\n",
       " 'tf_efficientnetv2_xl.in21k',\n",
       " 'tf_efficientnetv2_xl.in21k_ft_in1k',\n",
       " 'tf_inception_v3',\n",
       " 'tf_mixnet_l.in1k',\n",
       " 'tf_mixnet_m.in1k',\n",
       " 'tf_mixnet_s.in1k',\n",
       " 'tf_mobilenetv3_large_075.in1k',\n",
       " 'tf_mobilenetv3_large_100.in1k',\n",
       " 'tf_mobilenetv3_large_minimal_100.in1k',\n",
       " 'tf_mobilenetv3_small_075.in1k',\n",
       " 'tf_mobilenetv3_small_100.in1k',\n",
       " 'tf_mobilenetv3_small_minimal_100.in1k',\n",
       " 'tinynet_a.in1k',\n",
       " 'tinynet_b.in1k',\n",
       " 'tinynet_c.in1k',\n",
       " 'tinynet_d.in1k',\n",
       " 'tinynet_e.in1k',\n",
       " 'tnt_s_patch16_224',\n",
       " 'tresnet_l',\n",
       " 'tresnet_l_448',\n",
       " 'tresnet_m',\n",
       " 'tresnet_m_448',\n",
       " 'tresnet_m_miil_in21k',\n",
       " 'tresnet_v2_l',\n",
       " 'tresnet_xl',\n",
       " 'tresnet_xl_448',\n",
       " 'tv_densenet121',\n",
       " 'tv_resnet34',\n",
       " 'tv_resnet50',\n",
       " 'tv_resnet101',\n",
       " 'tv_resnet152',\n",
       " 'tv_resnext50_32x4d',\n",
       " 'twins_pcpvt_base',\n",
       " 'twins_pcpvt_large',\n",
       " 'twins_pcpvt_small',\n",
       " 'twins_svt_base',\n",
       " 'twins_svt_large',\n",
       " 'twins_svt_small',\n",
       " 'vgg11',\n",
       " 'vgg11_bn',\n",
       " 'vgg13',\n",
       " 'vgg13_bn',\n",
       " 'vgg16',\n",
       " 'vgg16_bn',\n",
       " 'vgg19',\n",
       " 'vgg19_bn',\n",
       " 'visformer_small',\n",
       " 'vit_base_patch8_224.augreg2_in21k_ft_in1k',\n",
       " 'vit_base_patch8_224.augreg_in21k',\n",
       " 'vit_base_patch8_224.augreg_in21k_ft_in1k',\n",
       " 'vit_base_patch8_224.dino',\n",
       " 'vit_base_patch16_224.augreg2_in21k_ft_in1k',\n",
       " 'vit_base_patch16_224.augreg_in1k',\n",
       " 'vit_base_patch16_224.augreg_in21k',\n",
       " 'vit_base_patch16_224.augreg_in21k_ft_in1k',\n",
       " 'vit_base_patch16_224.dino',\n",
       " 'vit_base_patch16_224.orig_in21k_ft_in1k',\n",
       " 'vit_base_patch16_224.sam',\n",
       " 'vit_base_patch16_224_miil.in21k',\n",
       " 'vit_base_patch16_224_miil.in21k_ft_in1k',\n",
       " 'vit_base_patch16_384.augreg_in1k',\n",
       " 'vit_base_patch16_384.augreg_in21k_ft_in1k',\n",
       " 'vit_base_patch16_384.orig_in21k_ft_in1k',\n",
       " 'vit_base_patch16_clip_224.laion2b_ft_in1k',\n",
       " 'vit_base_patch16_clip_224.laion2b_ft_in12k',\n",
       " 'vit_base_patch16_clip_224.laion2b_ft_in12k_in1k',\n",
       " 'vit_base_patch16_clip_224.openai',\n",
       " 'vit_base_patch16_clip_224.openai_ft_in1k',\n",
       " 'vit_base_patch16_clip_224.openai_ft_in12k',\n",
       " 'vit_base_patch16_clip_224.openai_ft_in12k_in1k',\n",
       " 'vit_base_patch16_clip_384.laion2b_ft_in1k',\n",
       " 'vit_base_patch16_clip_384.laion2b_ft_in12k_in1k',\n",
       " 'vit_base_patch16_clip_384.openai_ft_in1k',\n",
       " 'vit_base_patch16_clip_384.openai_ft_in12k_in1k',\n",
       " 'vit_base_patch16_rpn_224.in1k',\n",
       " 'vit_base_patch32_224.augreg_in1k',\n",
       " 'vit_base_patch32_224.augreg_in21k',\n",
       " 'vit_base_patch32_224.augreg_in21k_ft_in1k',\n",
       " 'vit_base_patch32_224.sam',\n",
       " 'vit_base_patch32_384.augreg_in1k',\n",
       " 'vit_base_patch32_384.augreg_in21k_ft_in1k',\n",
       " 'vit_base_patch32_clip_224.laion2b',\n",
       " 'vit_base_patch32_clip_224.laion2b_ft_in1k',\n",
       " 'vit_base_patch32_clip_224.laion2b_ft_in12k_in1k',\n",
       " 'vit_base_patch32_clip_224.openai',\n",
       " 'vit_base_patch32_clip_224.openai_ft_in1k',\n",
       " 'vit_base_patch32_clip_384.laion2b_ft_in12k_in1k',\n",
       " 'vit_base_patch32_clip_384.openai_ft_in12k_in1k',\n",
       " 'vit_base_patch32_clip_448.laion2b_ft_in12k_in1k',\n",
       " 'vit_base_r50_s16_224.orig_in21k',\n",
       " 'vit_base_r50_s16_384.orig_in21k_ft_in1k',\n",
       " 'vit_giant_patch14_clip_224.laion2b',\n",
       " 'vit_gigantic_patch14_clip_224.laion2b',\n",
       " 'vit_huge_patch14_224.orig_in21k',\n",
       " 'vit_huge_patch14_clip_224.laion2b',\n",
       " 'vit_huge_patch14_clip_224.laion2b_ft_in1k',\n",
       " 'vit_huge_patch14_clip_224.laion2b_ft_in12k',\n",
       " 'vit_huge_patch14_clip_224.laion2b_ft_in12k_in1k',\n",
       " 'vit_huge_patch14_clip_336.laion2b_ft_in12k_in1k',\n",
       " 'vit_large_patch14_clip_224.laion2b',\n",
       " 'vit_large_patch14_clip_224.laion2b_ft_in1k',\n",
       " 'vit_large_patch14_clip_224.laion2b_ft_in12k',\n",
       " 'vit_large_patch14_clip_224.laion2b_ft_in12k_in1k',\n",
       " 'vit_large_patch14_clip_224.openai',\n",
       " 'vit_large_patch14_clip_224.openai_ft_in1k',\n",
       " 'vit_large_patch14_clip_224.openai_ft_in12k',\n",
       " 'vit_large_patch14_clip_224.openai_ft_in12k_in1k',\n",
       " 'vit_large_patch14_clip_336.laion2b_ft_in1k',\n",
       " 'vit_large_patch14_clip_336.laion2b_ft_in12k_in1k',\n",
       " 'vit_large_patch14_clip_336.openai_ft_in12k_in1k',\n",
       " 'vit_large_patch16_224.augreg_in21k',\n",
       " 'vit_large_patch16_224.augreg_in21k_ft_in1k',\n",
       " 'vit_large_patch16_384.augreg_in21k_ft_in1k',\n",
       " 'vit_large_patch32_224.orig_in21k',\n",
       " 'vit_large_patch32_384.orig_in21k_ft_in1k',\n",
       " 'vit_large_r50_s32_224.augreg_in21k',\n",
       " 'vit_large_r50_s32_224.augreg_in21k_ft_in1k',\n",
       " 'vit_large_r50_s32_384.augreg_in21k_ft_in1k',\n",
       " 'vit_medium_patch16_gap_240.in12k',\n",
       " 'vit_medium_patch16_gap_256.in12k_ft_in1k',\n",
       " 'vit_medium_patch16_gap_384.in12k_ft_in1k',\n",
       " 'vit_relpos_base_patch16_224.sw_in1k',\n",
       " 'vit_relpos_base_patch16_clsgap_224.sw_in1k',\n",
       " 'vit_relpos_base_patch32_plus_rpn_256.sw_in1k',\n",
       " 'vit_relpos_medium_patch16_224.sw_in1k',\n",
       " 'vit_relpos_medium_patch16_cls_224.sw_in1k',\n",
       " 'vit_relpos_medium_patch16_rpn_224.sw_in1k',\n",
       " 'vit_relpos_small_patch16_224.sw_in1k',\n",
       " 'vit_small_patch8_224.dino',\n",
       " 'vit_small_patch16_224.augreg_in1k',\n",
       " 'vit_small_patch16_224.augreg_in21k',\n",
       " 'vit_small_patch16_224.augreg_in21k_ft_in1k',\n",
       " 'vit_small_patch16_224.dino',\n",
       " 'vit_small_patch16_384.augreg_in1k',\n",
       " 'vit_small_patch16_384.augreg_in21k_ft_in1k',\n",
       " 'vit_small_patch32_224.augreg_in21k',\n",
       " 'vit_small_patch32_224.augreg_in21k_ft_in1k',\n",
       " 'vit_small_patch32_384.augreg_in21k_ft_in1k',\n",
       " 'vit_small_r26_s32_224.augreg_in21k',\n",
       " 'vit_small_r26_s32_224.augreg_in21k_ft_in1k',\n",
       " 'vit_small_r26_s32_384.augreg_in21k_ft_in1k',\n",
       " 'vit_srelpos_medium_patch16_224.sw_in1k',\n",
       " 'vit_srelpos_small_patch16_224.sw_in1k',\n",
       " 'vit_tiny_patch16_224.augreg_in21k',\n",
       " 'vit_tiny_patch16_224.augreg_in21k_ft_in1k',\n",
       " 'vit_tiny_patch16_384.augreg_in21k_ft_in1k',\n",
       " 'vit_tiny_r_s16_p8_224.augreg_in21k',\n",
       " 'vit_tiny_r_s16_p8_224.augreg_in21k_ft_in1k',\n",
       " 'vit_tiny_r_s16_p8_384.augreg_in21k_ft_in1k',\n",
       " 'volo_d1_224',\n",
       " 'volo_d1_384',\n",
       " 'volo_d2_224',\n",
       " 'volo_d2_384',\n",
       " 'volo_d3_224',\n",
       " 'volo_d3_448',\n",
       " 'volo_d4_224',\n",
       " 'volo_d4_448',\n",
       " 'volo_d5_224',\n",
       " 'volo_d5_448',\n",
       " 'volo_d5_512',\n",
       " 'wide_resnet50_2',\n",
       " 'wide_resnet101_2',\n",
       " 'xception',\n",
       " 'xception41',\n",
       " 'xception41p',\n",
       " 'xception65',\n",
       " 'xception65p',\n",
       " 'xception71',\n",
       " 'xcit_large_24_p8_224',\n",
       " 'xcit_large_24_p8_224_dist',\n",
       " 'xcit_large_24_p8_384_dist',\n",
       " 'xcit_large_24_p16_224',\n",
       " 'xcit_large_24_p16_224_dist',\n",
       " 'xcit_large_24_p16_384_dist',\n",
       " 'xcit_medium_24_p8_224',\n",
       " 'xcit_medium_24_p8_224_dist',\n",
       " 'xcit_medium_24_p8_384_dist',\n",
       " 'xcit_medium_24_p16_224',\n",
       " 'xcit_medium_24_p16_224_dist',\n",
       " 'xcit_medium_24_p16_384_dist',\n",
       " 'xcit_nano_12_p8_224',\n",
       " 'xcit_nano_12_p8_224_dist',\n",
       " 'xcit_nano_12_p8_384_dist',\n",
       " 'xcit_nano_12_p16_224',\n",
       " 'xcit_nano_12_p16_224_dist',\n",
       " 'xcit_nano_12_p16_384_dist',\n",
       " 'xcit_small_12_p8_224',\n",
       " 'xcit_small_12_p8_224_dist',\n",
       " 'xcit_small_12_p8_384_dist',\n",
       " 'xcit_small_12_p16_224',\n",
       " 'xcit_small_12_p16_224_dist',\n",
       " 'xcit_small_12_p16_384_dist',\n",
       " 'xcit_small_24_p8_224',\n",
       " 'xcit_small_24_p8_224_dist',\n",
       " 'xcit_small_24_p8_384_dist',\n",
       " 'xcit_small_24_p16_224',\n",
       " 'xcit_small_24_p16_224_dist',\n",
       " 'xcit_small_24_p16_384_dist',\n",
       " 'xcit_tiny_12_p8_224',\n",
       " 'xcit_tiny_12_p8_224_dist',\n",
       " 'xcit_tiny_12_p8_384_dist',\n",
       " 'xcit_tiny_12_p16_224',\n",
       " 'xcit_tiny_12_p16_224_dist',\n",
       " 'xcit_tiny_12_p16_384_dist',\n",
       " 'xcit_tiny_24_p8_224',\n",
       " 'xcit_tiny_24_p8_224_dist',\n",
       " 'xcit_tiny_24_p8_384_dist',\n",
       " 'xcit_tiny_24_p16_224',\n",
       " 'xcit_tiny_24_p16_224_dist',\n",
       " 'xcit_tiny_24_p16_384_dist']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timm.list_models(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d8029a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fold': 3,\n",
       " 'epoch': 50,\n",
       " 'model_name': 'tf_efficientnet_b0_ns',\n",
       " 'soft_target': 0.9,\n",
       " 'finetune': True,\n",
       " 'img_size': 128,\n",
       " 'batch_size': 64,\n",
       " 'gradient_accumulation': 1,\n",
       " 'gradient_checkpoint': False,\n",
       " 'drop_out': 0.3,\n",
       " 'drop_path': 0.2,\n",
       " 'mixup': 0.65,\n",
       " 'lr': 6e-06,\n",
       " 'weight_decay': 0.0005,\n",
       " 'num_classes': 264,\n",
       " 'load_model': './train_model/cv3_best.pth',\n",
       " 'save_model': './train_model'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CFG= {\n",
    "    'fold': 3,\n",
    "    'epoch': 50,\n",
    "    'model_name': 'tf_efficientnet_b0_ns',\n",
    "    'soft_target': 0.9,\n",
    "    'finetune': True,\n",
    "    \n",
    "    'img_size': 128,\n",
    "    'batch_size': 64,\n",
    "    'gradient_accumulation': 1,\n",
    "    'gradient_checkpoint': False,\n",
    "    'drop_out': 0.3,\n",
    "    'drop_path': 0.2,\n",
    "    'mixup': 0.65,\n",
    "    \n",
    "    'lr': 6e-5,\n",
    "    'weight_decay': 5e-4,\n",
    "    \n",
    "    'num_classes': 264,\n",
    "    'load_model': 'pretrained/nfnet_l0.pth',\n",
    "    'save_model': './train_model'\n",
    "}\n",
    "\n",
    "if CFG['finetune']:\n",
    "    CFG['lr']= 6e-6\n",
    "    CFG['load_model']= f\"./train_model/cv{CFG['fold']}_best.pth\"\n",
    "#     CFG['load_model']= f\"./train_model/cv{CFG['fold']}_ep30.pth\"\n",
    "CFG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3aa7835",
   "metadata": {},
   "source": [
    "# Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9be52de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>label</th>\n",
       "      <th>label_name</th>\n",
       "      <th>group</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data/train_img_ex2020\\barswa\\XC134349._15804.png</td>\n",
       "      <td>20</td>\n",
       "      <td>barswa</td>\n",
       "      <td>XC134349.</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data/train_img_ex2020\\barswa\\XC134349._15805.png</td>\n",
       "      <td>20</td>\n",
       "      <td>barswa</td>\n",
       "      <td>XC134349.</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data/train_img_ex2020\\barswa\\XC134349._15806.png</td>\n",
       "      <td>20</td>\n",
       "      <td>barswa</td>\n",
       "      <td>XC134349.</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data/train_img_ex2020\\barswa\\XC134349._15807.png</td>\n",
       "      <td>20</td>\n",
       "      <td>barswa</td>\n",
       "      <td>XC134349.</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data/train_img_ex2020\\barswa\\XC134349._15808.png</td>\n",
       "      <td>20</td>\n",
       "      <td>barswa</td>\n",
       "      <td>XC134349.</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17325</th>\n",
       "      <td>Data/train_img_ex1\\greegr\\XC58490._95648.png</td>\n",
       "      <td>106</td>\n",
       "      <td>greegr</td>\n",
       "      <td>XC58490.</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17326</th>\n",
       "      <td>Data/train_img_ex1\\greegr\\XC586205._95649.png</td>\n",
       "      <td>106</td>\n",
       "      <td>greegr</td>\n",
       "      <td>XC586205.</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17327</th>\n",
       "      <td>Data/train_img_ex1\\greegr\\XC84914._95650.png</td>\n",
       "      <td>106</td>\n",
       "      <td>greegr</td>\n",
       "      <td>XC84914.</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17328</th>\n",
       "      <td>Data/train_img_ex1\\greegr\\XC84914._95651.png</td>\n",
       "      <td>106</td>\n",
       "      <td>greegr</td>\n",
       "      <td>XC84914.</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17329</th>\n",
       "      <td>Data/train_img_ex1\\greegr\\XC84914._95652.png</td>\n",
       "      <td>106</td>\n",
       "      <td>greegr</td>\n",
       "      <td>XC84914.</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17330 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             image_path  label label_name   \n",
       "0      Data/train_img_ex2020\\barswa\\XC134349._15804.png     20     barswa  \\\n",
       "1      Data/train_img_ex2020\\barswa\\XC134349._15805.png     20     barswa   \n",
       "2      Data/train_img_ex2020\\barswa\\XC134349._15806.png     20     barswa   \n",
       "3      Data/train_img_ex2020\\barswa\\XC134349._15807.png     20     barswa   \n",
       "4      Data/train_img_ex2020\\barswa\\XC134349._15808.png     20     barswa   \n",
       "...                                                 ...    ...        ...   \n",
       "17325      Data/train_img_ex1\\greegr\\XC58490._95648.png    106     greegr   \n",
       "17326     Data/train_img_ex1\\greegr\\XC586205._95649.png    106     greegr   \n",
       "17327      Data/train_img_ex1\\greegr\\XC84914._95650.png    106     greegr   \n",
       "17328      Data/train_img_ex1\\greegr\\XC84914._95651.png    106     greegr   \n",
       "17329      Data/train_img_ex1\\greegr\\XC84914._95652.png    106     greegr   \n",
       "\n",
       "           group  fold  \n",
       "0      XC134349.   1.0  \n",
       "1      XC134349.   1.0  \n",
       "2      XC134349.   1.0  \n",
       "3      XC134349.   1.0  \n",
       "4      XC134349.   1.0  \n",
       "...          ...   ...  \n",
       "17325   XC58490.   2.0  \n",
       "17326  XC586205.   4.0  \n",
       "17327   XC84914.   2.0  \n",
       "17328   XC84914.   2.0  \n",
       "17329   XC84914.   2.0  \n",
       "\n",
       "[17330 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.read_csv('Data/train.csv')\n",
    "label_name= list(df['label_name'].unique())\n",
    "\n",
    "df_1= pd.read_csv('Data/train_ex2020.csv')\n",
    "df_2= pd.read_csv('Data/train_ex2021.csv')\n",
    "df_3= pd.read_csv('Data/train_ex2022.csv')\n",
    "df_4= pd.read_csv('Data/train_ex1.csv')\n",
    "ex_df= pd.concat([df_1, df_2, df_3, df_4], axis=0)\n",
    "ex_df= ex_df[ex_df['label_name'].isin(label_name)].reset_index(drop=True)\n",
    "\n",
    "la= list(ex_df['label_name'].unique())\n",
    "for l in la:\n",
    "    ex_df.loc[ ex_df['label_name']==l, 'label' ]= label_name.index(l)\n",
    "ex_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0010c7a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7ddd930b96941de8678421fe1a9d0c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/264 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataset: 56031\n",
      "valid dataset: 26220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\kaggle_smbcd\\lib\\site-packages\\albumentations\\augmentations\\dropout\\cutout.py:49: FutureWarning: Cutout has been deprecated. Please use CoarseDropout\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>label</th>\n",
       "      <th>label_name</th>\n",
       "      <th>group</th>\n",
       "      <th>fold</th>\n",
       "      <th>2nd_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data/train_img\\abethr1\\XC128013._0.png</td>\n",
       "      <td>0</td>\n",
       "      <td>abethr1</td>\n",
       "      <td>XC128013.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data/train_img\\abethr1\\XC128013._1.png</td>\n",
       "      <td>0</td>\n",
       "      <td>abethr1</td>\n",
       "      <td>XC128013.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data/train_img\\abethr1\\XC128013._2.png</td>\n",
       "      <td>0</td>\n",
       "      <td>abethr1</td>\n",
       "      <td>XC128013.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data/train_img\\abethr1\\XC128013._3.png</td>\n",
       "      <td>0</td>\n",
       "      <td>abethr1</td>\n",
       "      <td>XC128013.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data/train_img\\abethr1\\XC128013._4.png</td>\n",
       "      <td>0</td>\n",
       "      <td>abethr1</td>\n",
       "      <td>XC128013.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               image_path  label label_name      group  fold   \n",
       "0  Data/train_img\\abethr1\\XC128013._0.png      0    abethr1  XC128013.   1.0  \\\n",
       "1  Data/train_img\\abethr1\\XC128013._1.png      0    abethr1  XC128013.   1.0   \n",
       "2  Data/train_img\\abethr1\\XC128013._2.png      0    abethr1  XC128013.   1.0   \n",
       "3  Data/train_img\\abethr1\\XC128013._3.png      0    abethr1  XC128013.   1.0   \n",
       "4  Data/train_img\\abethr1\\XC128013._4.png      0    abethr1  XC128013.   1.0   \n",
       "\n",
       "  2nd_label  \n",
       "0        []  \n",
       "1        []  \n",
       "2        []  \n",
       "3        []  \n",
       "4        []  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.read_csv('Data/train_2nd_label.csv')\n",
    "\n",
    "train_dataset= df[df['fold']!=CFG['fold']].reset_index(drop=True)\n",
    "train_dataset= pd.concat([train_dataset, ex_df],axis=0).reset_index(drop=True).fillna('[]')\n",
    "label= train_dataset['label'].unique().tolist()\n",
    "n= 500\n",
    "for i,g in enumerate(tqdm(label)):\n",
    "    sample_df= train_dataset[train_dataset['label']==g]\n",
    "    if len(sample_df)>=500: sample_df= sample_df.sample(n=n, replace=False, random_state=1).reset_index(drop=True)\n",
    "    elif len(sample_df)<50: sample_df= sample_df.sample(n=50, replace=True, random_state=1).reset_index(drop=True)\n",
    "    if i==0: new_df= sample_df\n",
    "    else: new_df= pd.concat([new_df, sample_df], axis=0).reset_index(drop=True)\n",
    "train_dataset= new_df\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "cls_weight= compute_class_weight(class_weight='balanced', classes=list(range(264)), y=train_dataset['label'].values)\n",
    "cls_weight= torch.tensor(cls_weight).cuda()\n",
    "\n",
    "valid_dataset= df[df['fold']==CFG['fold']].reset_index(drop=True)\n",
    "print(f'train dataset: {len(train_dataset)}')\n",
    "print(f'valid dataset: {len(valid_dataset)}')\n",
    "\n",
    "train_dataset= Customize_Dataset(train_dataset, get_train_transform(CFG['img_size']), mixup=CFG['mixup'])\n",
    "valid_dataset= Customize_Dataset(valid_dataset, get_test_transform(CFG['img_size']), mixup=False)\n",
    "\n",
    "train_loader= DataLoader(train_dataset, batch_size= CFG['batch_size'], shuffle=True, num_workers=0)\n",
    "valid_loader= DataLoader(valid_dataset, batch_size=32, shuffle=False, num_workers=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "32077713",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data= train_dataset[0]\n",
    "img= data['image']\n",
    "label= data['label']\n",
    "plt.imshow(img.permute(1,2,0).numpy())\n",
    "label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd8144c",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce46fc57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_model: ./train_model/cv3_best.pth\n",
      "\n",
      "ep: 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0fc0874230d470c88f0455599349720",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/876 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_18812\\2664467966.py:60: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'image': torch.tensor(img/255, dtype=torch.float32),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a57477fc5144563a2cfad01e99f6525",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/820 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7780701754385965\n",
      "mean_recall: 0.5609757350580358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmap: 0.7682644824820182\n",
      "train loss: 2.55056\n",
      "valid loss: 2.72966, valid_acc: 0.76826\n",
      "model save at score: 0.76826\n",
      "\n",
      "ep: 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a09ffcccac3647c28feb44f9be5c3f55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/876 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_18812\\2664467966.py:60: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'image': torch.tensor(img/255, dtype=torch.float32),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b764e4a54b9413e97438b27b585e60b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/820 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7793287566742945\n",
      "mean_recall: 0.5586588060351579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmap: 0.7683750934259393\n",
      "train loss: 2.5507\n",
      "valid loss: 2.72693, valid_acc: 0.76838\n",
      "model save at score: 0.76838\n",
      "\n",
      "ep: 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d8eff38e1c74b889b00fcd481264555",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/876 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_18812\\2664467966.py:60: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'image': torch.tensor(img/255, dtype=torch.float32),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30dfd53deb9b4985a9d10bda7401a0aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/820 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7795194508009153\n",
      "mean_recall: 0.555886218492365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmap: 0.76870699038379\n",
      "train loss: 2.54319\n",
      "valid loss: 2.72849, valid_acc: 0.76871\n",
      "model save at score: 0.76871\n",
      "\n",
      "ep: 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2177c51f3da44f75965b6b5f54e94a90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/876 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_18812\\2664467966.py:60: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'image': torch.tensor(img/255, dtype=torch.float32),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "610532b63e7d4dcd8b1dc3f71dd19246",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/820 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7800152555301296\n",
      "mean_recall: 0.5569174367817703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmap: 0.7688018778411795\n",
      "train loss: 2.54397\n",
      "valid loss: 2.72842, valid_acc: 0.7688\n",
      "model save at score: 0.7688\n",
      "\n",
      "ep: 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb101e937625441b9c878499e8056e95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/876 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_18812\\2664467966.py:60: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'image': torch.tensor(img/255, dtype=torch.float32),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8267bb3f150c46f0976da146c04f5d6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/820 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7799008390541571\n",
      "mean_recall: 0.5609485031531292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmap: 0.7691100886368869\n",
      "train loss: 2.54643\n",
      "valid loss: 2.72544, valid_acc: 0.76911\n",
      "model save at score: 0.76911\n",
      "\n",
      "ep: 6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "338fddc6b92243d1be0fd3c4f82670ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/876 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_18812\\2664467966.py:60: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'image': torch.tensor(img/255, dtype=torch.float32),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3420ed75f6554a35bcdb00885cdbf730",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/820 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7801678108314264\n",
      "mean_recall: 0.5589465837615143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmap: 0.7689065920853495\n",
      "train loss: 2.53655\n",
      "valid loss: 2.72602, valid_acc: 0.76891\n",
      "\n",
      "ep: 7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccec5bb132d540ff91a072d7221519f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/876 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_18812\\2664467966.py:60: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'image': torch.tensor(img/255, dtype=torch.float32),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "728a9602f1b14e8ba909e8b55210a8b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/820 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.780511060259344\n",
      "mean_recall: 0.5615926062165041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmap: 0.7689744209400244\n",
      "train loss: 2.53432\n",
      "valid loss: 2.72407, valid_acc: 0.76897\n",
      "\n",
      "ep: 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "699038f8a1f845feb9762724dd8730ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/876 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_18812\\2664467966.py:60: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'image': torch.tensor(img/255, dtype=torch.float32),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "090e119f1712404bbe9ce6d4d9a9b1ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/820 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7803585049580473\n",
      "mean_recall: 0.5576280866802754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmap: 0.7693102878893542\n",
      "train loss: 2.53538\n",
      "valid loss: 2.72495, valid_acc: 0.76931\n",
      "model save at score: 0.76931\n",
      "\n",
      "ep: 9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "143d5cb42cd94bd59531b2fcba17016a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/876 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_18812\\2664467966.py:60: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'image': torch.tensor(img/255, dtype=torch.float32),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05c68750c7564845b53cd6db57aab315",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/820 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7815026697177727\n",
      "mean_recall: 0.5635141475548895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmap: 0.7695242497959986\n",
      "train loss: 2.5358\n",
      "valid loss: 2.72515, valid_acc: 0.76952\n",
      "model save at score: 0.76952\n",
      "\n",
      "ep: 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e3b2c1f8460409c872a23cc3cf8c010",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/876 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_18812\\2664467966.py:60: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'image': torch.tensor(img/255, dtype=torch.float32),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de3fc5ae99c14c7fa28fcf2f28182210",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/820 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.781350114416476\n",
      "mean_recall: 0.5598733597391156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmap: 0.7696595310787586\n",
      "train loss: 2.53188\n",
      "valid loss: 2.72268, valid_acc: 0.76966\n",
      "model save at score: 0.76966\n",
      "\n",
      "ep: 11\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee2c0f4d6c65475da697d58a26faa560",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/876 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_18812\\2664467966.py:60: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'image': torch.tensor(img/255, dtype=torch.float32),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9faa2d5153ca46e4bb62e540ad28b17e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/820 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7810068649885583\n",
      "mean_recall: 0.5629802278364486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmap: 0.7699540402712964\n",
      "train loss: 2.53056\n",
      "valid loss: 2.72431, valid_acc: 0.76995\n",
      "model save at score: 0.76995\n",
      "\n",
      "ep: 12\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c69e01f861f4071a177b50050192f25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/876 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_18812\\2664467966.py:60: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'image': torch.tensor(img/255, dtype=torch.float32),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5e666c2a6194d1c861c5e9973c573a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/820 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.780511060259344\n",
      "mean_recall: 0.559493803382611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmap: 0.7695102251414254\n",
      "train loss: 2.53874\n",
      "valid loss: 2.72602, valid_acc: 0.76951\n",
      "\n",
      "ep: 13\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcece7906f3644729cc6a4ef388de4f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/876 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_18812\\2664467966.py:60: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'image': torch.tensor(img/255, dtype=torch.float32),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "952e6a897ac445a79ddd5004f09e02da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/820 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7799008390541571\n",
      "mean_recall: 0.5601372451676082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmap: 0.7693683393252964\n",
      "train loss: 2.52706\n",
      "valid loss: 2.72507, valid_acc: 0.76937\n",
      "\n",
      "ep: 14\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02a406219cbd41acb565bbb88dd73be5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/876 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_18812\\2664467966.py:60: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'image': torch.tensor(img/255, dtype=torch.float32),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4a514339ab848dda543891d5db64960",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/820 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7806254767353166\n",
      "mean_recall: 0.5601345801956177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmap: 0.7701287150936403\n",
      "train loss: 2.52422\n",
      "valid loss: 2.72287, valid_acc: 0.77013\n",
      "model save at score: 0.77013\n",
      "\n",
      "ep: 15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00f650fc4f5c4c57be34fcb9871aeef5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/876 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_18812\\2664467966.py:60: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'image': torch.tensor(img/255, dtype=torch.float32),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93941ebb63d446e292212e6f58b213fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/820 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7806254767353166\n",
      "mean_recall: 0.5625868317769468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmap: 0.7698752544131585\n",
      "train loss: 2.53402\n",
      "valid loss: 2.72425, valid_acc: 0.76988\n",
      "\n",
      "ep: 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f13368db8cff44e5a72cf880441be8d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/876 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_18812\\2664467966.py:60: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'image': torch.tensor(img/255, dtype=torch.float32),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "050f620f681c45f78f48aec6e9ee52b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/820 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7802440884820747\n",
      "mean_recall: 0.5593351059363582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmap: 0.7696134227382908\n",
      "train loss: 2.52809\n",
      "valid loss: 2.72418, valid_acc: 0.76961\n",
      "\n",
      "ep: 17\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eeda5d7d55fc41ec90771a65a3349ad5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/876 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_18812\\2664467966.py:60: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'image': torch.tensor(img/255, dtype=torch.float32),\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c220dab2627242839b9ec83f1b4c8e43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/820 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7807398932112891\n",
      "mean_recall: 0.5598736408445564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmap: 0.7694055722914479\n",
      "train loss: 2.53231\n",
      "valid loss: 2.72553, valid_acc: 0.76941\n",
      "\n",
      "ep: 18\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a07fc14de25482a976efe78b64be405",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/876 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_18812\\2664467966.py:60: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'image': torch.tensor(img/255, dtype=torch.float32),\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18812\\3371981083.py\u001b[0m in \u001b[0;36m<cell line: 24>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'\\nep: {ep}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m     \u001b[0mtrain_loss\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m     \u001b[0mvalid_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_acc\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mvalid_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'train loss: {round(train_loss, 5)}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18812\\4254015569.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[1;34m(dataloader, model, criterion, optimizer)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mep_loss\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mimgs\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'image'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cuda'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\kaggle_smbcd\\lib\\site-packages\\tqdm\\notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    257\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m             \u001b[0mit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 259\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    260\u001b[0m                 \u001b[1;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\kaggle_smbcd\\lib\\site-packages\\tqdm\\std.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1194\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1195\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1196\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1197\u001b[0m                 \u001b[1;31m# Update and possibly print the progressbar.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\kaggle_smbcd\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    632\u001b[0m                 \u001b[1;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    633\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 634\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    635\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    636\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\kaggle_smbcd\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    676\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    677\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\kaggle_smbcd\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\kaggle_smbcd\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18812\\2664467966.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     49\u001b[0m                 \u001b[0mindx\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m                 \u001b[0mimg_2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_2\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlabel_1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m!=\u001b[0m\u001b[0mlabel_2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m             img, label= self.mixup_aug(img_1, label_1, \n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18812\\2664467966.py\u001b[0m in \u001b[0;36mread_data\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'image_path'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m         \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## create model\n",
    "if CFG['load_model']:\n",
    "    print(f\"load_model: {CFG['load_model']}\")\n",
    "    model= torch.load(CFG['load_model'], map_location= 'cuda')\n",
    "else:\n",
    "    model= Customize_Model(CFG['model_name'], CFG['num_classes'])\n",
    "    \n",
    "if CFG['gradient_checkpoint']: \n",
    "    print('use gradient checkpoint')\n",
    "    model.model.set_grad_checkpointing(enable=True)\n",
    "    \n",
    "if 'pretrained' in str(CFG['load_model']): \n",
    "    print('use bird pretrained')\n",
    "#     model.model.classifier= nn.Linear(in_features=1280, out_features=264, bias=True)\n",
    "    model.model.head.fc= nn.Linear(in_features=2304, out_features=264, bias=True)\n",
    "model.to('cuda')\n",
    "    \n",
    "## hyperparameter\n",
    "criterion= Customize_loss()\n",
    "optimizer= optim.AdamW(model.parameters(), lr= CFG['lr'], weight_decay= CFG['weight_decay'])\n",
    "\n",
    "## start training\n",
    "best_score= 0\n",
    "for ep in range(1, CFG['epoch']+1):\n",
    "    print(f'\\nep: {ep}')\n",
    "    \n",
    "    train_loss= train_epoch(train_loader, model, criterion, optimizer)\n",
    "    valid_loss, valid_acc= valid_epoch(valid_loader, model, criterion)\n",
    "    print(f'train loss: {round(train_loss, 5)}')\n",
    "    print(f'valid loss: {round(valid_loss, 5)}, valid_acc: {round(valid_acc, 5)}')\n",
    "    \n",
    "    if valid_acc >= best_score:\n",
    "        best_score= valid_acc\n",
    "        torch.save(model, f\"{CFG['save_model']}/cv{CFG['fold']}_best.pth\")\n",
    "        print(f'model save at score: {round(best_score, 5)}')\n",
    "        \n",
    "    ## save model every epoch\n",
    "#     torch.save(model, f\"{CFG['save_model']}/cv{CFG['fold']}_ep{ep}.pth\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c1cd6067",
   "metadata": {},
   "source": [
    "effb0, imgsz= 128, aug, kaggle_balance_preprocess, soft_ce=0.25, cv0= 0.525, cmap=0.721\n",
    "effb0, imgsz= 128, aug, kaggle_balance_preprocess, soft_ce=0.25, mixup=0.2, cv0= 0.536, cmap=0.736\n",
    "effb0, imgsz= 128, aug, pos_weight, soft_ce=0.25, mixup=0.2, cv0= 0.32, cmap=0.738\n",
    "\n",
    "effb0, imgsz= 128, aug, pos_weight, ExPretrained, ExData, soft_ce=0.25, mixup=0.4, cmap=0.770, lb=0.79\n",
    "effb0, imgsz= 192, aug, pos_weight, ExPretrained, ExData, soft_ce=0.25, mixup=0.4, cmap=0.776, lb=0.79\n",
    "\n",
    "effb0, imgsz= 256, aug, pos_weight, soft_ce=0.25, mixup=0.5, 2nd_label=0.9, cmap=0.780, lb=0.78\n",
    "\n",
    "nfnet_l0, imgsz=128, kaggle_balance, soft_ce=0.25, ExData, mixup=0.65, cmap=0.782,lb=0.79"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
